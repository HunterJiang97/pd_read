,id,title,categories,abstract,doi,created,updated,authors
1590,2408.10524,xcb: an effective contextual biasing approach to bias cross-lingual   phrases in speech recognition,cs.cl cs.ai cs.sd eess.as,"contextualized asr models have been demonstrated to effectively improve the recognition accuracy of uncommon phrases when a predefined phrase list is available. however, these models often struggle with bilingual settings, which are prevalent in code-switching speech recognition. in this study, we make the initial attempt to address this challenge by introducing a cross-lingual contextual biasing(xcb) module. specifically, we augment a pre-trained asr model for the dominant language by integrating an auxiliary language biasing module and a supplementary language-specific loss, aimed at enhancing the recognition of phrases in the secondary language. experimental results conducted on our in-house code-switching dataset have validated the efficacy of our approach, demonstrating significant improvements in the recognition of biasing phrases in the secondary language, even without any additional inference overhead. additionally, our proposed system exhibits both efficiency and generalization when is applied by the unseen asru-2019 test set.",,2024-08-20,,"['xucheng wan', 'naijun zheng', 'kai liu', 'huan zhou']"
1591,2408.10525,mpgnet: learning move-push-grasping synergy for target-oriented grasping   in occluded scenes,cs.ro,"this paper focuses on target-oriented grasping in occluded scenes, where the target object is specified by a binary mask and the goal is to grasp the target object with as few robotic manipulations as possible. most existing methods rely on a push-grasping synergy to complete this task. to deliver a more powerful target-oriented grasping pipeline, we present mpgnet, a three-branch network for learning a synergy between moving, pushing, and grasping actions. we also propose a multi-stage training strategy to train the mpgnet which contains three policy networks corresponding to the three actions. the effectiveness of our method is demonstrated via both simulated and real-world experiments.",,2024-08-20,,"['dayou li', 'chenkun zhao', 'shuo yang', 'ran song', 'xiaolei li', 'wei zhang']"
1592,2408.10527,edgenat: transformer for efficient edge detection,cs.cv cs.ai,"transformers, renowned for their powerful feature extraction capabilities, have played an increasingly prominent role in various vision tasks. especially, recent advancements present transformer with hierarchical structures such as dilated neighborhood attention transformer (dinat), demonstrating outstanding ability to efficiently capture both global and local features. however, transformers' application in edge detection has not been fully exploited. in this paper, we propose edgenat, a one-stage transformer-based edge detector with dinat as the encoder, capable of extracting object boundaries and meaningful edges both accurately and efficiently. on the one hand, edgenat captures global contextual information and detailed local cues with dinat, on the other hand, it enhances feature representation with a novel scaf-mla decoder by utilizing both inter-spatial and inter-channel relationships of feature maps. extensive experiments on multiple datasets show that our method achieves state-of-the-art performance on both rgb and depth images. notably, on the widely used bsds500 dataset, our l model achieves impressive performances, with ods f-measure and ois f-measure of 86.0%, 87.6% for multi-scale input,and 84.9%, and 86.3% for single-scale input, surpassing the current state-of-the-art edter by 1.2%, 1.1%, 1.7%, and 1.6%, respectively. moreover, as for throughput, our approach runs at 20.87 fps on rtx 4090 gpu with single-scale input. the code for our method will be released soon.",,2024-08-20,,"['jinghuai jie', 'yan guo', 'guixing wu', 'junmin wu', 'baojian hua']"
1593,2408.10528,"nomatterxai: generating ""no matter what"" alterfactual examples for   explaining black-box text classification models",cs.cl,"in explainable ai (xai), counterfactual explanations (ces) are a well-studied method to communicate feature relevance through contrastive reasoning of ""what if"" to explain ai models' predictions. however, they only focus on important (i.e., relevant) features and largely disregard less important (i.e., irrelevant) ones. such irrelevant features can be crucial in many applications, especially when users need to ensure that an ai model's decisions are not affected or biased against specific attributes such as gender, race, religion, or political affiliation. to address this gap, the concept of alterfactual explanations (aes) has been proposed. aes explore an alternative reality of ""no matter what"", where irrelevant features are substituted with alternative features (e.g., ""republicans"" -> ""democrats"") within the same attribute (e.g., ""politics"") while maintaining a similar prediction output. this serves to validate whether ai model predictions are influenced by the specified attributes. despite the promise of aes, there is a lack of computational approaches to systematically generate them, particularly in the text domain, where creating aes for ai text classifiers presents unique challenges. this paper addresses this challenge by formulating ae generation as an optimization problem and introducing momatterxai, a novel algorithm that generates aes for text classification tasks. our approach achieves high fidelity of up to 95% while preserving context similarity of over 90% across multiple models and datasets. a human study further validates the effectiveness of aes in explaining ai text classifiers to end users. all codes will be publicly available.",,2024-08-20,,"['tuc nguyen', 'james michels', 'hua shen', 'thai le']"
1594,2408.10531,leveraging temporal contexts to enhance vehicle-infrastructure   cooperative perception,cs.ro,"infrastructure sensors installed at elevated positions offer a broader perception range and encounter fewer occlusions. integrating both infrastructure and ego-vehicle data through v2x communication, known as vehicle-infrastructure cooperation, has shown considerable advantages in enhancing perception capabilities and addressing corner cases encountered in single-vehicle autonomous driving. however, cooperative perception still faces numerous challenges, including limited communication bandwidth and practical communication interruptions. in this paper, we propose ctce, a novel framework for cooperative 3d object detection. this framework transmits queries with temporal contexts enhancement, effectively balancing transmission efficiency and performance to accommodate real-world communication conditions. additionally, we propose a temporal-guided fusion module to further improve performance. the roadside temporal enhancement and vehicle-side spatial-temporal fusion together constitute a multi-level temporal contexts integration mechanism, fully leveraging temporal information to enhance performance. furthermore, a motion-aware reconstruction module is introduced to recover lost roadside queries due to communication interruptions. experimental results on v2x-seq and v2x-sim datasets demonstrate that ctce outperforms the baseline quest, achieving improvements of 3.8% and 1.3% in map, respectively. experiments under communication interruption conditions validate ctce's robustness to communication interruptions.",,2024-08-20,,"['jiaru zhong', 'haibao yu', 'tianyi zhu', 'jiahui xu', 'wenxian yang', 'zaiqing nie', 'chao sun']"
1595,2408.10532,"nutrifyai: an ai-powered system for real-time food detection,   nutritional analysis, and personalized meal recommendations",cs.cv cs.ai,"with diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's no surprise that health apps like myfitnesspal, noom, and calorie counter, are surging in popularity. however, one major setback [2] of nearly all nutrition applications is that users must enter food data manually, which is time-consuming and tedious. thus, there has been an increasing demand for applications that can accurately identify food items, analyze their nutritional content, and offer dietary recommendations in real-time. this paper introduces a comprehensive system that combines advanced computer vision techniques with nutrition analysis, implemented in a versatile mobile and web application. the system is divided into three key components: 1) food detection using the yolov8 model, 2) nutrient analysis via the edamam nutrition analysis api, and 3) personalized meal recommendations using the edamam meal planning and recipe search apis. designed for both mobile and web platforms, the application ensures fast processing times with an intuitive user interface, with features such as data visualizations using chart.js, a login system, and personalized settings for dietary preferences, allergies, and cuisine choices. preliminary results showcase the system's effectiveness, making it a valuable tool for users to make informed dietary decisions.",,2024-08-20,,"['michelle han', 'junyao chen']"
1596,2408.10536,"synergistic approach for simultaneous optimization of monolingual,   cross-lingual, and multilingual information retrieval",cs.ir cs.cl,"information retrieval across different languages is an increasingly important challenge in natural language processing. recent approaches based on multilingual pre-trained language models have achieved remarkable success, yet they often optimize for either monolingual, cross-lingual, or multilingual retrieval performance at the expense of others. this paper proposes a novel hybrid batch training strategy to simultaneously improve zero-shot retrieval performance across monolingual, cross-lingual, and multilingual settings while mitigating language bias. the approach fine-tunes multilingual language models using a mix of monolingual and cross-lingual question-answer pair batches sampled based on dataset size. experiments on xquad-r, mlqa-r, and miracl benchmark datasets show that the proposed method consistently achieves comparable or superior results in zero-shot retrieval across various languages and retrieval tasks compared to monolingual-only or cross-lingual-only training. hybrid batch training also substantially reduces language bias in multilingual retrieval compared to monolingual training. these results demonstrate the effectiveness of the proposed approach for learning language-agnostic representations that enable strong zero-shot retrieval performance across diverse languages.",,2024-08-20,,"['adel elmahdy', 'sheng-chieh lin', 'amin ahmad']"
1597,2408.10537,subspace prototype guidance for mitigating class imbalance in point   cloud semantic segmentation,cs.cv,"point cloud semantic segmentation can significantly enhance the perception of an intelligent agent. nevertheless, the discriminative capability of the segmentation network is influenced by the quantity of samples available for different categories. to mitigate the cognitive bias induced by class imbalance, this paper introduces a novel method, namely subspace prototype guidance (\textbf{spg}), to guide the training of segmentation network. specifically, the point cloud is initially separated into independent point sets by category to provide initial conditions for the generation of feature subspaces. the auxiliary branch which consists of an encoder and a projection head maps these point sets into separate feature subspaces. subsequently, the feature prototypes which are extracted from the current separate subspaces and then combined with prototypes of historical subspaces guide the feature space of main branch to enhance the discriminability of features of minority categories. the prototypes derived from the feature space of main branch are also employed to guide the training of the auxiliary branch, forming a supervisory loop to maintain consistent convergence of the entire network. the experiments conducted on the large public benchmarks (i.e. s3dis, scannet v2, scannet200, toronto-3d) and collected real-world data illustrate that the proposed method significantly improves the segmentation performance and surpasses the state-of-the-art method. the code is available at \url{https://github.com/javion11/pointlibr.git}.",,2024-08-20,,"['jiawei han', 'kaiqi liu', 'wei li', 'guangzhi chen']"
1598,2408.10539,training matting models without alpha labels,cs.cv,"the labelling difficulty has been a longstanding problem in deep image matting. to escape from fine labels, this work explores using rough annotations such as trimaps coarsely indicating the foreground/background as supervision. we present that the cooperation between learned semantics from indicated known regions and proper assumed matting rules can help infer alpha values at transition areas. inspired by the nonlocal principle in traditional image matting, we build a directional distance consistency loss (ddc loss) at each pixel neighborhood to constrain the alpha values conditioned on the input image. ddc loss forces the distance of similar pairs on the alpha matte and on its corresponding image to be consistent. in this way, the alpha values can be propagated from learned known regions to unknown transition areas. with only images and trimaps, a matting model can be trained under the supervision of a known loss and the proposed ddc loss. experiments on am-2k and p3m-10k dataset show that our paradigm achieves comparable performance with the fine-label-supervised baseline, while sometimes offers even more satisfying results than human-labelled ground truth. code is available at \url{https://github.com/poppuppy/alpha-free-matting}.",,2024-08-20,,"['wenze liu', 'zixuan ye', 'hao lu', 'zhiguo cao', 'xiangyu yue']"
1599,2408.10541,the instance-centric transformer for the rvos track of lsvos challenge:   3rd place solution,cs.cv,"referring video object segmentation is an emerging multi-modal task that aims to segment objects in the video given a natural language expression. in this work, we build two instance-centric models and fuse predicted results from frame-level and instance-level. first, we introduce instance mask into the detr-based model for query initialization to achieve temporal enhancement and employ sam for spatial refinement. secondly, we build an instance retrieval model conducting binary instance mask classification whether the instance is referred. finally, we fuse predicted results and our method achieved a score of 52.67 j&f in the validation phase and 60.36 j&f in the test phase, securing the final ranking of 3rd place in the 6-th lsvos challenge rvos track.",,2024-08-20,,"['bin cao', 'yisi zhang', 'hanyi wang', 'xingjian he', 'jing liu']"
1600,2408.10543,diff-pcc: diffusion-based neural compression for 3d point clouds,cs.cv cs.ai eess.iv,"stable diffusion networks have emerged as a groundbreaking development for their ability to produce realistic and detailed visual content. this characteristic renders them ideal decoders, capable of producing high-quality and aesthetically pleasing reconstructions. in this paper, we introduce the first diffusion-based point cloud compression method, dubbed diff-pcc, to leverage the expressive power of the diffusion model for generative and aesthetically superior decoding. different from the conventional autoencoder fashion, a dual-space latent representation is devised in this paper, in which a compressor composed of two independent encoding backbones is considered to extract expressive shape latents from distinct latent spaces. at the decoding side, a diffusion-based generator is devised to produce high-quality reconstructions by considering the shape latents as guidance to stochastically denoise the noisy point clouds. experiments demonstrate that the proposed diff-pcc achieves state-of-the-art compression performance (e.g., 7.711 db bd-psnr gains against the latest g-pcc standard at ultra-low bitrate) while attaining superior subjective quality. source code will be made publicly available.",,2024-08-20,,"['kai liu', 'kang you', 'pan gao']"
1601,2408.10547,"semi-on-demand off-peak transit services with shared autonomous vehicles   -- service planning, simulation, and analysis in munich, germany",eess.sy cs.sy math.oc,"this study investigates the implementation of semi-on-demand (sod) hybrid-route services using shared autonomous vehicles (savs) on existing transit lines. sod services combine the cost efficiency of fixed-route buses with the flexibility of on-demand services. savs first serve all scheduled fixed-route stops, then drop off and pick up passengers in the pre-determined flexible-route portion, and return to the fixed route. this study addresses four key questions: optimal fleet and vehicle sizes for peak-hour fixed-route services with savs and during transition (from drivers to autonomous vehicles), optimal off-peak sod service planning, and suitable use cases. the methodology combines analytical modeling for service planning with agent-based simulation for operational analysis. we examine ten bus routes in munich, germany, considering full sav and transition scenarios with varying proportions of drivers. our findings demonstrate that the lower operating costs of savs improve service quality through increased frequency and smaller vehicles, even in transition scenarios. the reduced headway lowers waiting time and also favors more flexible-route operation in sod services. the optimal sod settings range from fully flexible to hybrid routes, where higher occupancy from the terminus favors shorter flexible routes. during the transition phase, limited fleet size and higher headways constrain the benefits of flexible-route operations. the simulation results corroborate the sod benefits of door-to-door convenience, attracting more passengers without excessive detours and operator costs at moderate flexible-route lengths, and validate the analytical model.",,2024-08-20,,"['max t. m. ng', 'roman engelhardt', 'florian dandl', 'vasileios volakakis', 'hani s. mahmassani', 'klaus bogenberger']"
1602,2408.10548,"language modeling on tabular data: a survey of foundations, techniques   and evolution",cs.cl,"tabular data, a prevalent data type across various domains, presents unique challenges due to its heterogeneous nature and complex structural relationships. achieving high predictive performance and robustness in tabular data analysis holds significant promise for numerous applications. influenced by recent advancements in natural language processing, particularly transformer architectures, new methods for tabular data modeling have emerged. early techniques concentrated on pre-training transformers from scratch, often encountering scalability issues. subsequently, methods leveraging pre-trained language models like bert have been developed, which require less data and yield enhanced performance. the recent advent of large language models, such as gpt and llama, has further revolutionized the field, facilitating more advanced and diverse applications with minimal fine-tuning. despite the growing interest, a comprehensive survey of language modeling techniques for tabular data remains absent. this paper fills this gap by providing a systematic review of the development of language modeling for tabular data, encompassing: (1) a categorization of different tabular data structures and data types; (2) a review of key datasets used in model training and tasks used for evaluation; (3) a summary of modeling techniques including widely-adopted data processing methods, popular architectures, and training objectives; (4) the evolution from adapting traditional pre-training/pre-trained language models to the utilization of large language models; (5) an identification of persistent challenges and potential future research directions in language modeling for tabular data analysis. github page associated with this survey is available at: https://github.com/lanxiang1017/language-modeling-on-tabular-data-survey.git.",,2024-08-20,,"['yucheng ruan', 'xiang lan', 'jingying ma', 'yizhi dong', 'kai he', 'mengling feng']"
1603,2408.10549,ai-based ivr,cs.ai,"the use of traditional ivr (interactive voice response) methods often proves insufficient to meet customer needs. this article examines the application of artificial intelligence (ai) technologies to enhance the efficiency of ivr systems in call centers. a proposed approach is based on the integration of speech-to-text conversion solutions, text query classification using large language models (llm), and speech synthesis. special attention is given to adapting these technologies to work with the kazakh language, including fine-tuning models on specialized datasets. the practical aspects of implementing the developed system in a real call center for query classification are described. the research results demonstrate that the application of ai technologies in call center ivr systems reduces operator workload, improves customer service quality, and increases the efficiency of query processing. the proposed approach can be adapted for use in call centers operating with various languages.",,2024-08-20,,"['gassyrbek kosherbay', 'nurgissa apbaz']"
1604,2408.10554,ethics of software programming with generative ai: is programming   without generative ai always radical?,cs.se,"this paper provides a comprehensive analysis of generative ai (genai) potential to revolutionise software coding through increased efficiency and reduced time span for writing code. it acknowledges the transformative power of genai in software code generation, while also cautioning against the inherent risks of bias and errors if left unchecked. emphasising the irreplaceable value of traditional programming, it posits that genai is not a replacement but a complementary tool for writing software code. ethical considerations are paramount with the paper advocating for stringent ethical guidelines to ensure genai serves the greater good and does not compromise on accountability in writing software code. it suggests a balanced approach, combining human oversight with ai's capabilities, to mitigate risks and enhance reliability. the paper concludes by proposing guidelines for genai utilisation in coding, which will empower developers to navigate its complexities and employ it responsibly. this approach addresses current ethical concerns and sets a foundation for the judicious use of genai in the future, ensuring its benefits are harnessed effectively while maintaining moral integrity.",,2024-08-20,,"['marcellin atemkeng', 'sisipho hamlomo', 'brian welman', 'nicole oyentunji', 'pouya ataei', 'jean louis k. e fendji']"
1605,2408.10555,target-prompt online graph collaborative learning for temporal qos   prediction,cs.lg cs.ir,"in service-oriented architecture, accurately predicting the quality of service (qos) is vital for maintaining reliability and enhancing user satisfaction. however, current methods often neglect high-order latent collaborative relationships and fail to dynamically adjust feature learning for specific user-service invocations, which are critical for precise feature extraction. moreover, relying on rnns to capture qos evolution limits the ability to detect long-term trends due to challenges in managing long-range dependencies. to address these issues, we propose the target-prompt online graph collaborative learning (togcl) framework for temporal qos prediction. it leverages a dynamic user-service invocation graph to comprehensively model historical interactions. building on this graph, it develops a target-prompt graph attention network to extract online deep latent features of users and services at each time slice, considering implicit target-neighboring collaborative relationships and historical qos values. additionally, a multi-layer transformer encoder is employed to uncover temporal feature evolution patterns, enhancing temporal qos prediction. extensive experiments on the ws-dream dataset demonstrate that togcl significantly outperforms state-of-the-art methods across multiple metrics, achieving improvements of up to 38.80\%. these results underscore the effectiveness of togcl for temporal qos prediction.",,2024-08-20,,"['shengxiang hu', 'guobing zou', 'song yang', 'shiyi lin', 'bofeng zhang', 'yixin chen']"
1606,2408.10556,hokoff: real game dataset from honor of kings and its offline   reinforcement learning benchmarks,cs.ai cs.lg,"the advancement of offline reinforcement learning (rl) and offline multi-agent reinforcement learning (marl) critically depends on the availability of high-quality, pre-collected offline datasets that represent real-world complexities and practical applications. however, existing datasets often fall short in their simplicity and lack of realism. to address this gap, we propose hokoff, a comprehensive set of pre-collected datasets that covers both offline rl and offline marl, accompanied by a robust framework, to facilitate further research. this data is derived from honor of kings, a recognized multiplayer online battle arena (moba) game known for its intricate nature, closely resembling real-life situations. utilizing this framework, we benchmark a variety of offline rl and offline marl algorithms. we also introduce a novel baseline algorithm tailored for the inherent hierarchical action space of the game. we reveal the incompetency of current offline rl approaches in handling task complexity, generalization and multi-task learning.",,2024-08-20,,"['yun qu', 'boyuan wang', 'jianzhun shao', 'yuhang jiang', 'chen chen', 'zhenbin ye', 'lin liu', 'junfeng yang', 'lin lai', 'hongyang qin', 'minwen deng', 'juchao zhuo', 'deheng ye', 'qiang fu', 'wei yang', 'guang yang', 'lanxiao huang', 'xiangyang ji']"
1607,2408.10557,speech representation learning revisited: the necessity of separate   learnable parameters and robust data augmentation,cs.cl,"speech modeling methods learn one embedding for a fixed segment of speech, typically in between 10-25 ms. the information present in speech can be divided into two categories: ""what is being said"" (content) and ""how it is expressed"" (other) and these two are orthogonal in nature causing the optimization algorithm to find a sub-optimal solution if forced to optimize together. this leads to sub-optimal performance in one or all downstream tasks as shown by previous studies. current self-supervised learning (ssl) methods such as hubert are very good at modeling the content information present in speech. data augmentation improves the performance on tasks which require effective modeling of other information but this leads to a divided capacity of the model. in this work, we conduct a preliminary study to understand the importance of modeling other information using separate learnable parameters. we propose a modified version of hubert, termed other hubert (o-hubert), to test our hypothesis. our findings are twofold: first, the o-hubert method is able to utilize all layers to build complex features to encode other information; second, a robust data augmentation strategy is essential for learning the information required by tasks that depend on other information and to achieve state-of-the-art (sota) performance on the superb benchmark with a similarly sized model (100 million parameters) and pre-training data (960 hours).",,2024-08-20,,"['hemant yadav', 'sunayana sitaram', 'rajiv ratn shah']"
1608,2408.10561,icsd: an open-source dataset for infant cry and snoring detection,cs.sd eess.as,"the detection and analysis of infant cry and snoring events are crucial tasks within the field of audio signal processing. while existing datasets for general sound event detection are plentiful, they often fall short in providing sufficient, strongly labeled data specific to infant cries and snoring. to provide a benchmark dataset and thus foster the research of infant cry and snoring detection, this paper introduces the infant cry and snoring detection (icsd) dataset, a novel, publicly available dataset specially designed for icsd tasks. the icsd comprises three types of subsets: a real strongly labeled subset with event-based labels annotated manually, a weakly labeled subset with only clip-level event annotations, and a synthetic subset generated and labeled with strong annotations. this paper provides a detailed description of the icsd creation process, including the challenges encountered and the solutions adopted. we offer a comprehensive characterization of the dataset, discussing its limitations and key factors for icsd usage. additionally, we conduct extensive experiments on the icsd dataset to establish baseline systems and offer insights into the main factors when using this dataset for icsd research. our goal is to develop a dataset that will be widely adopted by the community as a new open benchmark for future icsd research.",,2024-08-20,,"['qingyu liu', 'longfei song', 'dongxing xu', 'yanhua long']"
1609,2408.10562,kalib: markerless hand-eye calibration with keypoint tracking,cs.ro cs.cv,"hand-eye calibration involves estimating the transformation between the camera and the robot. traditional methods rely on fiducial markers, involving much manual labor and careful setup. recent advancements in deep learning offer markerless techniques, but they present challenges, including the need for retraining networks for each robot, the requirement of accurate mesh models for data generation, and the need to address the sim-to-real gap. in this letter, we propose kalib, an automatic and universal markerless hand-eye calibration pipeline that leverages the generalizability of visual foundation models to eliminate these barriers. in each calibration process, kalib uses keypoint tracking and proprioceptive sensors to estimate the transformation between a robot's coordinate space and its corresponding points in camera space. our method does not require training new networks or access to mesh models. through evaluations in simulation environments and the real-world dataset droid, kalib demonstrates superior accuracy compared to recent baseline methods. this approach provides an effective and flexible calibration process for various robot systems by simplifying setup and removing dependency on precise physical markers.",,2024-08-20,,"['tutian tang', 'minghao liu', 'wenqiang xu', 'cewu lu']"
1610,2408.10563,the stable model semantics for higher-order logic programming,cs.lo cs.ai cs.pl,"we propose a stable model semantics for higher-order logic programs. our semantics is developed using approximation fixpoint theory (aft), a powerful formalism that has successfully been used to give meaning to diverse non-monotonic formalisms. the proposed semantics generalizes the classical two-valued stable model semantics of (gelfond and lifschitz 1988) as-well-as the three-valued one of (przymusinski 1990), retaining their desirable properties. due to the use of aft, we also get for free alternative semantics for higher-order logic programs, namely supported model, kripke-kleene, and well-founded. additionally, we define a broad class of stratified higher-order logic programs and demonstrate that they have a unique two-valued higher-order stable model which coincides with the well-founded semantics of such programs. we provide a number of examples in different application domains, which demonstrate that higher-order logic programming under the stable model semantics is a powerful and versatile formalism, which can potentially form the basis of novel asp systems.",,2024-08-20,,"['bart bogaerts', 'angelos charalambidis', 'giannos chatziagapis', 'babis kostopoulos', 'samuele pollaci', 'panos rondogiannis']"
1611,2408.10564,fault tolerant dynamic task assignment for uav-based search teams,eess.sy cs.sy,"this research offers a novel framework for dynamic task assignment for unmanned aerial vehicles (uavs) in cooperative search settings. notably, it incorporates post-fault uav capabilities into job assignment techniques, assuring operational dependability in the event of sensor and actuator failures. a significant innovation is the utilization of uav battery charge to assess range relative to search objectives, hence improving job distribution while conserving battery life. this model integrates repair, recharge, and stochastic goal recurrence, hence increasing its real-world applicability. using stochastic dynamic programming, this method makes it simpler to determine optimal assignment policies offline so they may be implemented rapidly online. this paper emphasizes the holistic aspect of the proposed model, which connects high-level task rules to low-level control capabilities. a simulation-based case study proves its usefulness, highlighting its robustness in fault-prone and battery-variable settings. overall, this paper proposes and demonstrates a comprehensive method for assigning uav tasks that integrates defect awareness, battery management, and multilayer control through the use of stochastic dynamic programming.",,2024-08-20,,"['ali nasir', 'mohammad aldurgam']"
1612,2408.10566,sparsegrow: addressing growth-induced forgetting in task-agnostic   continual learning,cs.lg cs.ai,"in continual learning (cl), model growth enhances adaptability over new data, improving knowledge retention for more tasks. however, improper model growth can lead to severe degradation of previously learned knowledge, an issue we name as growth-induced forgetting (gift), especially in task-agnostic cl using entire grown model for inference. existing works, despite adopting model growth and random initialization for better adaptability, often fail to recognize the presence of gift caused by improper model growth. this oversight limits comprehensive control of forgetting and hinders full utilization of model growth. we are the first in cl to identify this issue and conduct an in-depth study on root cause of gift, where layer expansion stands out among model growth strategies, widening layers without affecting model functionality. yet, direct adoption of layer expansion presents challenges. it lacks data-driven control and initialization of expanded parameters to balance adaptability and knowledge retention. this paper presents a novel sparsegrow approach to overcome the issue of gift while enhancing adaptability over new data. sparsegrow employs data-driven sparse layer expansion to control efficient parameter usage during growth, reducing gift from excessive growth and functionality changes. it also combines sparse growth with on-data initialization at training late-stage to create partially 0-valued expansions that fit learned distribution, enhancing retention and adaptability. to further minimize forgetting, freezing is applied by calculating the sparse mask, allowing data-driven preservation of important parameters. through experiments across datasets with various settings, cases and task numbers, we demonstrate the necessity of layer expansion and showcase the effectiveness of sparsegrow in overcoming gift, highlighting its adaptability and knowledge retention for incremental tasks.",,2024-08-20,,"['yuqing zhao', 'divya saxena', 'jiannong cao', 'xiaoyun liu', 'changlin song']"
1613,2408.10567,prompt your brain: scaffold prompt tuning for efficient adaptation of   fmri pre-trained model,q-bio.nc cs.ai cs.cv cs.lg,"we introduce scaffold prompt tuning (scapt), a novel prompt-based framework for adapting large-scale functional magnetic resonance imaging (fmri) pre-trained models to downstream tasks, with high parameter efficiency and improved performance compared to fine-tuning and baselines for prompt tuning. the full fine-tuning updates all pre-trained parameters, which may distort the learned feature space and lead to overfitting with limited training data which is common in fmri fields. in contrast, we design a hierarchical prompt structure that transfers the knowledge learned from high-resource tasks to low-resource ones. this structure, equipped with a deeply-conditioned input-prompt (dip) mapping module, allows for efficient adaptation by updating only 2% of the trainable parameters. the framework enhances semantic interpretability through attention mechanisms between inputs and prompts, and it clusters prompts in the latent space in alignment with prior knowledge. experiments on public resting state fmri datasets reveal scapt outperforms fine-tuning and multitask-based prompt tuning in neurodegenerative diseases diagnosis/prognosis and personality trait prediction, even with fewer than 20 participants. it highlights scapt's efficiency in adapting pre-trained fmri models to low-resource tasks.",,2024-08-20,,"['zijian dong', 'yilei wu', 'zijiao chen', 'yichi zhang', 'yueming jin', 'juan helen zhou']"
1614,2408.10568,constrained behavior cloning for robotic learning,cs.ro,"behavior cloning (bc) is a popular supervised imitation learning method in the societies of robotics, autonomous driving, etc., wherein complex skills can be learned by direct imitation from expert demonstrations. despite its rapid development, it is still affected by limited field of view where accumulation of sensors and joint noise bring compounding errors. in this paper, we introduced geometrically and historically constrained behavior cloning (ghcbc) to dominantly consider high-level state information inspired by neuroscientists, wherein the geometrically constrained behavior cloning were used to geometrically constrain predicting poses, and the historically constrained behavior cloning were utilized to temporally constrain action sequences. the synergy between these two types of constrains enhanced the bc performance in terms of robustness and stability. comprehensive experimental results showed that success rates were improved by 29.73% in simulation and 39.4% in real robot experiments in average, respectively, compared to state-of-the-art bc method, especially in long-term operational scenes, indicating great potential of using the ghcbc for robotic learning.",,2024-08-20,,"['wensheng liang', 'jun xie', 'zhicheng wang', 'jianwei tan', 'xiaoguang ma']"
1615,2408.10569,navigating dimensionality through state machines in automotive system   validation,cs.ro,"the increasing automation of vehicles is resulting in the integration of more extensive in-vehicle sensor systems, electronic control units, and software. additionally, vehicle-to-everything communication is seen as an opportunity to extend automated driving capabilities through information from a source outside the ego vehicle. however, the validation and verification of automated driving functions already pose a challenge due to the number of possible scenarios that can occur for a driving function, which makes it difficult to achieve comprehensive test coverage. currently, the establishment of safety of the intended functionality ( sotif ) mandates the implementation of scenario-based testing. the introduction of additional external systems through vehicle-to-everything further complicates the problem and increases the scenario space. in this paper, a methodology based on state charts is proposed for modeling the interaction with external systems, which may remain as black boxes. this approach leverages the testability and coverage analysis inherent in state charts by combining them with scenario-based testing. the overall objective is to reduce the space of scenarios necessary for testing a networked driving function and to streamline validation and verification. the utilization of this approach is demonstrated using a simulated signalized intersection with a roadside unit that detects vulnerable road users.",,2024-08-20,,"['laurenz adolph', 'barbara schütt', 'david kraus', 'eric sax']"
1616,2408.10571,prompt-agnostic adversarial perturbation for customized diffusion models,cs.cv cs.ai,"diffusion models have revolutionized customized text-to-image generation, allowing for efficient synthesis of photos from personal data with textual descriptions. however, these advancements bring forth risks including privacy breaches and unauthorized replication of artworks. previous researches primarily center around using prompt-specific methods to generate adversarial examples to protect personal images, yet the effectiveness of existing methods is hindered by constrained adaptability to different prompts. in this paper, we introduce a prompt-agnostic adversarial perturbation (pap) method for customized diffusion models. pap first models the prompt distribution using a laplace approximation, and then produces prompt-agnostic perturbations by maximizing a disturbance expectation based on the modeled distribution. this approach effectively tackles the prompt-agnostic attacks, leading to improved defense stability. extensive experiments in face privacy and artistic style protection, demonstrate the superior generalization of our method in comparison to existing techniques.",,2024-08-20,,"['cong wan', 'yuhang he', 'xiang song', 'yihong gong']"
1617,2408.10572,a tutorial on explainable image classification for dementia stages using   convolutional neural network and gradient-weighted class activation mapping,eess.iv cs.ai cs.cv,"this paper presents a tutorial of an explainable approach using convolutional neural network (cnn) and gradient-weighted class activation mapping (grad-cam) to classify four progressive dementia stages based on open mri brain images. the detailed implementation steps are demonstrated with an explanation. whilst the proposed cnn architecture is demonstrated to achieve more than 99% accuracy for the test dataset, the computational procedure of cnn remains a black box. the visualisation based on grad-cam is attempted to explain such very high accuracy and may provide useful information for physicians. future motivation based on this work is discussed.",,2024-08-20,,['kevin kam fung yuen']
1618,2408.10573,putting people in llms' shoes: generating better answers via question   rewriter,cs.cl cs.ai,"large language models (llms) have demonstrated significant capabilities, particularly in the domain of question answering (qa). however, their effectiveness in qa is often undermined by the vagueness of user questions. to address this issue, we introduce single-round instance-level prompt optimization, referred to as question rewriter. by enhancing the intelligibility of human questions for black-box llms, our question rewriter improves the quality of generated answers. the rewriter is optimized using direct preference optimization based on feedback collected from automatic criteria for evaluating generated answers; therefore, its training does not require costly human annotations. the experiments across multiple black-box llms and long-form question answering (lfqa) datasets demonstrate the efficacy of our method. this paper provides a practical framework for training question rewriters and sets a precedent for future explorations in prompt optimization within lfqa tasks. code is available at \url{https://github.com/3244we/question-rewriter}.",,2024-08-20,,"['junhao chen', 'bowen wang', 'zhouqiang jiang', 'yuta nakashima']"
1619,2408.10575,muse: mamba is efficient multi-scale learner for text-video retrieval,cs.cv,"text-video retrieval (tvr) aims to align and associate relevant video content with corresponding natural language queries. most existing tvr methods are based on large-scale pre-trained vision-language models (e.g., clip). however, due to the inherent plain structure of clip, few tvr methods explore the multi-scale representations which offer richer contextual information for a more thorough understanding. to this end, we propose muse, a multi-scale mamba with linear computational complexity for efficient cross-resolution modeling. specifically, the multi-scale representations are generated by applying a feature pyramid on the last single-scale feature map. then, we employ the mamba structure as an efficient multi-scale learner to jointly learn scale-wise representations. furthermore, we conduct comprehensive studies to investigate different model structures and designs. extensive results on three popular benchmarks have validated the superiority of muse.",,2024-08-20,,"['haoran tang', 'meng cao', 'jinfa huang', 'ruyang liu', 'peng jin', 'ge li', 'xiaodan liang']"
1620,2408.10577,optimizing large language model hyperparameters for code generation,cs.se,"large language models (llms), such as gpt models, are increasingly used in software engineering for various tasks, such as code generation, requirements management, and debugging. while automating these tasks has garnered significant attention, a systematic study on the impact of varying hyperparameters on code generation outcomes remains unexplored. this study aims to assess llms' code generation performance by exhaustively exploring the impact of various hyperparameters. hyperparameters for llms are adjustable settings that affect the model's behaviour and performance. specifically, we investigated how changes to the hyperparameters: temperature, top probability (top_p), frequency penalty, and presence penalty affect code generation outcomes. we systematically adjusted all hyperparameters together, exploring every possible combination by making small increments to each hyperparameter at a time. this exhaustive approach was applied to 13 python code generation tasks, yielding one of four outcomes for each hyperparameter combination: no output from the llm, non executable code, code that fails unit tests, or correct and functional code. we analysed these outcomes for a total of 14,742 generated python code segments, focusing on correctness, to determine how the hyperparameters influence the llm to arrive at each outcome. using correlation coefficient and regression tree analyses, we ascertained which hyperparameters influence which aspect of the llm. our results indicate that optimal performance is achieved with a temperature below 0.5, top probability below 0.75, frequency penalty above -1 and below 1.5, and presence penalty above -1. we make our dataset and results available to facilitate replication.",,2024-08-20,,"['chetan arora', 'ahnaf ibn sayeed', 'sherlock licorish', 'fanyu wang', 'christoph treude']"
1621,2408.10578,where to fetch: extracting visual scene representation from large   pre-trained models for robotic goal navigation,cs.ro,"to complete a complex task where a robot navigates to a goal object and fetches it, the robot needs to have a good understanding of the instructions and the surrounding environment. large pre-trained models have shown capabilities to interpret tasks defined via language descriptions. however, previous methods attempting to integrate large pre-trained models with daily tasks are not competent in many robotic goal navigation tasks due to poor understanding of the environment. in this work, we present a visual scene representation built with large-scale visual language models to form a feature representation of the environment capable of handling natural language queries. combined with large language models, this method can parse language instructions into action sequences for a robot to follow, and accomplish goal navigation with querying the scene representation. experiments demonstrate that our method enables the robot to follow a wide range of instructions and complete complex goal navigation tasks.",,2024-08-20,,"['yu li', 'dayou li', 'chenkun zhao', 'ruifeng wang', 'ran song', 'wei zhang']"
1622,2408.1058,a passivity-based variable impedance controller for incremental learning   of periodic interactive tasks,cs.ro,"in intelligent manufacturing, robots are asked to dynamically adapt their behaviours without reducing productivity. human teaching, where an operator physically interacts with the robot to demonstrate a new task, is a promising strategy to quickly and intuitively reconfigure the production line. however, physical guidance during task execution poses challenges in terms of both operator safety and system usability. in this paper, we solve this issue by designing a variable impedance control strategy that regulates the interaction with the environment and the physical demonstrations, explicitly preventing at the same time passivity violations. we derive constraints to limit not only the exchanged energy with the environment but also the exchanged power, resulting in smoother interactions. by monitoring the energy flow between the robot and the environment, we are able to distinguish between disturbances (to be rejected) and physical guidance (to be accomplished), enabling smooth and controlled transitions from teaching to execution and vice versa. the effectiveness of the proposed approach is validated in wiping tasks with a real robotic manipulator.",,2024-08-20,,"['matteo dalle vedove', 'edoardo lamon', 'daniele fontanelli', 'luigi palopoli', 'matteo saveriano']"
1623,2408.10581,multi-view hand reconstruction with a point-embedded transformer,cs.cv,"this work introduces a novel and generalizable multi-view hand mesh reconstruction (hmr) model, named poem, designed for practical use in real-world hand motion capture scenarios. the advances of the poem model consist of two main aspects. first, concerning the modeling of the problem, we propose embedding a static basis point within the multi-view stereo space. a point represents a natural form of 3d information and serves as an ideal medium for fusing features across different views, given its varied projections across these views. consequently, our method harnesses a simple yet effective idea: a complex 3d hand mesh can be represented by a set of 3d basis points that 1) are embedded in the multi-view stereo, 2) carry features from the multi-view images, and 3) encompass the hand in it. the second advance lies in the training strategy. we utilize a combination of five large-scale multi-view datasets and employ randomization in the number, order, and poses of the cameras. by processing such a vast amount of data and a diverse array of camera configurations, our model demonstrates notable generalizability in the real-world applications. as a result, poem presents a highly practical, plug-and-play solution that enables user-friendly, cost-effective multi-view motion capture for both left and right hands. the model and source codes are available at https://github.com/jubsteven/poem-v2.",,2024-08-20,,"['lixin yang', 'licheng zhong', 'pengxiang zhu', 'xinyu zhan', 'junxiao kong', 'jian xu', 'cewu lu']"
1624,2408.10588,degas: detailed expressions on full-body gaussian avatars,cs.cv cs.gr,"although neural rendering has made significant advancements in creating lifelike, animatable full-body and head avatars, incorporating detailed expressions into full-body avatars remains largely unexplored. we present degas, the first 3d gaussian splatting (3dgs)-based modeling method for full-body avatars with rich facial expressions. trained on multiview videos of a given subject, our method learns a conditional variational autoencoder that takes both the body motion and facial expression as driving signals to generate gaussian maps in the uv layout. to drive the facial expressions, instead of the commonly used 3d morphable models (3dmms) in 3d head avatars, we propose to adopt the expression latent space trained solely on 2d portrait images, bridging the gap between 2d talking faces and 3d avatars. leveraging the rendering capability of 3dgs and the rich expressiveness of the expression latent space, the learned avatars can be reenacted to reproduce photorealistic rendering images with subtle and accurate facial expressions. experiments on an existing dataset and our newly proposed dataset of full-body talking avatars demonstrate the efficacy of our method. we also propose an audio-driven extension of our method with the help of 2d talking faces, opening new possibilities to interactive ai agents.",,2024-08-20,,"['zhijing shao', 'duotun wang', 'qing-yao tian', 'yao-dong yang', 'hengyu meng', 'zeyu cai', 'bo dong', 'yu zhang', 'kang zhang', 'zeyu wang']"
1625,2408.10589,bidirectional intent communication: a role for large foundation models,cs.ro cs.hc,"integrating multimodal foundation models has significantly enhanced autonomous agents' language comprehension, perception, and planning capabilities. however, while existing works adopt a \emph{task-centric} approach with minimal human interaction, applying these models to developing assistive \emph{user-centric} robots that can interact and cooperate with humans remains underexplored. this paper introduces ``bident'', a framework designed to integrate robots seamlessly into shared spaces with humans. bident enhances the interactive experience by incorporating multimodal inputs like speech and user gaze dynamics. furthermore, bident supports verbal utterances and physical actions like gestures, making it versatile for bidirectional human-robot interactions. potential applications include personalized education, where robots can adapt to individual learning styles and paces, and healthcare, where robots can offer personalized support, companionship, and everyday assistance in the home and workplace environments.",,2024-08-20,,"['tim schreiter', 'rishi hazra', 'jens rüppel', 'andrey rudenko']"
1626,2408.10592,hologram reasoning for solving algebra problems with geometry diagrams,cs.ai cs.cg cs.lo,"solving algebra problems with geometry diagrams (apgds) is still a challenging problem because diagram processing is not studied as intensively as language processing. to work against this challenge, this paper proposes a hologram reasoning scheme and develops a high-performance method for solving apgds by using this scheme. to reach this goal, it first defines a hologram, being a kind of graph, and proposes a hologram generator to convert a given apgd into a hologram, which represents the entire information of apgd and the relations for solving the problem can be acquired from it by a uniform way. then hgr, a hologram reasoning method employs a pool of prepared graph models to derive algebraic equations, which is consistent with the geometric theorems. this method is able to be updated by adding new graph models into the pool. lastly, it employs deep reinforcement learning to enhance the efficiency of model selection from the pool. the entire hgr not only ensures high solution accuracy with fewer reasoning steps but also significantly enhances the interpretability of the solution process by providing descriptions of all reasoning steps. experimental results demonstrate the effectiveness of hgr in improving both accuracy and interpretability in solving apgds.",,2024-08-20,,"['litian huang', 'xinguo yu', 'feng xiong', 'bin he', 'shengbing tang', 'jiawen fu']"
1627,2408.10593,an efficient sign language translation using spatial configuration and   motion dynamics with llms,cs.cl cs.cv,"gloss-free sign language translation (slt) converts sign videos directly into spoken language sentences without relying on glosses. recently, large language models (llms) have shown remarkable translation performance in gloss-free methods by harnessing their powerful natural language generation capabilities. however, these methods often rely on domain-specific fine-tuning of visual encoders to achieve optimal results. by contrast, this paper emphasizes the importance of capturing the spatial configurations and motion dynamics inherent in sign language. with this in mind, we introduce spatial and motion-based sign language translation (spamo), a novel llm-based slt framework. the core idea of spamo is simple yet effective. we first extract spatial and motion features using off-the-shelf visual encoders and then input these features into an llm with a language prompt. additionally, we employ a visual-text alignment process as a warm-up before the slt supervision. our experiments demonstrate that spamo achieves state-of-the-art performance on two popular datasets, phoenix14t and how2sign.",,2024-08-20,,"['eui jun hwang', 'sukmin cho', 'junmyeong lee', 'jong c. park']"
1628,2408.10594,design and implementation of a takum arithmetic hardware codec in vhdl,cs.ar,"the takum machine number format has been recently proposed as an enhancement over the posit number format, which is considered a promising alternative to the ieee 754 floating-point standard. takums retain the useful posit properties, but feature a novel exponent coding scheme that yields more precision for small and large magnitude numbers. takum's dynamic range is larger and bounded, as reflected in its name, derived from the icelandic 'takmarka{\dh} umfang', meaning 'limited range'. consequently, the selection of bit string lengths becomes determined solely by precision requirements and independent of dynamic range considerations. takum is defined in both a logarithmic number system (lns) format and a traditional floating-point format.   this paper presents the design and implementation of a hardware codec for both the logarithmic and floating-point takum formats. the design primarily focuses on the codec, as both formats share a common internal arithmetic representation. non-essential aspects of current posit designs, such as fused or pipelined architectures and the choice of floating-point ip cores, are thus omitted. the proposed takum codec, implemented in vhdl, demonstrates near-optimal scalability and performance on an fpga, matching or exceeding state-of-the-art posit codecs in terms of both latency and lut utilisation.",,2024-08-20,,['laslo hunhold']
1629,2408.10595,synchronization behind learning in periodic zero-sum games triggers   divergence from nash equilibrium,cs.gt cs.ma math.oc nlin.cd,"learning in zero-sum games studies a situation where multiple agents competitively learn their strategy. in such multi-agent learning, we often see that the strategies cycle around their optimum, i.e., nash equilibrium. when a game periodically varies (called a ``periodic'' game), however, the nash equilibrium moves generically. how learning dynamics behave in such periodic games is of interest but still unclear. interestingly, we discover that the behavior is highly dependent on the relationship between the two speeds at which the game changes and at which players learn. we observe that when these two speeds synchronize, the learning dynamics diverge, and their time-average does not converge. otherwise, the learning dynamics draw complicated cycles, but their time-average converges. under some assumptions introduced for the dynamical systems analysis, we prove that this behavior occurs. furthermore, our experiments observe this behavior even if removing these assumptions. this study discovers a novel phenomenon, i.e., synchronization, and gains insight widely applicable to learning in periodic games.",,2024-08-20,,"['yuma fujimoto', 'kaito ariu', 'kenshi abe']"
1630,2408.10596,fast collective evasion in self-localized swarms of unmanned aerial   vehicles,cs.ro,"a novel approach for achieving fast evasion in self-localized swarms of unmanned aerial vehicles (uavs) threatened by an intruding moving object is presented in this paper. motivated by natural self-organizing systems, the presented approach of fast and collective evasion enables the uav swarm to avoid dynamic objects (interferers) that are actively approaching the group. the main objective of the proposed technique is the fast and safe escape of the swarm from an interferer ~discovered in proximity. this method is inspired by the collective behavior of groups of certain animals, such as schools of fish or flocks of birds. these animals use the limited information of their sensing organs and decentralized control to achieve reliable and effective group motion. the system presented in this paper is intended to execute the safe coordination of uav swarms with a large number of agents. similar to natural swarms, this system propagates a fast shock of information about detected interferers throughout the group to achieve dynamic and collective evasion. the proposed system is fully decentralized using only onboard sensors to mutually localize swarm agents and interferers, similar to how animals accomplish this behavior. as a result, the communication structure between swarm agents is not overwhelmed by information about the state (position and velocity) of each individual and it is reliable to communication dropouts. the proposed system and theory were numerically evaluated and verified in real-world experiments.",10.1088/1748-3190/ac3060,2024-08-20,,"['filip novák', 'viktor walter', 'pavel petráček', 'tomáš báča', 'martin saska']"
1631,2408.10599,vision calorimeter for anti-neutron reconstruction: a baseline,hep-ex cs.cv,"in high-energy physics, anti-neutrons ($\bar{n}$) are fundamental particles that frequently appear as final-state particles, and the reconstruction of their kinematic properties provides an important probe for understanding the governing principles. however, this confronts significant challenges instrumentally with the electromagnetic calorimeter (emc), a typical experimental sensor but recovering the information of incident $\bar{n}$ insufficiently. in this study, we introduce vision calorimeter (vic), a baseline method for anti-neutron reconstruction that leverages deep learning detectors to analyze the implicit relationships between emc responses and incident $\bar{n}$ characteristics. our motivation lies in that energy distributions of $\bar{n}$ samples deposited in the emc cell arrays embody rich contextual information. converted to 2-d images, such contextual energy distributions can be used to predict the status of $\bar{n}$ ($i.e.$, incident position and momentum) through a deep learning detector along with pseudo bounding boxes and a specified training objective. experimental results demonstrate that vic substantially outperforms the conventional reconstruction approach, reducing the prediction error of incident position by 42.81% (from 17.31$^{\circ}$ to 9.90$^{\circ}$). more importantly, this study for the first time realizes the measurement of incident $\bar{n}$ momentum, underscoring the potential of deep learning detectors for particle reconstruction. code is available at https://github.com/yuhongtian17/vic.",,2024-08-20,,"['hongtian yu', 'yangu li', 'mingrui wu', 'letian shen', 'yue liu', 'yunxuan song', 'qixiang ye', 'xiaorui lyu', 'yajun mao', 'yangheng zheng', 'yunfan liu']"
1632,2408.106,breast tumor classification based on self-supervised contrastive   learning from ultrasound videos,cs.cv cs.ai,"background: breast ultrasound is prominently used in diagnosing breast tumors. at present, many automatic systems based on deep learning have been developed to help radiologists in diagnosis. however, training such systems remains challenging because they are usually data-hungry and demand amounts of labeled data, which need professional knowledge and are expensive. methods: we adopted a triplet network and a self-supervised contrastive learning technique to learn representations from unlabeled breast ultrasound video clips. we further designed a new hard triplet loss to to learn representations that particularly discriminate positive and negative image pairs that are hard to recognize. we also constructed a pretraining dataset from breast ultrasound videos (1,360 videos from 200 patients), which includes an anchor sample dataset with 11,805 images, a positive sample dataset with 188,880 images, and a negative sample dataset dynamically generated from video clips. further, we constructed a finetuning dataset, including 400 images from 66 patients. we transferred the pretrained network to a downstream benign/malignant classification task and compared the performance with other state-of-the-art models, including three models pretrained on imagenet and a previous contrastive learning model retrained on our datasets. results and conclusion: experiments revealed that our model achieved an area under the receiver operating characteristic curve (auc) of 0.952, which is significantly higher than the others. further, we assessed the dependence of our pretrained model on the number of labeled data and revealed that <100 samples were required to achieve an auc of 0.901. the proposed framework greatly reduces the demand for labeled data and holds potential for use in automatic breast ultrasound image diagnosis.",,2024-08-20,,"['yunxin tang', 'siyuan tang', 'jian zhang', 'hao chen']"
1633,2408.10602,mv-mos: multi-view feature fusion for 3d moving object segmentation,cs.cv cs.ai,"effectively summarizing dense 3d point cloud data and extracting motion information of moving objects (moving object segmentation, mos) is crucial to autonomous driving and robotics applications. how to effectively utilize motion and semantic features and avoid information loss during 3d-to-2d projection is still a key challenge. in this paper, we propose a novel multi-view mos model (mv-mos) by fusing motion-semantic features from different 2d representations of point clouds. to effectively exploit complementary information, the motion branches of the proposed model combines motion features from both bird's eye view (bev) and range view (rv) representations. in addition, a semantic branch is introduced to provide supplementary semantic features of moving objects. finally, a mamba module is utilized to fuse the semantic features with motion features and provide effective guidance for the motion branches. we validated the effectiveness of the proposed multi-branch fusion mos framework via comprehensive experiments, and our proposed model outperforms existing state-of-the-art models on the semantickitti benchmark.",,2024-08-20,,"['jintao cheng', 'xingming chen', 'jinxin liang', 'xiaoyu tang', 'xieyuanli chen', 'dachuan li']"
1634,2408.10604,multilingual non-factoid question answering with silver answers,cs.cl cs.ai cs.ir cs.lg,"most existing question answering datasets (quads) primarily focus on factoid-based short-context question answering (qa) in high-resource languages. however, the scope of such datasets for low-resource languages remains limited, with only a few works centered on factoid-based quads and none on non-factoid quads. therefore, this work presents munfquad, a multilingual quad with non-factoid questions. it utilizes interrogative sub-headings from bbc news articles as questions and the corresponding paragraphs as silver answers. the dataset comprises over 370k qa pairs across 38 languages, encompassing several low-resource languages, and stands as the largest multilingual qa dataset to date. based on the manual annotations of 790 qa-pairs from munfquad (golden set), we observe that 98\% of questions can be answered using their corresponding silver answer. our fine-tuned answer paragraph selection (aps) model outperforms the baselines. the aps model attained an accuracy of 80\% and 72\%, as well as a macro f1 of 72\% and 66\%, on the munfquad testset and the golden set, respectively. furthermore, the aps model effectively generalizes certain a language within the golden set, even after being fine-tuned on silver labels.",,2024-08-20,,"['ritwik mishra', 'sreeram vennam', 'rajiv ratn shah', 'ponnurangam kumaraguru']"
1635,2408.10608,promoting equality in large language models: identifying and mitigating   the implicit bias based on bayesian theory,cs.cl cs.ai,"large language models (llms) are trained on extensive text corpora, which inevitably include biased information. although techniques such as affective alignment can mitigate some negative impacts of these biases, existing prompt-based attack methods can still extract these biases from the model's weights. moreover, these biases frequently appear subtly when llms are prompted to perform identical tasks across different demographic groups, thereby camouflaging their presence. to address this issue, we have formally defined the implicit bias problem and developed an innovative framework for bias removal based on bayesian theory, bayesian-theory based bias removal (btbr). btbr employs likelihood ratio screening to pinpoint data entries within publicly accessible biased datasets that represent biases inadvertently incorporated during the llm training phase. it then automatically constructs relevant knowledge triples and expunges bias information from llms using model editing techniques. through extensive experimentation, we have confirmed the presence of the implicit bias problem in llms and demonstrated the effectiveness of our btbr approach.",,2024-08-20,,"['yongxin deng', 'xihe qiu', 'xiaoyu tan', 'jing pan', 'chen jue', 'zhijun fang', 'yinghui xu', 'wei chu', 'yuan qi']"
1636,2408.10609,perturbench: benchmarking machine learning models for cellular   perturbation analysis,cs.lg q-bio.gn stat.ml,"we present a comprehensive framework for predicting the effects of perturbations in single cells, designed to standardize benchmarking in this rapidly evolving field. our framework, perturbench, includes a user-friendly platform, diverse datasets, metrics for fair model comparison, and detailed performance analysis. extensive evaluations of published and baseline models reveal limitations like mode or posterior collapse, and underscore the importance of rank metrics that assess the ordering of perturbations alongside traditional measures like rmse. our findings show that simple models can outperform more complex approaches. this benchmarking exercise sets new standards for model evaluation, supports robust model development, and advances the potential of these models to use high-throughput and high-content genetic and chemical screens for disease target discovery.",,2024-08-20,,"['yan wu', 'esther wershof', 'sebastian m schmon', 'marcel nassar', 'błażej osiński', 'ridvan eksi', 'kun zhang', 'thore graepel']"
1637,2408.1061,on the approximability of stationary processes using the arma model,cs.lg math.pr stat.me,"we identify certain gaps in the literature on the approximability of stationary random variables using the autoregressive moving average (arma) model. to quantify approximability, we propose that an arma model be viewed as an approximation of a stationary random variable. we map these stationary random variables to hardy space functions, and formulate a new function approximation problem that corresponds to random variable approximation, and thus to arma. based on this hardy space formulation we identify a class of stationary processes where approximation guarantees are feasible. we also identify an idealized stationary random process for which we conjecture that a good arma approximation is not possible. next, we provide a constructive proof that pad\'e approximations do not always correspond to the best arma approximation. finally, we note that the spectral methods adopted in this paper can be seen as a generalization of unit root methods for stationary processes even when an arma model is not defined.",,2024-08-20,,"['anand ganesh', 'babhrubahan bose', 'anand rajagopalan']"
1638,2408.10613,task-level distributionally robust optimization for large language   model-based dense retrieval,cs.ir,"large language model-based dense retrieval (llm-dr) optimizes over numerous heterogeneous fine-tuning collections from different domains. however, the discussion about its training data distribution is still minimal. previous studies rely on empirically assigned dataset choices or sampling ratios, which inevitably leads to sub-optimal retrieval performances. in this paper, we propose a new task-level distributionally robust optimization (tdro) algorithm for llm-dr fine-tuning, targeted at improving the universal domain generalization ability by end-to-end reweighting the data distribution of each task. the tdro parameterizes the domain weights and updates them with scaled domain gradients. the optimized weights are then transferred to the llm-dr fine-tuning to train more robust retrievers. experiments show optimal improvements in large-scale retrieval benchmarks and reduce up to 30% dataset usage after applying our optimization algorithm with a series of different-sized llm-dr models.",,2024-08-20,,"['guangyuan ma', 'yongliang ma', 'xing wu', 'zhenpeng su', 'ming zhou', 'songlin hu']"
1639,2408.10614,generalizable facial expression recognition,cs.cv cs.ai,"sota facial expression recognition (fer) methods fail on test sets that have domain gaps with the train set. recent domain adaptation fer methods need to acquire labeled or unlabeled samples of target domains to fine-tune the fer model, which might be infeasible in real-world deployment. in this paper, we aim to improve the zero-shot generalization ability of fer methods on different unseen test sets using only one train set. inspired by how humans first detect faces and then select expression features, we propose a novel fer pipeline to extract expression-related features from any given face images. our method is based on the generalizable face features extracted by large models like clip. however, it is non-trivial to adapt the general features of clip for specific tasks like fer. to preserve the generalization ability of clip and the high precision of the fer model, we design a novel approach that learns sigmoid masks based on the fixed clip face features to extract expression features. to further improve the generalization ability on unseen test sets, we separate the channels of the learned masked features according to the expression classes to directly generate logits and avoid using the fc layer to reduce overfitting. we also introduce a channel-diverse loss to make the learned masks separated. extensive experiments on five different fer datasets verify that our method outperforms sota fer methods by large margins. code is available in https://github.com/zyh-uaiaaaa/generalizable-fer.",,2024-08-20,,"['yuhang zhang', 'xiuqi zheng', 'chenyi liang', 'jiani hu', 'weihong deng']"
1640,2408.10615,enhancing robustness in large language models: prompting for mitigating   the impact of irrelevant information,cs.cl,"in recent years, large language models (llms) have garnered significant attention due to their superior performance in complex reasoning tasks. however, recent studies may diminish their reasoning capabilities markedly when problem descriptions contain irrelevant information, even with the use of advanced prompting techniques. to further investigate this issue, a dataset of primary school mathematics problems containing irrelevant information, named gsmir, was constructed. testing prominent llms and prompting techniques on this dataset revealed that while llms can identify irrelevant information, they do not effectively mitigate the interference it causes once identified. a novel automatic construction method, atf, which enhances the ability of llms to identify and self-mitigate the influence of irrelevant information, is proposed to address this shortcoming. this method operates in two steps: first, analysis of irrelevant information, followed by its filtering. the atf method, as demonstrated by experimental results, significantly improves the reasoning performance of llms and prompting techniques, even in the presence of irrelevant information on the gsmir dataset.",,2024-08-20,,"['ming jiang', 'tingting huang', 'biao guo', 'yao lu', 'feng zhang']"
1641,2408.10616,a toolbox for calculating objective image properties in aesthetics   research,cs.cv stat.ap,"over the past two decades, researchers in the field of visual aesthetics have studied numerous quantitative (objective) image properties and how they relate to visual aesthetic appreciation. however, results are difficult to compare between research groups. one reason is that researchers use different sets of image properties in their studies. but even if the same properties are used, the image pre-processing techniques may differ and often researchers use their own customized scripts to calculate the image properties. to provide greater accessibility and comparability of research results in visual experimental aesthetics, we developed an open-access and easy-to-use toolbox (called the 'aesthetics toolbox'). the toolbox allows users to calculate a well-defined set of quantitative image properties popular in contemporary research. the properties include lightness and color statistics, fourier spectral properties, fractality, self-similarity, symmetry, as well as different entropy measures and cnn-based variances. compatible with most devices, the toolbox provides an intuitive click-and-drop web interface. in the toolbox, we integrated the original scripts of four different research groups and translated them into python 3. to ensure that results were consistent across analyses, we took care that results from the python versions of the scripts were the same as those from the original scripts. the toolbox, detailed documentation, and a link to the cloud version are available via github: https://github.com/rbartho/aesthetics-toolbox. in summary, we developed a toolbox that helps to standardize and simplify the calculation of quantitative image properties for visual aesthetics research.",,2024-08-20,,"['christoph redies', 'ralf bartho', 'lisa koßmann', 'branka spehar', 'ronald hübner', 'johan wagemans', 'gregor u. hayn-leichsenring']"
1642,2408.10618,omega: efficient occlusion-aware navigation for air-ground robot in   dynamic environments via state space model,cs.ro cs.ai cs.cv,"air-ground robots (agrs) are widely used in surveillance and disaster response due to their exceptional mobility and versatility (i.e., flying and driving). current agr navigation systems perform well in static occlusion-prone environments (e.g., indoors) by using 3d semantic occupancy networks to predict occlusions for complete local mapping and then computing euclidean signed distance field (esdf) for path planning. however, these systems face challenges in dynamic, severe occlusion scenes (e.g., crowds) due to limitations in perception networks' low prediction accuracy and path planners' high computation overhead. in this paper, we propose omega, which contains occmamba with an efficient agr-planner to address the above-mentioned problems. occmamba adopts a novel architecture that separates semantic and occupancy prediction into independent branches, incorporating two mamba blocks within these branches. these blocks efficiently extract semantic and geometric features in 3d environments with linear complexity, ensuring that the network can learn long-distance dependencies to improve prediction accuracy. semantic and geometric features are combined within the bird's eye view (bev) space to minimise computational overhead during feature fusion. the resulting semantic occupancy map is then seamlessly integrated into the local map, providing occlusion awareness of the dynamic environment. our agr-planner utilizes this local map and employs kinodynamic a* search and gradient-based trajectory optimization to guarantee planning is esdf-free and energy-efficient. extensive experiments demonstrate that occmamba outperforms the state-of-the-art 3d semantic occupancy network with 25.0% miou. end-to-end navigation experiments in dynamic scenes verify omega's efficiency, achieving a 96% average planning success rate. code and video are available at https://jmwang0117.github.io/omega/.",,2024-08-20,,"['junming wang', 'dong huang', 'xiuxian guan', 'zekai sun', 'tianxiang shen', 'fangming liu', 'heming cui']"
1643,2408.10619,novel change detection framework in remote sensing imagery using   diffusion models and structural similarity index (ssim),cs.cv cs.ai eess.iv,"change detection is a crucial task in remote sensing, enabling the monitoring of environmental changes, urban growth, and disaster impact. conventional change detection techniques, such as image differencing and ratioing, often struggle with noise and fail to capture complex variations in imagery. recent advancements in machine learning, particularly generative models like diffusion models, offer new opportunities for enhancing change detection accuracy. in this paper, we propose a novel change detection framework that combines the strengths of stable diffusion models with the structural similarity index (ssim) to create robust and interpretable change maps. our approach, named diffusion based change detector, is evaluated on both synthetic and real-world remote sensing datasets and compared with state-of-the-art methods. the results demonstrate that our method significantly outperforms traditional differencing techniques and recent deep learning-based methods, particularly in scenarios with complex changes and noise.",,2024-08-20,,"['andrew kiruluta', 'eric lundy', 'andreas lemos']"
1644,2408.1062,fast grid emissions sensitivities using parallel decentralized implicit   differentiation,eess.sy cs.sy,"marginal emissions rates -- the sensitivity of carbon emissions to electricity demand -- are important for evaluating the impact of emissions mitigation measures. like locational marginal prices, locational marginal emissions rates (lmes) can vary geographically, even between nearby locations, and may be coupled across time periods because of, for example, storage and ramping constraints. this temporal coupling makes computing lmes computationally expensive for large electricity networks with high storage and renewable penetrations. recent work demonstrates that decentralized algorithms can mitigate this problem by decoupling timesteps during differentiation. unfortunately, we show these potential speedups are negated by the sparse structure inherent in power systems problems. we address these limitations by introducing a parallel, reverse-mode decentralized differentiation scheme that never explicitly instantiates the solution map jacobian. we show both theoretically and empirically that parallelization is necessary to achieve non-trivial speedups when computing grid emissions sensitivities. numerical results on a 500 node system indicate that our method can achieve greater than 10x speedups over centralized and serial decentralized approaches.",,2024-08-20,,"['anthony degleris', 'lucas fuentes valenzuela', 'ram rajagopal', 'marco pavone', 'abbas el gamal']"
1645,2408.10622,safety metric aware trajectory repairing for automated driving,cs.ro,"recent analyses highlight challenges in autonomous vehicle technologies, particularly failures in decision-making under dynamic or emergency conditions. traditional automated driving systems recalculate the entire trajectory in a changing environment. instead, a novel approach retains valid trajectory segments, minimizing the need for complete replanning and reducing changes to the original plan. this work introduces a trajectory repairing framework that calculates a feasible evasive trajectory while computing the feasible time-to-react (f-ttr), balancing the maintenance of the original plan with safety assurance. the framework employs a binary search algorithm to iteratively create repaired trajectories, guaranteeing both the safety and feasibility of the trajectory repairing result. in contrast to earlier approaches that separated the calculation of safety metrics from trajectory repairing, which resulted in unsuccessful plans for evasive maneuvers, our work has the anytime capability to provide both a feasible time-to-react and an evasive trajectory for further execution.",,2024-08-20,,"['kailin tong', 'berin dikic', 'wenbo xiao', 'martin steinberger', 'martin horn', 'selim solmaz']"
1646,2408.10623,textmastero: mastering high-quality scene text editing in diverse   languages and styles,cs.cv,"scene text editing aims to modify texts on images while maintaining the style of newly generated text similar to the original. given an image, a target area, and target text, the task produces an output image with the target text in the selected area, replacing the original. this task has been studied extensively, with initial success using generative adversarial networks (gans) to balance text fidelity and style similarity. however, gan-based methods struggled with complex backgrounds or text styles. recent works leverage diffusion models, showing improved results, yet still face challenges, especially with non-latin languages like cjk characters (chinese, japanese, korean) that have complex glyphs, often producing inaccurate or unrecognizable characters. to address these issues, we present \emph{textmastero} - a carefully designed multilingual scene text editing architecture based on latent diffusion models (ldms). textmastero introduces two key modules: a glyph conditioning module for fine-grained content control in generating accurate texts, and a latent guidance module for providing comprehensive style information to ensure similarity before and after editing. both qualitative and quantitative experiments demonstrate that our method surpasses all known existing works in text fidelity and style similarity.",,2024-08-20,,"['tong wang', 'xiaochao qu', 'ting liu']"
1647,2408.10624,wrim-net: wide-ranging information mining network for visible-infrared   person re-identification,cs.cv cs.ai,"for the visible-infrared person re-identification (vi-reid) task, one of the primary challenges lies in significant cross-modality discrepancy. existing methods struggle to conduct modality-invariant information mining. they often focus solely on mining singular dimensions like spatial or channel, and overlook the extraction of specific-modality multi-dimension information. to fully mine modality-invariant information across a wide range, we introduce the wide-ranging information mining network (wrim-net), which mainly comprises a multi-dimension interactive information mining (miim) module and an auxiliary-information-based contrastive learning (aicl) approach. empowered by the proposed global region interaction (gri), miim comprehensively mines non-local spatial and channel information through intra-dimension interaction. moreover, thanks to the low computational complexity design, separate miim can be positioned in shallow layers, enabling the network to better mine specific-modality multi-dimension information. aicl, by introducing the novel cross-modality key-instance contrastive (cmkic) loss, effectively guides the network in extracting modality-invariant information. we conduct extensive experiments not only on the well-known sysu-mm01 and regdb datasets but also on the latest large-scale cross-modality llcm dataset. the results demonstrate wrim-net's superiority over state-of-the-art methods.",,2024-08-20,,"['yonggan wu', 'ling-chao meng', 'yuan zichao', 'sixian chan', 'hong-qiang wang']"
1648,2408.10627,rethinking video segmentation with masked video consistency: did the   model learn as intended?,cs.cv,"video segmentation aims at partitioning video sequences into meaningful segments based on objects or regions of interest within frames. current video segmentation models are often derived from image segmentation techniques, which struggle to cope with small-scale or class-imbalanced video datasets. this leads to inconsistent segmentation results across frames. to address these issues, we propose a training strategy masked video consistency, which enhances spatial and temporal feature aggregation. mvc introduces a training strategy that randomly masks image patches, compelling the network to predict the entire semantic segmentation, thus improving contextual information integration. additionally, we introduce object masked attention (oma) to optimize the cross-attention mechanism by reducing the impact of irrelevant queries, thereby enhancing temporal modeling capabilities. our approach, integrated into the latest decoupled universal video segmentation framework, achieves state-of-the-art performance across five datasets for three video segmentation tasks, demonstrating significant improvements over previous methods without increasing model parameters.",,2024-08-20,,"['chen liang', 'qiang guo', 'xiaochao qu', 'luoqi liu', 'ting liu']"
1649,2408.10628,finding the deepdream for time series: activation maximization for   univariate time series,cs.lg cs.ai,"understanding how models process and interpret time series data remains a significant challenge in deep learning to enable applicability in safety-critical areas such as healthcare. in this paper, we introduce sequence dreaming, a technique that adapts activation maximization to analyze sequential information, aiming to enhance the interpretability of neural networks operating on univariate time series. by leveraging this method, we visualize the temporal dynamics and patterns most influential in model decision-making processes. to counteract the generation of unrealistic or excessively noisy sequences, we enhance sequence dreaming with a range of regularization techniques, including exponential smoothing. this approach ensures the production of sequences that more accurately reflect the critical features identified by the neural network. our approach is tested on a time series classification dataset encompassing applications in predictive maintenance. the results show that our proposed sequence dreaming approach demonstrates targeted activation maximization for different use cases so that either centered class or border activation maximization can be generated. the results underscore the versatility of sequence dreaming in uncovering salient temporal features learned by neural networks, thereby advancing model transparency and trustworthiness in decision-critical domains.",,2024-08-20,,"['udo schlegel', 'daniel a. keim', 'tobias sutter']"
1650,2408.10631,llm-barber: block-aware rebuilder for sparsity mask in one-shot for   large language models,cs.lg cs.ai cs.cl,"large language models (llms) have grown significantly in scale, leading to a critical need for efficient model pruning techniques. existing post-training pruning techniques primarily focus on measuring weight importance on converged dense models to determine salient weights to retain. however, they often overlook the changes in weight importance during the pruning process, which can lead to performance degradation in the pruned models. to address this issue, we present llm-barber (block-aware rebuilder for sparsity mask in one-shot), a novel one-shot pruning framework that rebuilds the sparsity mask of pruned models without any retraining or weight reconstruction. llm-barber incorporates block-aware error optimization across self-attention and mlp blocks, ensuring global performance optimization. inspired by the recent discovery of prominent outliers in llms, llm-barber introduces an innovative pruning metric that identifies weight importance using weights multiplied by gradients. our experiments show that llm-barber can efficiently prune models like llama and opt families with 7b to 13b parameters on a single a100 gpu in just 30 minutes, achieving state-of-the-art results in both perplexity and zero-shot performance across various language benchmarks. code is available at https://github.com/yupengsu/llm-barber.",,2024-08-20,,"['yupeng su', 'ziyi guan', 'xiaoqun liu', 'tianlai jin', 'dongkuan wu', 'graziano chesi', 'ngai wong', 'hao yu']"
1651,2408.10633,interactive counterfactual generation for univariate time series,cs.lg cs.hc,"we propose an interactive methodology for generating counterfactual explanations for univariate time series data in classification tasks by leveraging 2d projections and decision boundary maps to tackle interpretability challenges. our approach aims to enhance the transparency and understanding of deep learning models' decision processes. the application simplifies the time series data analysis by enabling users to interactively manipulate projected data points, providing intuitive insights through inverse projection techniques. by abstracting user interactions with the projected data points rather than the raw time series data, our method facilitates an intuitive generation of counterfactual explanations. this approach allows for a more straightforward exploration of univariate time series data, enabling users to manipulate data points to comprehend potential outcomes of hypothetical scenarios. we validate this method using the ecg5000 benchmark dataset, demonstrating significant improvements in interpretability and user understanding of time series classification. the results indicate a promising direction for enhancing explainable ai, with potential applications in various domains requiring transparent and interpretable deep learning models. future work will explore the scalability of this method to multivariate time series data and its integration with other interpretability techniques.",,2024-08-20,,"['udo schlegel', 'julius rauscher', 'daniel a. keim']"
1652,2408.10634,industry perception of security challenges with identity access   management solutions,cs.cr,"identity access management (iam) is an area posing significant challenges, particularly in the context of remote connectivity and distributed or cloud-based systems. a wide range of technical solutions have been proposed by prior research, but the integration of these solutions in the commercial sector represent steps that significantly hamper their acceptance. the study aims to outline the current perception and security issues associated with iams solutions from the perspective of the beneficiaries. the analysis relies on a series of interviews with 45 cyber security professionals from different organisations all over the world. as results showed, cloud iam solutions and on premises iam solutions are affected by different issues. the main challenges for cloud based iam solutions were default configurations, poor management of non-human identities such as service accounts, poor certificate management, poor api configuration and limited log analysis. in contrast, the challenges for on premise solutions were multi factor authentication, insecure default configurations, lack of skillsets required to manage iam solution securely, poor password policies, unpatched vulnerabilities, and compromise of single-sign on leading to compromise of multiple entities. the study also determined that, regardless the evolving functionality of cloud based iam solutions, 41% of respondents believe that the on premise solutions more secure than the cloud-based ones. as pointed out by the respondents, cloud iam may potentially expose organisations to a wider range of vulnerabilities due to the complexity of the underlying solutions, challenges with managing permissions, and compliance to dynamic iam policies.",,2024-08-20,,"['abhishek pratap singh', 'ievgeniia kuzminykh', 'bogdan ghita']"
1653,2408.10635,strategist: learning strategic skills by llms via bi-level tree search,cs.ai cs.cl,"in this paper, we propose a new method strategist that utilizes llms to acquire new skills for playing multi-agent games through a self-improvement process. our method gathers quality feedback through self-play simulations with monte carlo tree search and llm-based reflection, which can then be used to learn high-level strategic skills such as how to evaluate states that guide the low-level execution.we showcase how our method can be used in both action planning and dialogue generation in the context of games, achieving good performance on both tasks. specifically, we demonstrate that our method can help train agents with better performance than both traditional reinforcement learning-based approaches and other llm-based skill learning approaches in games including the game of pure strategy (gops) and the resistance: avalon.",,2024-08-20,,"['jonathan light', 'min cai', 'weiqin chen', 'guanzhi wang', 'xiusi chen', 'wei cheng', 'yisong yue', 'ziniu hu']"
1654,2408.10636,generating multi-frame ultrawide-field fluorescein angiography from   ultrawide-field color imaging improves diabetic retinopathy stratification,eess.iv cs.cv,"ultrawide-field fluorescein angiography (uwf-fa) facilitates diabetic retinopathy (dr) detection by providing a clear visualization of peripheral retinal lesions. however, the intravenous dye injection with potential risks hamper its application. we aim to acquire dye-free uwf-fa images from noninvasive uwf color fundus (uwf-cf) images using generative artificial intelligence (genai) and evaluate its effectiveness in dr screening. a total of 18,321 uwf-fa images of different phases were registered with corresponding uwf-cf images and fed into a generative adversarial networks (gan)-based model for training. the quality of generated uwf-fa images was evaluated through quantitative metrics and human evaluation. the deepdrid dataset was used to externally assess the contribution of generated uwf-fa images to dr classification, using area under the receiver operating characteristic curve (auroc) as outcome metrics. the generated early, mid, and late phase uwf-fa images achieved high authenticity, with multi-scale similarity scores ranging from 0.70 to 0.91 and qualitative visual scores ranging from 1.64 to 1.98 (1=real uwf-fa quality). in fifty randomly selected images, 56% to 76% of the generated images were difficult to distinguish from real images in the turing test. moreover, adding these generated uwf-fa images for dr classification significantly increased the auroc from 0.869 to 0.904 compared to the baseline model using uwf-cf images (p < .001). the model successfully generates realistic multi-frame uwf-fa images without intravenous dye injection. the generated uwf-fa enhanced dr stratification.",,2024-08-20,,"['ruoyu chen', 'kezheng xu', 'kangyan zheng', 'weiyi zhang', 'yan lu', 'danli shi', 'mingguang he']"
1655,2408.10637,variations on distributed belief,cs.lo,"motivated by the search for forms of distributed belief that do not collapse in the face of conflicting information, this paper introduces the notions of cautious and bold distributed belief. both notions rely on maximally consistent subgroups of agents, with cautious quantifying universally and bold quantifying existentially. as a result, while the cautious distributed belief of a group is inconsistent only when all group members are individually inconsistent, the bold distributed belief of a group is never inconsistent. the paper discusses these two notions, presenting their respective modalities and semantic interpretations, discussing some of their basic properties, studying whether they preserve doxastic properties from the members of the group, and comparing them not only with standard distributed belief but also with one another, both at the level of modalities and at the level of language expressivity.",,2024-08-20,,"['john lindqvist', 'fernando r. velázquez-quesada', 'thomas ågotnes']"
1656,2408.10641,a review of human-object interaction detection,cs.cv cs.ai,"human-object interaction (hoi) detection plays a key role in high-level visual understanding, facilitating a deep comprehension of human activities. specifically, hoi detection aims to locate the humans and objects involved in interactions within images or videos and classify the specific interactions between them. the success of this task is influenced by several key factors, including the accurate localization of human and object instances, as well as the correct classification of object categories and interaction relationships. this paper systematically summarizes and discusses the recent work in image-based hoi detection. first, the mainstream datasets involved in hoi relationship detection are introduced. furthermore, starting with two-stage methods and end-to-end one-stage detection approaches, this paper comprehensively discusses the current developments in image-based hoi detection, analyzing the strengths and weaknesses of these two methods. additionally, the advancements of zero-shot learning, weakly supervised learning, and the application of large-scale language models in hoi detection are discussed. finally, the current challenges in hoi detection are outlined, and potential research directions and future trends are explored.",,2024-08-20,,"['yuxiao wang', 'qiwei xiong', 'yu lei', 'weiying xue', 'qi liu', 'zhenao wei']"
1657,2408.10642,minor sft loss for llm fine-tune to increase performance and reduce   model deviation,cs.ai cs.cl,"instruct llm provide a paradigm used in large scale language model to align llm to human preference. the paradigm contains supervised fine tuning and reinforce learning from human feedback. this paradigm is also used in downstream scenarios to adapt llm to specific corpora and applications. comparing to sft, there are many efforts focused on rlhf and several algorithms being proposed, such as ppo, dpo, ipo, kto, minordpo and etc. meanwhile most efforts for sft are focused on how to collect, filter and mix high quality data. in this article with insight from dpo and minordpo, we propose a training metric for sft to measure the discrepancy between the optimized model and the original model, and a loss function minorsft that can increase the training effectiveness, and reduce the discrepancy between the optimized llm and original llm.",,2024-08-20,,"['shiming xie', 'hong chen', 'fred yu', 'zeye sun', 'xiuyu wu']"
1658,2408.10645,cora: collaborative information perception by large language model's   weights for recommendation,cs.ir cs.lg,"involving collaborative information in large language models (llms) is a promising technique for adapting llms for recommendation. existing methods achieve this by concatenating collaborative features with text tokens into a unified sequence input and then fine-tuning to align these features with llm's input space. although effective, in this work, we identify two limitations when adapting llms to recommendation tasks, which hinder the integration of general knowledge and collaborative information, resulting in sub-optimal recommendation performance. (1) fine-tuning llm with recommendation data can undermine its inherent world knowledge and fundamental competencies, which are crucial for interpreting and inferring recommendation text. (2) incorporating collaborative features into textual prompts disrupts the semantics of the original prompts, preventing llm from generating appropriate outputs. in this paper, we propose a new paradigm, cora (an acronym for collaborative lora), with a collaborative weights generator. rather than input space alignment, this method aligns collaborative information with llm's parameter space, representing them as incremental weights to update llm's output. this way, llm perceives collaborative information without altering its general knowledge and text inference capabilities. specifically, we employ a collaborative filtering model to extract user and item embeddings, converting them into collaborative weights with low-rank properties through the collaborative weights generator. we then merge the collaborative weights into llm's weights, enabling llm to perceive the collaborative signals and generate personalized recommendations without fine-tuning or extra collaborative tokens in prompts. extensive experiments confirm that cora effectively integrates collaborative information into llm, enhancing recommendation performance.",,2024-08-20,,"['yuting liu', 'jinghao zhang', 'yizhou dang', 'yuliang liang', 'qiang liu', 'guibing guo', 'jianzhe zhao', 'xingwei wang']"
1659,2408.10646,beneath the surface of consistency: exploring cross-lingual knowledge   representation sharing in llms,cs.cl cs.ai,"the veracity of a factoid is largely independent of the language it is written in. however, language models are inconsistent in their ability to answer the same factual question across languages. this raises questions about how llms represent a given fact across languages. we explore multilingual factual knowledge through two aspects: the model's ability to answer a query consistently across languages, and the ability to ''store'' answers in a shared representation for several languages. we propose a methodology to measure the extent of representation sharing across languages by repurposing knowledge editing methods. we examine llms with various multilingual configurations using a new multilingual dataset. we reveal that high consistency does not necessarily imply shared representation, particularly for languages with different scripts. moreover, we find that script similarity is a dominant factor in representation sharing. finally, we observe that if llms could fully share knowledge across languages, their accuracy in their best-performing language could benefit an increase of up to 150\% on average. these findings highlight the need for improved multilingual knowledge representation in llms and suggest a path for the development of more robust and consistent multilingual llms.",,2024-08-20,,"['maxim ifergan', 'leshem choshen', 'roee aharoni', 'idan szpektor', 'omri abend']"
1660,2408.10647,privacy-preserving universal adversarial defense for black-box models,cs.lg cs.ai cs.cr,"deep neural networks (dnns) are increasingly used in critical applications such as identity authentication and autonomous driving, where robustness against adversarial attacks is crucial. these attacks can exploit minor perturbations to cause significant prediction errors, making it essential to enhance the resilience of dnns. traditional defense methods often rely on access to detailed model information, which raises privacy concerns, as model owners may be reluctant to share such data. in contrast, existing black-box defense methods fail to offer a universal defense against various types of adversarial attacks. to address these challenges, we introduce ducd, a universal black-box defense method that does not require access to the target model's parameters or architecture. our approach involves distilling the target model by querying it with data, creating a white-box surrogate while preserving data privacy. we further enhance this surrogate model using a certified defense based on randomized smoothing and optimized noise selection, enabling robust defense against a broad range of adversarial attacks. comparative evaluations between the certified defenses of the surrogate and target models demonstrate the effectiveness of our approach. experiments on multiple image classification datasets show that ducd not only outperforms existing black-box defenses but also matches the accuracy of white-box defenses, all while enhancing data privacy and reducing the success rate of membership inference attacks.",,2024-08-20,,"['qiao li', 'cong wu', 'jing chen', 'zijun zhang', 'kun he', 'ruiying du', 'xinxin wang', 'qingchuang zhao', 'yang liu']"
1661,2408.10648,smart contract coordinated privacy preserving crowd-sensing campaigns,cs.cr cs.ni,"crowd-sensing has emerged as a powerful data retrieval model, enabling diverse applications by leveraging active user participation. however, data availability and privacy concerns pose significant challenges. traditional methods like data encryption and anonymization, while essential, may not fully address these issues. for instance, in sparsely populated areas, anonymized data can still be traced back to individual users. additionally, the volume of data generated by users can reveal their identities. to develop credible crowd-sensing systems, data must be anonymized, aggregated and separated into uniformly sized chunks. furthermore, decentralizing the data management process, rather than relying on a single server, can enhance security and trust. this paper proposes a system utilizing smart contracts and blockchain technologies to manage crowd-sensing campaigns. the smart contract handles user subscriptions, data encryption, and decentralized storage, creating a secure data marketplace. incentive policies within the smart contract encourage user participation and data diversity. simulation results confirm the system's viability, highlighting the importance of user participation for data credibility and the impact of geographical data scarcity on rewards. this approach aims to balance data origin and reduce cheating risks.",,2024-08-20,,"['luca bedogni', 'stefano ferretti']"
1662,2408.10649,inferring underwater topography with finn,cs.lg cs.ai physics.ao-ph physics.comp-ph physics.flu-dyn,"spatiotemporal partial differential equations (pdes) find extensive application across various scientific and engineering fields. while numerous models have emerged from both physics and machine learning (ml) communities, there is a growing trend towards integrating these approaches to develop hybrid architectures known as physics-aware machine learning models. among these, the finite volume neural network (finn) has emerged as a recent addition. finn has proven to be particularly efficient in uncovering latent structures in data. in this study, we explore the capabilities of finn in tackling the shallow-water equations, which simulates wave dynamics in coastal regions. specifically, we investigate finn's efficacy to reconstruct underwater topography based on these particular wave equations. our findings reveal that finn exhibits a remarkable capacity to infer topography solely from wave dynamics, distinguishing itself from both conventional ml and physics-aware ml models. our results underscore the potential of finn in advancing our understanding of spatiotemporal phenomena and enhancing parametrization capabilities in related domains.",,2024-08-20,,"['coşku can horuz', 'matthias karlbauer', 'timothy praditia', 'sergey oladyshkin', 'wolfgang nowak', 'sebastian otte']"
1663,2408.10652,vocabulary-free 3d instance segmentation with vision and language   assistant,cs.cv cs.ai,"most recent 3d instance segmentation methods are open vocabulary, offering a greater flexibility than closed-vocabulary methods. yet, they are limited to reasoning within a specific set of concepts, \ie the vocabulary, prompted by the user at test time. in essence, these models cannot reason in an open-ended fashion, i.e., answering ``list the objects in the scene.''. we introduce the first method to address 3d instance segmentation in a setting that is void of any vocabulary prior, namely a vocabulary-free setting. we leverage a large vision-language assistant and an open-vocabulary 2d instance segmenter to discover and ground semantic categories on the posed images. to form 3d instance mask, we first partition the input point cloud into dense superpoints, which are then merged into 3d instance masks. we propose a novel superpoint merging strategy via spectral clustering, accounting for both mask coherence and semantic coherence that are estimated from the 2d object instance masks. we evaluate our method using scannet200 and replica, outperforming existing methods in both vocabulary-free and open-vocabulary settings. code will be made available.",,2024-08-20,,"['guofeng mei', 'luigi riz', 'yiming wang', 'fabio poiesi']"
1664,2408.10653,uie-unfold: deep unfolding network with color priors and vision   transformer for underwater image enhancement,cs.cv,"underwater image enhancement (uie) plays a crucial role in various marine applications, but it remains challenging due to the complex underwater environment. current learning-based approaches frequently lack explicit incorporation of prior knowledge about the physical processes involved in underwater image formation, resulting in limited optimization despite their impressive enhancement results. this paper proposes a novel deep unfolding network (dun) for uie that integrates color priors and inter-stage feature transformation to improve enhancement performance. the proposed dun model combines the iterative optimization and reliability of model-based methods with the flexibility and representational power of deep learning, offering a more explainable and stable solution compared to existing learning-based uie approaches. the proposed model consists of three key components: a color prior guidance block (cpgb) that establishes a mapping between color channels of degraded and original images, a nonlinear activation gradient descent module (nagdm) that simulates the underwater image degradation process, and an inter stage feature transformer (isf-former) that facilitates feature exchange between different network stages. by explicitly incorporating color priors and modeling the physical characteristics of underwater image formation, the proposed dun model achieves more accurate and reliable enhancement results. extensive experiments on multiple underwater image datasets demonstrate the superiority of the proposed model over state-of-the-art methods in both quantitative and qualitative evaluations. the proposed dun-based approach offers a promising solution for uie, enabling more accurate and reliable scientific analysis in marine research. the code is available at https://github.com/cxh-research/uie-unfold.",,2024-08-20,,"['yingtie lei', 'jia yu', 'yihang dong', 'changwei gong', 'ziyang zhou', 'chi-man pun']"
1665,2408.10654,incorporating a 'ladder of trust' into dynamic allocation of function in   human-autonomous agent collectives,cs.hc,"a major, ongoing social transition is the inclusion of autonomous agents into human organizations. for example, in defence and security applications, robots may be used alongside human operatives to reduce risk or add capability. but a key barrier to the transition to successful human-autonomous agent collectives is the need for sufficient trust between team members. a critical enabling factor for this trust will be a suitably designed dynamic allocation of function (aof). we consider aof in terms of a 'ladder of trust' (from low to high) with individual team members adjusting trust in their teammates based on variation in 'score' over time. the score is derived by the ability of team member to perceive and understand its situation based on the gathered information and act to acheive team or self goals. combining these trust scores gives a system-level perspective on how aof might be adjusted during a mission. that is, the most suitable teammate for a function might have a low trust rating from its fellow teammates, so it might be preferable to choose the next most suitable teammate for the function at that point in time. of course, this is only in the situation where the next most suitable teammate is also likely to perform within the set framework of moral, ethical, and legal constraints. the trade-offs between trust in the individual agent's capability and predictability need to be considered within the broader context of the agent's integrity and accountability. from this perspective, the allocation space is defined by more than ability of each agent to perform a function.",,2024-08-20,,"['chris baber', 'patrick waterson', 'sanja milivojevic', 'sally maynard', 'edmund r. hunt', 'sagir yusuf']"
1666,2408.10656,deepmriprep: voxel-based morphometry (vbm) preprocessing via deep neural   networks,eess.iv cs.cv,"voxel-based morphometry (vbm) has emerged as a powerful approach in neuroimaging research, utilized in over 7,000 studies since the year 2000. using magnetic resonance imaging (mri) data, vbm assesses variations in the local density of brain tissue and examines its associations with biological and psychometric variables. here, we present deepmriprep, a neural network-based pipeline that performs all necessary preprocessing steps for vbm analysis of t1-weighted mr images using deep neural networks. utilizing the graphics processing unit (gpu), deepmriprep is 37 times faster than cat12, the leading vbm preprocessing toolbox. the proposed method matches cat12 in accuracy for tissue segmentation and image registration across more than 100 datasets and shows strong correlations in vbm results. tissue segmentation maps from deepmriprep have over 95% agreement with ground truth maps, and its non-linear registration, using supervised symnet, predicts smooth deformation fields comparable to cat12. the high processing speed of deepmriprep enables rapid preprocessing of extensive datasets and thereby fosters the application of vbm analysis to large-scale neuroimaging studies and opens the door to real-time applications. finally, deepmripreps straightforward, modular design enables researchers to easily understand, reuse, and advance the underlying methods, fostering further advancements in neuroimaging research. deepmriprep can be conveniently installed as a python package and is publicly accessible at https://github.com/wwu-mmll/deepmriprep.",,2024-08-20,,"['lukas fisch', 'nils r. winter', 'janik goltermann', 'carlotta barkhau', 'daniel emden', 'jan ernsting', 'maximilian konowski', 'ramona leenings', 'tiana borgers', 'kira flinkenflügel', 'dominik grotegerd', 'anna kraus', 'elisabeth j. leehr', 'susanne meinert', 'frederike stein', 'lea teutenberg', 'florian thomas-odenthal', 'paula usemann', 'marco hermesdorf', 'hamidreza jamalabadi', 'andreas jansen', 'igor nenadic', 'benjamin straube', 'tilo kircher', 'klaus berger', 'benjamin risse', 'udo dannlowski', 'tim hahn']"
1667,2408.10657,etguard: malicious encrypted traffic detection in blockchain-based power   grid systems,cs.cr cs.ai,"the escalating prevalence of encryption protocols has led to a concomitant surge in the number of malicious attacks that hide in encrypted traffic. power grid systems, as fundamental infrastructure, are becoming prime targets for such attacks. conventional methods for detecting malicious encrypted packets typically use a static pre-trained model. we observe that these methods are not well-suited for blockchain-based power grid systems. more critically, they fall short in dynamic environments where new types of encrypted attacks continuously emerge. motivated by this, in this paper we try to tackle these challenges from two aspects: (1) we present a novel framework that is able to automatically detect malicious encrypted traffic in blockchain-based power grid systems and incrementally learn from new malicious traffic. (2) we mathematically derive incremental learning losses to resist the forgetting of old attack patterns while ensuring the model is capable of handling new encrypted attack patterns. empirically, our method achieves state-of-the-art performance on three different benchmark datasets. we also constructed the first malicious encrypted traffic dataset for blockchain-based power grid scenario. our code and dataset are available at https://github.com/pppmzt/etguard, hoping to inspire future research.",,2024-08-20,,"['peng zhou', 'yongdong liu', 'lixun ma', 'weiye zhang', 'haohan tan', 'zhenguang liu', 'butian huang']"
1668,2408.10658,learning instruction-guided manipulation affordance via large models for   embodied robotic tasks,cs.ro,"we study the task of language instruction-guided robotic manipulation, in which an embodied robot is supposed to manipulate the target objects based on the language instructions. in previous studies, the predicted manipulation regions of the target object typically do not change with specification from the language instructions, which means that the language perception and manipulation prediction are separate. however, in human behavioral patterns, the manipulation regions of the same object will change for different language instructions. in this paper, we propose instruction-guided affordance net (iganet) for predicting affordance maps of instruction-guided robotic manipulation tasks by utilizing powerful priors from vision and language encoders pre-trained on large-scale datasets. we develop a vison-language-models(vlms)-based data augmentation pipeline, which can generate a large amount of data automatically for model training. besides, with the help of large-language-models(llms), actions can be effectively executed to finish the tasks defined by instructions. a series of real-world experiments revealed that our method can achieve better performance with generated data. moreover, our model can generalize better to scenarios with unseen objects and language instructions.",,2024-08-20,,"['dayou li', 'chenkun zhao', 'shuo yang', 'lin ma', 'yibin li', 'wei zhang']"
1669,2408.10663,reinstruct: building instruction data from unlabeled corpus,cs.cl,"manually annotating instruction data for large language models is difficult, costly, and hard to scale. meanwhile, current automatic annotation methods typically rely on distilling synthetic data from proprietary llms, which not only limits the upper bound of the quality of the instruction data but also raises potential copyright issues. in this paper, we propose reinstruct, a simple and scalable method to automatically build instruction data from an unlabeled corpus without heavy reliance on proprietary llms and human annotation. specifically, reinstruct first selects a subset of unlabeled texts that potentially contain well-structured helpful and insightful content and then generates instructions for these texts. to generate accurate and relevant responses for effective and robust training, reinstruct further proposes a rewriting-based approach to improve the quality of the generated instruction data. by training llama-7b on a combination of 3k seed data and 32k synthetic data from reinstruct, fine-tuned model achieves a 65.41\% win rate on alpacaeval leaderboard against text-davinci-003, outperforming other open-source, non-distilled instruction data construction methods. the code is publicly available at \url{https://github.com/cs32963/reinstruct}.",,2024-08-20,,"['shu chen', 'xinyan guan', 'yaojie lu', 'hongyu lin', 'xianpei han', 'le sun']"
1670,2408.10664,federated clustering: an unsupervised cluster-wise training for   decentralized data distributions,cs.lg,"federated learning (fl) is a pivotal approach in decentralized machine learning, especially when data privacy is crucial and direct data sharing is impractical. while fl is typically associated with supervised learning, its potential in unsupervised scenarios is underexplored. this paper introduces a novel unsupervised federated learning methodology designed to identify the complete set of categories (global k) across multiple clients within label-free, non-uniform data distributions, a process known as federated clustering. our approach, federated cluster-wise refinement (fedcref), involves clients that collaboratively train models on clusters with similar data distributions. initially, clients with diverse local data distributions (local k) train models on their clusters to generate compressed data representations. these local models are then shared across the network, enabling clients to compare them through reconstruction error analysis, leading to the formation of federated groups.in these groups, clients collaboratively train a shared model representing each data distribution, while continuously refining their local clusters to enhance data association accuracy. this iterative process allows our system to identify all potential data distributions across the network and develop robust representation models for each. to validate our approach, we compare it with traditional centralized methods, establishing a performance baseline and showcasing the advantages of our distributed solution. we also conduct experiments on the emnist and kmnist datasets, demonstrating fedcref's ability to refine and align cluster models with actual data distributions, significantly improving data representation precision in unsupervised federated settings.",,2024-08-20,,"['mirko nardi', 'lorenzo valerio', 'andrea passarella']"
1671,2408.10665,end-to-end learned lossy dynamic point cloud attribute compression,eess.iv cs.lg,"recent advancements in point cloud compression have primarily emphasized geometry compression while comparatively fewer efforts have been dedicated to attribute compression. this study introduces an end-to-end learned dynamic lossy attribute coding approach, utilizing an efficient high-dimensional convolution to capture extensive inter-point dependencies. this enables the efficient projection of attribute features into latent variables. subsequently, we employ a context model that leverage previous latent space in conjunction with an auto-regressive context model for encoding the latent tensor into a bitstream. evaluation of our method on widely utilized point cloud datasets from the mpeg and microsoft demonstrates its superior performance compared to the core attribute compression module region-adaptive hierarchical transform method from mpeg geometry point cloud compression with 38.1% bjontegaard delta-rate saving in average while ensuring a low-complexity encoding/decoding.",,2024-08-20,,"['dat thanh nguyen', 'daniel zieger', 'marc stamminger', 'andre kaup']"
1672,2408.10666,accelerating the surrogate retraining for poisoning attacks against   recommender systems,cs.ir,"recent studies have demonstrated the vulnerability of recommender systems to data poisoning attacks, where adversaries inject carefully crafted fake user interactions into the training data of recommenders to promote target items. current attack methods involve iteratively retraining a surrogate recommender on the poisoned data with the latest fake users to optimize the attack. however, this repetitive retraining is highly time-consuming, hindering the efficient assessment and optimization of fake users. to mitigate this computational bottleneck and develop a more effective attack in an affordable time, we analyze the retraining process and find that a change in the representation of one user/item will cause a cascading effect through the user-item interaction graph. under theoretical guidance, we introduce \emph{gradient passing} (gp), a novel technique that explicitly passes gradients between interacted user-item pairs during backpropagation, thereby approximating the cascading effect and accelerating retraining. with just a single update, gp can achieve effects comparable to multiple original training iterations. under the same number of retraining epochs, gp enables a closer approximation of the surrogate recommender to the victim. this more accurate approximation provides better guidance for optimizing fake users, ultimately leading to enhanced data poisoning attacks. extensive experiments on real-world datasets demonstrate the efficiency and effectiveness of our proposed gp.",,2024-08-20,,"['yunfan wu', 'qi cao', 'shuchang tao', 'kaike zhang', 'fei sun', 'huawei shen']"
1673,2408.10669,tensor tree learns hidden relational structures in data to construct   generative models,cs.lg cond-mat.stat-mech cs.ai quant-ph,"based on the tensor tree network with the born machine framework, we propose a general method for constructing a generative model by expressing the target distribution function as the quantum wave function amplitude represented by a tensor tree. the key idea is dynamically optimizing the tree structure that minimizes the bond mutual information. the proposed method offers enhanced performance and uncovers hidden relational structures in the target data. we illustrate potential practical applications with four examples: (i) random patterns, (ii) qmnist hand-written digits, (iii) bayesian networks, and (iv) the stock price fluctuation pattern in s&p500. in (i) and (ii), strongly correlated variables were concentrated near the center of the network; in (iii), the causality pattern was identified; and, in (iv), a structure corresponding to the eleven sectors emerged.",,2024-08-20,,"['kenji harada', 'tsuyoshi okubo', 'naoki kawashima']"
1674,2408.1067,a noncontact technique for wave measurement based on thermal   stereography and deep learning,cs.cv eess.iv,"the accurate measurement of the wave field and its spatiotemporal evolution is essential in many hydrodynamic experiments and engineering applications. the binocular stereo imaging technique has been widely used to measure waves. however, the optical properties of indoor water surfaces, including transparency, specular reflection, and texture absence, pose challenges for image processing and stereo reconstruction. this study proposed a novel technique that combined thermal stereography and deep learning to achieve fully noncontact wave measurements. the optical imaging properties of water in the long-wave infrared spectrum were found to be suitable for stereo matching, effectively avoiding the issues in the visible-light spectrum. after capturing wave images using thermal stereo cameras, a reconstruction strategy involving deep learning techniques was proposed to improve stereo matching performance. a generative approach was employed to synthesize a dataset with ground-truth disparity from unannotated infrared images. this dataset was then fed to a pretrained stereo neural network for fine-tuning to achieve domain adaptation. wave flume experiments were conducted to validate the feasibility and accuracy of the proposed technique. the final reconstruction results indicated great agreement and high accuracy with a mean bias of less than 2.1% compared with the measurements obtained using wave probes, suggesting that the novel technique effectively measures the spatiotemporal distribution of wave surface in hydrodynamic experiments.",,2024-08-20,,"['deyu li', 'longfei xiao', 'handi wei', 'yan li', 'binghua zhang']"
1675,2408.10672,neural exploratory landscape analysis,cs.lg cs.ne,"recent research in meta-black-box optimization (metabbo) have shown that meta-trained neural networks can effectively guide the design of black-box optimizers, significantly reducing the need for expert tuning and delivering robust performance across complex problem distributions. despite their success, a paradox remains: metabbo still rely on human-crafted exploratory landscape analysis features to inform the meta-level agent about the low-level optimization progress. to address the gap, this paper proposes neural exploratory landscape analysis (neurela), a novel framework that dynamically profiles landscape features through a two-stage, attention-based neural network, executed in an entirely end-to-end fashion. neurela is pre-trained over a variety of metabbo algorithms using a multi-task neuroevolution strategy. extensive experiments show that neurela achieves consistently superior performance when integrated into different and even unseen metabbo tasks and can be efficiently fine-tuned for further performance boost. this advancement marks a pivotal step in making metabbo algorithms more autonomous and broadly applicable.",,2024-08-20,,"['zeyuan ma', 'jiacheng chen', 'hongshu guo', 'yue-jiao gong']"
1676,2408.10673,iterative window mean filter: thwarting diffusion-based adversarial   purification,cs.cr,"face authentication systems have brought significant convenience and advanced developments, yet they have become unreliable due to their sensitivity to inconspicuous perturbations, such as adversarial attacks. existing defenses often exhibit weaknesses when facing various attack algorithms and adaptive attacks or compromise accuracy for enhanced security. to address these challenges, we have developed a novel and highly efficient non-deep-learning-based image filter called the iterative window mean filter (iwmf) and proposed a new framework for adversarial purification, named iwmf-diff, which integrates iwmf and denoising diffusion models. these methods can function as pre-processing modules to eliminate adversarial perturbations without necessitating further modifications or retraining of the target system. we demonstrate that our proposed methodologies fulfill four critical requirements: preserved accuracy, improved security, generalizability to various threats in different settings, and better resistance to adaptive attacks. this performance surpasses that of the state-of-the-art adversarial purification method, diffpure.",,2024-08-20,,"['hanrui wang', 'ruoxi sun', 'cunjian chen', 'minhui xue', 'lay-ki soon', 'shuo wang', 'zhe jin']"
1677,2408.10676,representation norm amplification for out-of-distribution detection in   long-tail learning,cs.lg,"detecting out-of-distribution (ood) samples is a critical task for reliable machine learning. however, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from ood samples. we examine the main challenges in this problem by identifying the trade-offs between ood detection and in-distribution (id) classification, faced by existing methods. we then introduce our method, called \textit{representation norm amplification} (rna), which solves this challenge by decoupling the two problems. the main idea is to use the norm of the representation as a new dimension for ood detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between id and ood data, while not perturbing the feature learning for id classification. our experiments show that rna achieves superior performance in both ood detection and classification compared to the state-of-the-art methods, by 1.70\% and 9.46\% in fpr95 and 2.43\% and 6.87\% in classification accuracy on cifar10-lt and imagenet-lt, respectively. the code for this work is available at https://github.com/dgshin21/rna.",,2024-08-20,,"['dong geun shin', 'hye won chung']"
1678,2408.10679,demmamba: alignment-free raw video demoireing with frequency-assisted   spatio-temporal mamba,cs.cv,"moire patterns arise when two similar repetitive patterns interfere, a phenomenon frequently observed during the capture of images or videos on screens. the color, shape, and location of moire patterns may differ across video frames, posing a challenge in learning information from adjacent frames and preserving temporal consistency. previous video demoireing methods heavily rely on well-designed alignment modules, resulting in substantial computational burdens. recently, mamba, an improved version of the state space model (ssm), has demonstrated significant potential for modeling long-range dependencies with linear complexity, enabling efficient temporal modeling in video demoireing without requiring a specific alignment module. in this paper, we propose a novel alignment-free raw video demoireing network with frequency-assisted spatio-temporal mamba (demmamba). the spatial mamba block (smb) and temporal mamba block (tmb) are sequentially arranged to facilitate effective intra- and inter-relationship modeling in raw videos with moire patterns. within smb, an adaptive frequency block (afb) is introduced to aid demoireing in the frequency domain. for tmb, a channel attention block (cab) is embedded to further enhance temporal information interactions by exploiting the inter-channel relationships among features. extensive experiments demonstrate that our proposed demmamba surpasses state-of-the-art approaches by 1.3 db and delivers a superior visual experience.",,2024-08-20,,"['shuning xu', 'xina liu', 'binbin song', 'xiangyu chen', 'qiubo chen', 'jiantao zhou']"
1679,2408.1068,towards rehearsal-free multilingual asr: a lora-based case study on   whisper,cs.cl cs.sd eess.as,"pre-trained multilingual speech foundation models, like whisper, have shown impressive performance across different languages. however, adapting these models to new or specific languages is computationally extensive and faces catastrophic forgetting problems. addressing these issues, our study investigates strategies to enhance the model on new languages in the absence of original training data, while also preserving the established performance on the original languages. specifically, we first compare various lora-based methods to find out their vulnerability to forgetting. to mitigate this issue, we propose to leverage the lora parameters from the original model for approximate orthogonal gradient descent on the new samples. additionally, we also introduce a learnable rank coefficient to allocate trainable parameters for more efficient training. our experiments with a chinese whisper model (for uyghur and tibetan) yield better results with a more compact parameter set.",,2024-08-20,,"['tianyi xu', 'kaixun huang', 'pengcheng guo', 'yu zhou', 'longtao huang', 'hui xue', 'lei xie']"
1680,2408.10681,hmoe: heterogeneous mixture of experts for language modeling,cs.cl cs.lg,"mixture of experts (moe) offers remarkable performance and computational efficiency by selectively activating subsets of model parameters. traditionally, moe models use homogeneous experts, each with identical capacity. however, varying complexity in input data necessitates experts with diverse capabilities, while homogeneous moe hinders effective expert specialization and efficient parameter utilization. in this study, we propose a novel heterogeneous mixture of experts (hmoe), where experts differ in size and thus possess diverse capacities. this heterogeneity allows for more specialized experts to handle varying token complexities more effectively. to address the imbalance in expert activation, we propose a novel training objective that encourages the frequent activation of smaller experts, enhancing computational efficiency and parameter utilization. extensive experiments demonstrate that hmoe achieves lower loss with fewer activated parameters and outperforms conventional homogeneous moe models on various pre-training evaluation benchmarks. codes will be released upon acceptance.",,2024-08-20,,"['an wang', 'xingwu sun', 'ruobing xie', 'shuaipeng li', 'jiaqi zhu', 'zhen yang', 'pinxue zhao', 'j. n. han', 'zhanhui kang', 'di wang', 'naoaki okazaki', 'cheng-zhong xu']"
1681,2408.10682,towards robust knowledge unlearning: an adversarial framework for   assessing and improving unlearning robustness in large language models,cs.cl cs.ai cs.cr cs.lg,"llm have achieved success in many fields but still troubled by problematic content in the training corpora. llm unlearning aims at reducing their influence and avoid undesirable behaviours. however, existing unlearning methods remain vulnerable to adversarial queries and the unlearned knowledge resurfaces after the manually designed attack queries. as part of a red-team effort to proactively assess the vulnerabilities of unlearned models, we design dynamic unlearning attack (dua), a dynamic and automated framework to attack these models and evaluate their robustness. it optimizes adversarial suffixes to reintroduce the unlearned knowledge in various scenarios. we find that unlearned knowledge can be recovered in $55.2\%$ of the questions, even without revealing the unlearned model's parameters. in response to this vulnerability, we propose latent adversarial unlearning (lau), a universal framework that effectively enhances the robustness of the unlearned process. it formulates the unlearning process as a min-max optimization problem and resolves it through two stages: an attack stage, where perturbation vectors are trained and added to the latent space of llms to recover the unlearned knowledge, and a defense stage, where previously trained perturbation vectors are used to enhance unlearned model's robustness. with our lau framework, we obtain two robust unlearning methods, advga and advnpo. we conduct extensive experiments across multiple unlearning benchmarks and various models, and demonstrate that they improve the unlearning effectiveness by over $53.5\%$, cause only less than a $11.6\%$ reduction in neighboring knowledge, and have almost no impact on the model's general capabilities.",,2024-08-20,,"['hongbang yuan', 'zhuoran jin', 'pengfei cao', 'yubo chen', 'kang liu', 'jun zhao']"
1682,2408.10683,rejection in abstract argumentation: harder than acceptance?,cs.ai cs.cc cs.lo,"abstract argumentation is a popular toolkit for modeling, evaluating, and comparing arguments. relationships between arguments are specified in argumentation frameworks (afs), and conditions are placed on sets (extensions) of arguments that allow afs to be evaluated. for more expressiveness, afs are augmented with \emph{acceptance conditions} on directly interacting arguments or a constraint on the admissible sets of arguments, resulting in dialectic frameworks or constrained argumentation frameworks. in this paper, we consider flexible conditions for \emph{rejecting} an argument from an extension, which we call rejection conditions (rcs). on the technical level, we associate each argument with a specific logic program. we analyze the resulting complexity, including the structural parameter treewidth. rejection afs are highly expressive, giving rise to natural problems on higher levels of the polynomial hierarchy.",,2024-08-20,,"['johannes k. fichte', 'markus hecher', 'yasir mahmood', 'arne meier']"
1683,2408.10685,proving cutoff bounds for safety properties in first-order logic,cs.lo cs.pl,"first-order logic has been established as an important tool for modeling and verifying intricate systems such as distributed protocols and concurrent systems. these systems are parametric in the number of nodes in the network or the number of threads, which is finite in any system instance, but unbounded. one disadvantage of first-order logic is that it cannot distinguish between finite and infinite structures, leading to spurious counterexamples. to mitigate this, we offer a verification approach that captures only finite system instances. our approach is an adaptation of the cutoff method to systems modeled in first-order logic. the idea is to show that any safety violation in a system instance of size larger than some bound can be simulated by a safety violation in a system of a smaller size. the simulation provides an inductive argument for correctness in finite instances, reducing the problem to showing safety of instances with bounded size. to this end, we develop a framework to (i) encode such simulation relations in first-order logic and to (ii) validate the simulation relation by a set of verification conditions given to an smt solver. we apply our approach to verify safety of a set of examples, some of which cannot be proven by a first-order inductive invariant.",,2024-08-20,,"['raz lotan', 'eden frenkel', 'sharon shoham']"
1684,2408.10688,tds-clip: temporal difference side network for image-to-video transfer   learning,cs.cv,"recently, large-scale pre-trained vision-language models (e.g., clip), have garnered significant attention thanks to their powerful representative capabilities. this inspires researchers in transferring the knowledge from these large pre-trained models to other task-specific models, e.g., video action recognition (var) models, via particularly leveraging side networks to enhance the efficiency of parameter-efficient fine-tuning (peft). however, current transferring approaches in var tend to directly transfer the frozen knowledge from large pre-trained models to action recognition networks with minimal cost, instead of exploiting the temporal modeling capabilities of the action recognition models themselves. therefore, in this paper, we propose a memory-efficient temporal difference side network (tds-clip) to balance knowledge transferring and temporal modeling, avoiding backpropagation in frozen parameter models. specifically, we introduce a temporal difference adapter (td-adapter), which can effectively capture local temporal differences in motion features to strengthen the model's global temporal modeling capabilities. furthermore, we designed a side motion enhancement adapter (sme-adapter) to guide the proposed side network in efficiently learning the rich motion information in videos, thereby improving the side network's ability to capture and learn motion information. extensive experiments are conducted on three benchmark datasets, including something-something v1\&v2, and kinetics-400. experimental results demonstrate that our approach achieves competitive performance.",,2024-08-20,,"['bin wang', 'wenqian wang']"
1685,2408.10689,genesis: towards the automation of systems biology research,cs.ai,"the cutting edge of applying ai to science is the closed-loop automation of scientific research: robot scientists. we have previously developed two robot scientists: `adam' (for yeast functional biology), and `eve' (for early-stage drug design)). we are now developing a next generation robot scientist genesis. with genesis we aim to demonstrate that an area of science can be investigated using robot scientists unambiguously faster, and at lower cost, than with human scientists. here we report progress on the genesis project. genesis is designed to automatically improve system biology models with thousands of interacting causal components. when complete genesis will be able to initiate and execute in parallel one thousand hypothesis-led closed-loop cycles of experiment per-day. here we describe the core genesis hardware: the one thousand computer-controlled $\mu$-bioreactors. for the integrated mass spectrometry platform we have developed autonoms, a system to automatically run, process, and analyse high-throughput experiments. we have also developed genesis-db, a database system designed to enable software agents access to large quantities of structured domain information. we have developed rimbo (revisions for improvements of models in biology ontology) to describe the planned hundreds of thousands of changes to the models. we have demonstrated the utility of this infrastructure by developed two relational learning bioinformatic projects. finally, we describe lgem+ a relational learning system for the automated abductive improvement of genome-scale metabolic models.",,2024-08-20,,"['ievgeniia a. tiukova', 'daniel brunnsåker', 'erik y. bjurström', 'alexander h. gower', 'filip kronström', 'gabriel k. reder', 'ronald s. reiserer', 'konstantin korovin', 'larisa b. soldatova', 'john p. wikswo', 'ross d. king']"
1686,2408.1069,spectral function space learning and numerical linear algebra networks   for solving linear inverse problems,math.na cs.na math.fa,"we consider solving a probably ill-conditioned linear operator equation, where the operator is not modeled by physical laws but is specified via training pairs (consisting of images and data) of the input-output relation of the operator. we derive a stable method for computing the operator, which consists of first a gram-schmidt orthonormalization of images and a principal component analysis of the data. this two-step algorithm provides a spectral decomposition of the linear operator. moreover, we show that both gram-schmidt and principal component analysis can be written as a deep neural network, which relates this procedure to de-and encoder networks. therefore, we call the two-step algorithm a linear algebra network. finally, we provide numerical simulations showing the strategy is feasible for reconstructing spectral functions and for solving operator equations without explicitly exploiting the physical model.",,2024-08-20,,"['andrea aspri', 'leon frischauf', 'otmar scherzer']"
1687,2408.10691,fine-tuning and deploying large language models over edges: issues and   approaches,cs.ai,"since the invention of gpt2--1.5b in 2019, large language models (llms) have transitioned from specialized models to versatile foundation models. the llms exhibit impressive zero-shot ability, however, require fine-tuning on local datasets and significant resources for deployment. traditional fine-tuning techniques with the first-order optimizers require substantial gpu memory that exceeds mainstream hardware capability. therefore, memory-efficient methods are motivated to be investigated. model compression techniques can reduce energy consumption, operational costs, and environmental impact so that to support sustainable artificial intelligence advancements. additionally, large-scale foundation models have expanded to create images, audio, videos, and multi-modal contents, further emphasizing the need for efficient deployment. therefore, we are motivated to present a comprehensive overview of the prevalent memory-efficient fine-tuning methods over the network edge. we also review the state-of-the-art literatures on model compression to provide a vision on deploying llms over the network edge.",,2024-08-20,,"['yanjie dong', 'xiaoyi fan', 'fangxin wang', 'chengming li', 'victor c. m. leung', 'xiping hu']"
1688,2408.10692,unconditional truthfulness: learning conditional dependency for   uncertainty quantification of large language models,cs.cl,"uncertainty quantification (uq) is a perspective approach to detecting large language model (llm) hallucinations and low quality output. in this work, we address one of the challenges of uq in generation tasks that arises from the conditional dependency between the generation steps of an llm. we propose to learn this dependency from data. we train a regression model, which target variable is the gap between the conditional and the unconditional generation confidence. during llm inference, we use this learned conditional dependency model to modulate the uncertainty of the current generation step based on the uncertainty of the previous step. our experimental evaluation on nine datasets and three llms shows that the proposed method is highly effective for uncertainty quantification, achieving substantial improvements over rivaling approaches.",,2024-08-20,,"['artem vazhentsev', 'ekaterina fadeeva', 'rui xing', 'alexander panchenko', 'preslav nakov', 'timothy baldwin', 'maxim panov', 'artem shelmanov']"
1689,2408.10693,"improved differential evolution based feature selection through quantum,   chaos, and lasso",cs.ne,"modern deep learning continues to achieve outstanding performance on an astounding variety of high-dimensional tasks. in practice, this is obtained by fitting deep neural models to all the input data with minimal feature engineering, thus sacrificing interpretability in many cases. however, in applications such as medicine, where interpretability is crucial, feature subset selection becomes an important problem. metaheuristics such as binary differential evolution are a popular approach to feature selection, and the research literature continues to introduce novel ideas, drawn from quantum computing and chaos theory, for instance, to improve them. in this paper, we demonstrate that introducing chaos-generated variables, generated from considerations of the lyapunov time, in place of random variables in quantum-inspired metaheuristics significantly improves their performance on high-dimensional medical classification tasks and outperforms other approaches. we show that this chaos-induced improvement is a general phenomenon by demonstrating it for multiple varieties of underlying quantum-inspired metaheuristics. performance is further enhanced through lasso-assisted feature pruning. at the implementation level, we vastly speed up our algorithms through a scalable island-based computing cluster parallelization technique.",,2024-08-20,,"['yelleti vivek', 'sri krishna vadlamani', 'vadlamani ravi', 'p. radha krishna']"
1690,2408.10694,msmemorygan: a multi-scale memory gan for palm-vein adversarial   purification,cs.cv,"deep neural networks have recently achieved promising performance in the vein recognition task and have shown an increasing application trend, however, they are prone to adversarial perturbation attacks by adding imperceptible perturbations to the input, resulting in making incorrect recognition. to address this issue, we propose a novel defense model named msmemorygan, which aims to filter the perturbations from adversarial samples before recognition. first, we design a multi-scale autoencoder to achieve high-quality reconstruction and two memory modules to learn the detailed patterns of normal samples at different scales. second, we investigate a learnable metric in the memory module to retrieve the most relevant memory items to reconstruct the input image. finally, the perceptional loss is combined with the pixel loss to further enhance the quality of the reconstructed image. during the training phase, the msmemorygan learns to reconstruct the input by merely using fewer prototypical elements of the normal patterns recorded in the memory. at the testing stage, given an adversarial sample, the msmemorygan retrieves its most relevant normal patterns in memory for the reconstruction. perturbations in the adversarial sample are usually not reconstructed well, resulting in purifying the input from adversarial perturbations. we have conducted extensive experiments on two public vein datasets under different adversarial attack methods to evaluate the performance of the proposed approach. the experimental results show that our approach removes a wide variety of adversarial perturbations, allowing vein classifiers to achieve the highest recognition accuracy.",,2024-08-20,,"['huafeng qin', 'yuming fu', 'huiyan zhang', 'mounim a. el-yacoubi', 'xinbo gao', 'qun song', 'jun wang']"
1691,2408.10695,"on nvd users' attitudes, experiences, hopes and hurdles",cs.cr,"the national vulnerability database (nvd) is a major vulnerability database that is free to use for everyone. it provides information about vulnerabilities and further useful resources such as linked advisories and patches. the nvd is often considered as the central source for vulnerability information and as a help to improve the resource-intensive process of vulnerability management. although the nvd receives much public attention, little is known about its usage in vulnerability management, users' attitudes towards it and whether they encounter any problems during usage. we explored these questions using a preliminary interview study with seven people, and a follow-up survey with 71 participants. the results show that the nvd is consulted regularly and often aids decision making. generally, users are positive about the nvd and perceive it as a helpful, clearly structured tool. but users also faced issues: missing or incorrect entries, incomplete descriptions or incomprehensible cvss ratings. in order to identify the problems origins, we discussed the results with two senior nvd members. many of the problems can be attributed to higher-level problems such as the cve list or limited resources. nevertheless, the nvd is working on improving existing problems.",10.1145/3688806,2024-08-20,,"['julia wunder', 'alan corona', 'andreas hammer', 'zinaida benenson']"
1692,2408.107,anygraph: graph foundation model in the wild,cs.lg cs.ai,"the growing ubiquity of relational data structured as graphs has underscored the need for graph learning models with exceptional generalization capabilities. however, current approaches often struggle to effectively extract generalizable insights, frequently requiring extensive fine-tuning and limiting their versatility. graph foundation models offer a transformative solution, with the potential to learn robust, generalizable representations from graph data. this enables more effective and adaptable applications across a wide spectrum of tasks and domains. in this work, we investigate a unified graph model, anygraph, designed to handle key challenges: i) structure heterogenity. addressing distribution shift in graph structural information; ii) feature heterogenity. handling diverse feature representation spaces across graph datasets; iii) fast adaptation. efficiently adapting the model to new graph domains; iv) scaling law emergence. enabling the model to exhibit scaling law behavior, where its performance scales favorably with the amount of data and parameter sizes. to tackle these critical challenges, we build the anygraph upon a graph mixture-of-experts (moe) architecture. this approach empowers the model to effectively manage both the in-domain and cross-domain distribution shift concerning structure-level and feature-level heterogeneity. furthermore, a lightweight graph expert routing mechanism is proposed to facilitate anygraph's fast adaptability to new data and domains. our extensive experiments on diverse 38 graph datasets have demonstrated the strong zero-shot learning performance of anygraph across diverse graph domains with significant distribution shift. furthermore, we have validated the model's fast adaptation ability and scaling law emergence, showcasing its versatility.",,2024-08-20,,"['lianghao xia', 'chao huang']"
1693,2408.10701,ferret: faster and effective automated red teaming with reward-based   scoring technique,cs.cl,"in today's era, where large language models (llms) are integrated into numerous real-world applications, ensuring their safety and robustness is crucial for responsible ai usage. automated red-teaming methods play a key role in this process by generating adversarial attacks to identify and mitigate potential vulnerabilities in these models. however, existing methods often struggle with slow performance, limited categorical diversity, and high resource demands. while rainbow teaming, a recent approach, addresses the diversity challenge by framing adversarial prompt generation as a quality-diversity search, it remains slow and requires a large fine-tuned mutator for optimal performance. to overcome these limitations, we propose ferret, a novel approach that builds upon rainbow teaming by generating multiple adversarial prompt mutations per iteration and using a scoring function to rank and select the most effective adversarial prompt. we explore various scoring functions, including reward models, llama guard, and llm-as-a-judge, to rank adversarial mutations based on their potential harm to improve the efficiency of the search for harmful mutations. our results demonstrate that ferret, utilizing a reward model as a scoring function, improves the overall attack success rate (asr) to 95%, which is 46% higher than rainbow teaming. additionally, ferret reduces the time needed to achieve a 90% asr by 15.2% compared to the baseline and generates adversarial prompts that are transferable i.e. effective on other llms of larger size. our codes are available at https://github.com/declare-lab/ferret.",,2024-08-20,,"['tej deep pala', 'vernon y. h. toh', 'rishabh bhardwaj', 'soujanya poria']"
1694,2408.10703,large language models for multimodal deformable image registration,cs.cv,"the challenge of multimodal deformable image registration (mdir) lies in the conversion and alignment of features between images of different modalities. generative models (gms) cannot retain the necessary information enough from the source modality to the target one, while non-gms struggle to align features across these two modalities. in this paper, we propose a novel coarse-to-fine mdir framework,llm-morph, which is applicable to various pre-trained large language models (llms) to solve these concerns by aligning the deep features from different modal medical images. specifically, we first utilize a cnn encoder to extract deep visual features from cross-modal image pairs, then we use the first adapter to adjust these tokens, and use lora in pre-trained llms to fine-tune their weights, both aimed at eliminating the domain gap between the pre-trained llms and the mdir task. third, for the alignment of tokens, we utilize other four adapters to transform the llm-encoded tokens into multi-scale visual features, generating multi-scale deformation fields and facilitating the coarse-to-fine mdir task. extensive experiments in mr-ct abdomen and sr-reg brain datasets demonstrate the effectiveness of our framework and the potential of pre-trained llms for mdir task. our code is availabel at: https://github.com/ninjannn/llm-morph.",,2024-08-20,,"['mingrui ma', 'weijie wang', 'jie ning', 'jianfeng he', 'nicu sebe', 'bruno lepri']"
1695,2408.10706,performance analysis of physical layer security: from far-field to   near-field,cs.it eess.sp math.it,"the secrecy performance in both near-field and far-field communications is analyzed using two fundamental metrics: the secrecy capacity under a power constraint and the minimum power requirement to achieve a specified secrecy rate target. 1) for the secrecy capacity, a closed-form expression is derived under a discrete-time memoryless setup. this expression is further analyzed under several far-field and near-field channel models, and the capacity scaling law is revealed by assuming an infinitely large transmit array and an infinitely high power. a novel concept of ""depth of insecurity"" is proposed to evaluate the secrecy performance achieved by near-field beamfocusing. it is demonstrated that increasing the number of transmit antennas reduces this depth and thus improves the secrecy performance. 2) regarding the minimum required power, a closed-form expression is derived and analyzed within far-field and near-field scenarios. asymptotic analyses are performed by setting the number of transmit antennas to infinity to unveil the power scaling law. numerical results are provided to demonstrate that: i) compared to far-field communications, near-field communications expand the areas where secure transmission is feasible, specifically when the eavesdropper is located in the same direction as the intended receiver; ii) as the number of transmit antennas increases, neither the secrecy capacity nor the minimum required power scales or vanishes unboundedly, adhering to the principle of energy conservation.",,2024-08-20,,"['boqun zhao', 'chongjun ouyang', 'xingqi zhang', 'yuanwei liu']"
1696,2408.10708,distribution of reconfiguration languages maintaining tree-like   communication topology,cs.fl,"we study how to distribute trace languages in a setting where processes communicate via reconfigurable communication channels. that is, the different processes can connect and disconnect from channels at run time. we restrict attention to communication via tree-like communication architectures. these allow channels to connect more than two processes in a way that maintains an underlying spanning tree and keeps communication continuous on the tree. we make the reconfiguration explicit in the language allowing both a centralized automaton as well as the distributed processes to share relevant information about the current communication configuration. we show that zielonka's seminal result regarding distribution of regular languages for asynchronous automata can be generalized in this setting, incorporating both reconfiguration and more than binary tree architectures.",,2024-08-20,,"['daniel hausmann', 'mathieu lehaut', 'nir piterman']"
1697,2408.10709,variable assignment invariant neural networks for learning logic   programs,cs.lg cs.ai,"learning from interpretation transition (lfit) is a framework for learning rules from observed state transitions. lfit has been implemented in purely symbolic algorithms, but they are unable to deal with noise or generalize to unobserved transitions. rule extraction based neural network methods suffer from overfitting, while more general implementation that categorize rules suffer from combinatorial explosion. in this paper, we introduce a technique to leverage variable permutation invariance inherent in symbolic domains. our technique ensures that the permutation and the naming of the variables would not affect the results. we demonstrate the effectiveness and the scalability of this method with various experiments. our code is publicly available at https://github.com/phuayj/delta-lfit-2",,2024-08-20,,"['yin jun phua', 'katsumi inoue']"
1698,2408.1071,coarse-to-fine detection of multiple seams for robotic welding,cs.cv cs.ai,"efficiently detecting target weld seams while ensuring sub-millimeter accuracy has always been an important challenge in autonomous welding, which has significant application in industrial practice. previous works mostly focused on recognizing and localizing welding seams one by one, leading to inferior efficiency in modeling the workpiece. this paper proposes a novel framework capable of multiple weld seams extraction using both rgb images and 3d point clouds. the rgb image is used to obtain the region of interest by approximately localizing the weld seams, and the point cloud is used to achieve the fine-edge extraction of the weld seams within the region of interest using region growth. our method is further accelerated by using a pre-trained deep learning model to ensure both efficiency and generalization ability. the performance of the proposed method has been comprehensively tested on various workpieces featuring both linear and curved weld seams and in physical experiment systems. the results showcase considerable potential for real-world industrial applications, emphasizing the method's efficiency and effectiveness. videos of the real-world experiments can be found at https://youtu.be/pq162hsp2d4.",,2024-08-20,,"['pengkun wei', 'shuo cheng', 'dayou li', 'ran song', 'yipeng zhang', 'wei zhang']"
1699,2408.10711,investigating context effects in similarity judgements in large language   models,cs.ai,"large language models (llms) have revolutionised the capability of ai models in comprehending and generating natural language text. they are increasingly being used to empower and deploy agents in real-world scenarios, which make decisions and take actions based on their understanding of the context. therefore researchers, policy makers and enterprises alike are working towards ensuring that the decisions made by these agents align with human values and user expectations. that being said, human values and decisions are not always straightforward to measure and are subject to different cognitive biases. there is a vast section of literature in behavioural science which studies biases in human judgements. in this work we report an ongoing investigation on alignment of llms with human judgements affected by order bias. specifically, we focus on a famous human study which showed evidence of order effects in similarity judgements, and replicate it with various popular llms. we report the different settings where llms exhibit human-like order effect bias and discuss the implications of these findings to inform the design and development of llm based applications.",,2024-08-20,,"['sagar uprety', 'amit kumar jaiswal', 'haiming liu', 'dawei song']"
1700,2408.10713,offline model-based reinforcement learning with anti-exploration,cs.lg cs.ai,"model-based reinforcement learning (mbrl) algorithms learn a dynamics model from collected data and apply it to generate synthetic trajectories to enable faster learning. this is an especially promising paradigm in offline reinforcement learning (rl) where data may be limited in quantity, in addition to being deficient in coverage and quality. practical approaches to offline mbrl usually rely on ensembles of dynamics models to prevent exploitation of any individual model and to extract uncertainty estimates that penalize values in states far from the dataset support. uncertainty estimates from ensembles can vary greatly in scale, making it challenging to generalize hyperparameters well across even similar tasks. in this paper, we present morse model-based offline rl (momo), which extends the anti-exploration paradigm found in offline model-free rl to the model-based space. we develop model-free and model-based variants of momo and show how the model-free version can be extended to detect and deal with out-of-distribution (ood) states using explicit uncertainty estimation without the need for large ensembles. momo performs offline mbrl using an anti-exploration bonus to counteract value overestimation in combination with a policy constraint, as well as a truncation function to terminate synthetic rollouts that are excessively ood. experimentally, we find that both model-free and model-based momo perform well, and the latter outperforms prior model-based and model-free baselines on the majority of d4rl datasets tested.",,2024-08-20,,"['padmanaba srinivasan', 'william knottenbelt']"
1701,2408.10714,physics-driven ai correction in laser absorption sensing quantification,cs.ne,"laser absorption spectroscopy (las) quantification is a popular tool used in measuring temperature and concentration of gases. it has low error tolerance, whereas current ml-based solutions cannot guarantee their measure reliability. in this work, we propose a new framework, spec, to address this issue. in addition to the conventional ml estimator-based estimation mode, spec also includes a physics-driven anomaly detection module (pad) to assess the error of the estimation. and a correction mode is designed to correct the unreliable estimation. the correction mode is a network-based optimization algorithm, which uses the guidance of error to iteratively correct the estimation. a hybrid surrogate error model is proposed to estimate the error distribution, which contains an ensemble of networks to simulate reconstruction error, and true feasible error computation. a greedy ensemble search is proposed to find the optimal correction robustly and efficiently from the gradient guidance of surrogate model. the proposed spec is validated on the test scenarios which are outside the training distribution. the results show that spec can significantly improve the estimation quality, and the correction mode outperforms current network-based optimization algorithms. in addition, spec has the reconfigurability, which can be easily adapted to different quantification tasks via changing pad without retraining the ml estimator.",,2024-08-20,,"['ruiyuan kang', 'panos liatsis', 'meixia geng', 'qingjie yang']"
1702,2408.10715,fine-tuning a local llama-3 large language model for automated   privacy-preserving physician letter generation in radiation oncology,cs.ai,"generating physician letters is a time-consuming task in daily clinical practice. this study investigates local fine-tuning of large language models (llms), specifically llama models, for physician letter generation in a privacy-preserving manner within the field of radiation oncology. our findings demonstrate that base llama models, without fine-tuning, are inadequate for effectively generating physician letters. the qlora algorithm provides an efficient method for local intra-institutional fine-tuning of llms with limited computational resources (i.e., a single 48 gb gpu workstation within the hospital). the fine-tuned llm successfully learns radiation oncology-specific information and generates physician letters in an institution-specific style. rouge scores of the generated summary reports highlight the superiority of the 8b llama-3 model over the 13b llama-2 model. further multidimensional physician evaluations of 10 cases reveal that, although the fine-tuned llama-3 model has limited capacity to generate content beyond the provided input data, it successfully generates salutations, diagnoses and treatment histories, recommendations for further treatment, and planned schedules. overall, clinical benefit was rated highly by the clinical experts (average score of 3.44 on a 4-point scale). with careful physician review and correction, automated llm-based physician letter generation has significant practical value.",,2024-08-20,,"['yihao hou', 'christoph bert', 'ahmed gomaa', 'godehard lahmer', 'daniel hoefler', 'thomas weissmann', 'raphaela voigt', 'philipp schubert', 'charlotte schmitter', 'alina depardon', 'sabine semrau', 'andreas maier', 'rainer fietkau', 'yixing huang', 'florian putz']"
1703,2408.10717,"accelerated training of deep learning surrogate models for surface   displacement and flow, with application to mcmc-based history matching of co2   storage operations",cs.lg,"deep learning surrogate modeling shows great promise for subsurface flow applications, but the training demands can be substantial. here we introduce a new surrogate modeling framework to predict co2 saturation, pressure and surface displacement for use in the history matching of carbon storage operations. rather than train using a large number of expensive coupled flow-geomechanics simulation runs, training here involves a large number of inexpensive flow-only simulations combined with a much smaller number of coupled runs. the flow-only runs use an effective rock compressibility, which is shown to provide accurate predictions for saturation and pressure for our system. a recurrent residual u-net architecture is applied for the saturation and pressure surrogate models, while a new residual u-net model is introduced to predict surface displacement. the surface displacement surrogate accepts, as inputs, geomodel quantities along with saturation and pressure surrogate predictions. median relative error for a diverse test set is less than 4% for all variables. the surrogate models are incorporated into a hierarchical markov chain monte carlo history matching workflow. surrogate error is included using a new treatment involving the full model error covariance matrix. a high degree of prior uncertainty, with geomodels characterized by uncertain geological scenario parameters (metaparameters) and associated realizations, is considered. history matching results for a synthetic true model are generated using in-situ monitoring-well data only, surface displacement data only, and both data types. the enhanced uncertainty reduction achieved with both data types is quantified. posterior saturation and surface displacement fields are shown to correspond well with the true solution.",,2024-08-20,,"['yifu han', 'francois p. hamon', 'louis j. durlofsky']"
1704,2408.10718,codejudge-eval: can large language models be good judges in code   understanding?,cs.se cs.cl,"recent advancements in large language models (llms) have showcased impressive code generation capabilities, primarily evaluated through language-to-code benchmarks. however, these benchmarks may not fully capture a model's code understanding abilities. we introduce codejudge-eval (cj-eval), a novel benchmark designed to assess llms' code understanding abilities from the perspective of code judging rather than code generation. cj-eval challenges models to determine the correctness of provided code solutions, encompassing various error types and compilation issues. by leveraging a diverse set of problems and a fine-grained judging system, cj-eval addresses the limitations of traditional benchmarks, including the potential memorization of solutions. evaluation of 12 well-known llms on cj-eval reveals that even state-of-the-art models struggle, highlighting the benchmark's ability to probe deeper into models' code understanding abilities. our benchmark will be available at \url{https://github.com/codellm-research/codejudge-eval}.",,2024-08-20,,"['yuwei zhao', 'ziyang luo', 'yuchen tian', 'hongzhan lin', 'weixiang yan', 'annan li', 'jing ma']"
1705,2408.1072,towards foundation models for the industrial forecasting of chemical   kinetics,cs.lg cs.ai,"scientific machine learning is transforming traditional engineering industries by enhancing the efficiency of existing technologies and accelerating innovation, particularly in modeling chemical reactions. despite recent advancements, the issue of solving stiff chemically reacting problems within computational fluid dynamics remains a significant issue. in this study we propose a novel approach utilizing a multi-layer-perceptron mixer architecture (mlp-mixer) to model the time-series of stiff chemical kinetics. we evaluate this method using the rober system, a benchmark model in chemical kinetics, to compare its performance with traditional numerical techniques. this study provides insight into the industrial utility of the recently developed mlp-mixer architecture to model chemical kinetics and provides motivation for such neural architecture to be used as a base for time-series foundation models.",,2024-08-20,,"['imran nasim', 'joaõ lucas de sousa almeida']"
1706,2408.10722,megen: generative backdoor in large language models via model editing,cs.cl cs.ai,"large language models (llms) have demonstrated remarkable capabilities. their powerful generative abilities enable flexible responses based on various queries or instructions. emerging as widely adopted generalists for diverse tasks, llms are still vulnerable to backdoors. this paper proposes an editing-based generative backdoor, named megen, aiming to create a customized backdoor for nlp tasks with the least side effects. in our approach, we first leverage a language model to insert a trigger selected on fixed metrics into the input, then design a pipeline of model editing to directly embed a backdoor into an llm. by adjusting a small set of local parameters with a mini-batch of samples, megen significantly enhances time efficiency and achieves high robustness. experimental results indicate that our backdoor attack strategy achieves a high attack success rate on poison data while maintaining the model's performance on clean data. notably, the backdoored model, when triggered, can freely output pre-set dangerous information while successfully completing downstream tasks. this suggests that future llm applications could be guided to deliver certain dangerous information, thus altering the llm's generative style. we believe this approach provides insights for future llm applications and the execution of backdoor attacks on conversational ai systems.",,2024-08-20,,"['jiyang qiu', 'xinbei ma', 'zhuosheng zhang', 'hai zhao']"
1707,2408.10724,"crafting tomorrow's headlines: neural news generation and detection in   english, turkish, hungarian, and persian",cs.cl,"in the era dominated by information overload and its facilitation with large language models (llms), the prevalence of misinformation poses a significant threat to public discourse and societal well-being. a critical concern at present involves the identification of machine-generated news. in this work, we take a significant step by introducing a benchmark dataset designed for neural news detection in four languages: english, turkish, hungarian, and persian. the dataset incorporates outputs from multiple multilingual generators (in both, zero-shot and fine-tuned setups) such as bloomz, llama-2, mistral, mixtral, and gpt-4. next, we experiment with a variety of classifiers, ranging from those based on linguistic features to advanced transformer-based models and llms prompting. we present the detection results aiming to delve into the interpretablity and robustness of machine-generated texts detectors across all target languages.",,2024-08-20,,"['cem üyük', 'danica rovó', 'shaghayegh kolli', 'rabia varol', 'georg groh', 'daryna dementieva']"
1708,2408.10726,quantum artificial intelligence: a brief survey,quant-ph cs.ai,"quantum artificial intelligence (qai) is the intersection of quantum computing and ai, a technological synergy with expected significant benefits for both. in this paper, we provide a brief overview of what has been achieved in qai so far and point to some open questions for future research. in particular, we summarize some major key findings on the feasability and the potential of using quantum computing for solving computationally hard problems in various subfields of ai, and vice versa, the leveraging of ai methods for building and operating quantum computing devices.",,2024-08-20,,"['matthias klusch', 'jörg lässig', 'daniel müssig', 'antonio macaluso', 'frank k. wilhelm']"
1709,2408.10729,towards efficient large language models for scientific text: a review,cs.cl cs.ai,"large language models (llms) have ushered in a new era for processing complex information in various fields, including science. the increasing amount of scientific literature allows these models to acquire and understand scientific knowledge effectively, thus improving their performance in a wide range of tasks. due to the power of llms, they require extremely expensive computational resources, intense amounts of data, and training time. therefore, in recent years, researchers have proposed various methodologies to make scientific llms more affordable. the most well-known approaches align in two directions. it can be either focusing on the size of the models or enhancing the quality of data. to date, a comprehensive review of these two families of methods has not yet been undertaken. in this paper, we (i) summarize the current advances in the emerging abilities of llms into more accessible ai solutions for science, and (ii) investigate the challenges and opportunities of developing affordable solutions for scientific domains using llms.",,2024-08-20,,"['huy quoc to', 'ming liu', 'guangyan huang']"
1710,2408.10731,towards reliable real-time trajectory optimization,cs.ro cs.sy eess.sy,"motion planning is a key aspect of robotics. a common approach to address motion planning problems is trajectory optimization. trajectory optimization can represent the high-level behaviors of robots through mathematical formulations. however, current trajectory optimization approaches have two main challenges. firstly, their solution heavily depends on the initial guess, and they are prone to get stuck in local minima. secondly, they face scalability limitations by increasing the number of constraints. this thesis endeavors to tackle these challenges by introducing four innovative trajectory optimization algorithms to improve reliability, scalability, and computational efficiency. there are two novel aspects of the proposed algorithms. the first key innovation is remodeling the kinematic constraints and collision avoidance constraints. another key innovation lies in the design of algorithms that effectively utilize parallel computation on gpu accelerators. by using reformulated constraints and leveraging the computational power of gpus, the proposed algorithms of this thesis demonstrate significant improvements in efficiency and scalability compared to the existing methods. parallelization enables faster computation times, allowing for real-time decision-making in dynamic environments. moreover, the algorithms are designed to adapt to changes in the environment, ensuring robust performance. extensive benchmarking for each proposed optimizer validates their efficacy. overall, this thesis makes a significant contribution to the field of trajectory optimization algorithms. it introduces innovative solutions that specifically address the challenges faced by existing methods. the proposed algorithms pave the way for more efficient and robust motion planning solutions in robotics by leveraging parallel computation and specific mathematical structures.",,2024-08-20,,['fatemeh rastgar']
1711,2408.10733,classification of endoscopy and video capsule images using   cnn-transformer model,eess.iv cs.cv,"gastrointestinal cancer is a leading cause of cancer-related incidence and death, making it crucial to develop novel computer-aided diagnosis systems for early detection and enhanced treatment. traditional approaches rely on the expertise of gastroenterologists to identify diseases; however, this process is subjective, and interpretation can vary even among expert clinicians. considering recent advancements in classifying gastrointestinal anomalies and landmarks in endoscopic and video capsule endoscopy images, this study proposes a hybrid model that combines the advantages of transformers and convolutional neural networks (cnns) to enhance classification performance. our model utilizes densenet201 as a cnn branch to extract local features and integrates a swin transformer branch for global feature understanding, combining both to perform the classification task. for the gastrovision dataset, our proposed model demonstrates excellent performance with precision, recall, f1 score, accuracy, and matthews correlation coefficient (mcc) of 0.8320, 0.8386, 0.8324, 0.8386, and 0.8191, respectively, showcasing its robustness against class imbalance and surpassing other cnns as well as the swin transformer model. similarly, for the kvasir-capsule, a large video capsule endoscopy dataset, our model outperforms all others, achieving overall precision, recall, f1 score, accuracy, and mcc of 0.7007, 0.7239, 0.6900, 0.7239, and 0.3871. moreover, we generated saliency maps to explain our model's focus areas, demonstrating its reliable decision-making process. the results underscore the potential of our hybrid cnn-transformer model in aiding the early and accurate detection of gastrointestinal (gi) anomalies.",,2024-08-20,,"['aliza subedi', 'smriti regmi', 'nisha regmi', 'bhumi bhusal', 'ulas bagci', 'debesh jha']"
1712,2408.10734,vector symbolic open source information discovery,cs.ir,"combined, joint, intra-governmental, inter-agency and multinational (cjiim) operations require rapid data sharing without the bottlenecks of metadata curation and alignment. curation and alignment is particularly infeasible for external open source information (osinf), e.g., social media, which has become increasingly valuable in understanding unfolding situations. large language models (transformers) facilitate semantic data and metadata alignment but are inefficient in cjiim settings characterised as denied, degraded, intermittent and low bandwidth (ddil). vector symbolic architectures (vsa) support semantic information processing using highly compact binary vectors, typically 1-10k bits, suitable in a ddil setting. we demonstrate a novel integration of transformer models with vsa, combining the power of the former for semantic matching with the compactness and representational structure of the latter. the approach is illustrated via a proof-of-concept osinf data discovery portal that allows partners in a cjiim operation to share data sources with minimal metadata curation and low communications bandwidth. this work was carried out as a bridge between previous low technology readiness level (trl) research and future higher-trl technology demonstration and deployment.",10.1117/12.3013447,2024-08-20,,"['cai davies', 'sam meek', 'philip hawkins', 'benomy tutcher', 'graham bent', 'alun preece']"
1713,2408.10737,mid-band extra large-scale mimo system: channel modeling and performance   analysis,cs.it eess.sp math.it,"in pursuit of enhanced quality of service and higher transmission rates, communication within the mid-band spectrum, such as bands in the 6-15 ghz range, combined with extra large-scale multiple-input multiple-output (xl-mimo), is considered a potential enabler for future communication systems. however, the characteristics introduced by mid-band xl-mimo systems pose challenges for channel modeling and performance analysis. in this paper, we first analyze the potential characteristics of mid-band mimo channels. then, an analytical channel model incorporating novel channel characteristics is proposed, based on a review of classical analytical channel models. this model is convenient for theoretical analysis and compatible with other analytical channel models. subsequently, based on the proposed channel model, we analyze key metrics of wireless communication, including the ergodic spectral efficiency (se) and outage probability (op) of mimo maximal-ratio combining systems. specifically, we derive closed-form approximations and performance bounds for two typical scenarios, aiming to illustrate the influence of mid-band xl-mimo systems. finally, comparisons between systems under different practical configurations are carried out through simulations. the theoretical analysis and simulations demonstrate that mid-band xl-mimo systems excel in se and op due to the increased array elements, moderate large-scale fading, and enlarged transmission bandwidth.",,2024-08-20,,"['jiachen tian', 'yu han', 'xiao li', 'shi jin', 'chao-kai wen']"
1714,2408.10738,phishagent: a robust multimodal agent for phishing webpage detection,cs.cr,"phishing attacks are a major threat to online security, exploiting user vulnerabilities to steal sensitive information. various methods have been developed to counteract phishing, each with varying levels of accuracy, but they also encounter notable limitations. in this study, we introduce phishagent, a multimodal agent that combines a wide range of tools, integrating both online and offline knowledge bases with multimodal large language models (mllms). this combination leads to broader brand coverage, which enhances brand recognition and recall. furthermore, we propose a multimodal information retrieval framework designed to extract the top k relevant items from offline knowledge bases, utilizing all available information from a webpage, including logos, html, and urls. our empirical results, based on three real-world datasets, demonstrate that the proposed framework significantly enhances detection accuracy and reduces both false positives and false negatives, while maintaining model efficiency. additionally, phishagent shows strong resilience against various types of adversarial attacks.",,2024-08-20,,"['tri cao', 'chengyu huang', 'yuexin li', 'huilin wang', 'amy he', 'nay oo', 'bryan hooi']"
1715,2408.10739,tracknerf: bundle adjusting nerf from sparse and noisy views via feature   tracks,cs.cv,"neural radiance fields (nerfs) generally require many images with accurate poses for accurate novel view synthesis, which does not reflect realistic setups where views can be sparse and poses can be noisy. previous solutions for learning nerfs with sparse views and noisy poses only consider local geometry consistency with pairs of views. closely following \textit{bundle adjustment} in structure-from-motion (sfm), we introduce tracknerf for more globally consistent geometry reconstruction and more accurate pose optimization. tracknerf introduces \textit{feature tracks}, \ie connected pixel trajectories across \textit{all} visible views that correspond to the \textit{same} 3d points. by enforcing reprojection consistency among feature tracks, tracknerf encourages holistic 3d consistency explicitly. through extensive experiments, tracknerf sets a new benchmark in noisy and sparse view reconstruction. in particular, tracknerf shows significant improvements over the state-of-the-art barf and sparf by $\sim8$ and $\sim1$ in terms of psnr on dtu under various sparse and noisy view setups. the code is available at \href{https://tracknerf.github.io/}.",,2024-08-20,,"['jinjie mai', 'wenxuan zhu', 'sara rojas', 'jesus zarzar', 'abdullah hamdi', 'guocheng qian', 'bing li', 'silvio giancola', 'bernard ghanem']"
1716,2408.10743,fast algorithms and implementations for computing the minimum distance   of quantum codes,quant-ph cs.ce cs.it cs.ms math.it,"the distance of a stabilizer quantum code is a very important feature since it determines the number of errors that can be detected and corrected. we present three new fast algorithms and implementations for computing the symplectic distance of the associated classical code. our new algorithms are based on the brouwer-zimmermann algorithm. our experimental study shows that these new implementations are much faster than current state-of-the-art licensed implementations on single-core processors, multicore processors, and shared-memory multiprocessors. in the most computationally-demanding cases, the performance gain in the computational time can be larger than one order of magnitude. the experimental study also shows a good scalability on shared-memory parallel architectures.",,2024-08-20,,"['fernando hernando', 'gregorio quintana-ortí', 'markus grassl']"
1717,2408.10746,pluto and charon: a time and memory efficient collaborative edge ai   framework for personal llms fine-tuning,cs.dc cs.ai cs.lg cs.ni,"large language models (llms) have unlocked a plethora of powerful applications at the network edge, such as intelligent personal assistants. data privacy and security concerns have prompted a shift towards edge-based fine-tuning of personal llms, away from cloud reliance. however, this raises issues of computational intensity and resource scarcity, hindering training efficiency and feasibility. while current studies investigate parameter-efficient fine-tuning (peft) techniques to mitigate resource constraints, our analysis indicates that these techniques are not sufficiently resource-efficient for edge devices. to tackle these challenges, we propose pluto and charon (pac), a time and memory efficient collaborative edge ai framework for personal llms fine-tuning. pac breaks the resource wall of personal llms fine-tuning with a sophisticated algorithm-system co-design. (1) algorithmically, pac implements a personal llms fine-tuning technique that is efficient in terms of parameters, time, and memory. it utilizes parallel adapters to circumvent the need for a full backward pass through the llm backbone. additionally, an activation cache mechanism further streamlining the process by negating the necessity for repeated forward passes across multiple epochs. (2) systematically, pac leverages edge devices in close proximity, pooling them as a collective resource for in-situ personal llms fine-tuning, utilizing a hybrid data and pipeline parallelism to orchestrate distributed training. the use of the activation cache eliminates the need for forward pass through the llm backbone,enabling exclusive fine-tuning of the parallel adapters using data parallelism. extensive evaluation based on prototype implementation demonstrates that pac remarkably outperforms state-of-the-art approaches, achieving up to 8.64x end-to-end speedup and up to 88.16% reduction in memory footprint.",,2024-08-20,,"['bei ouyang', 'shengyuan ye', 'liekang zeng', 'tianyi qian', 'jingyi li', 'xu chen']"
1718,2408.10752,security assessment of hierarchical federated deep learning,cs.lg cs.ai cs.cr,"hierarchical federated learning (hfl) is a promising distributed deep learning model training paradigm, but it has crucial security concerns arising from adversarial attacks. this research investigates and assesses the security of hfl using a novel methodology by focusing on its resilience against adversarial attacks inference-time and training-time. through a series of extensive experiments across diverse datasets and attack scenarios, we uncover that hfl demonstrates robustness against untargeted training-time attacks due to its hierarchical structure. however, targeted attacks, particularly backdoor attacks, exploit this architecture, especially when malicious clients are positioned in the overlapping coverage areas of edge servers. consequently, hfl shows a dual nature in its resilience, showcasing its capability to recover from attacks thanks to its hierarchical aggregation that strengthens its suitability for adversarial training, thereby reinforcing its resistance against inference-time attacks. these insights underscore the necessity for balanced security strategies in hfl systems, leveraging their inherent strengths while effectively mitigating vulnerabilities.",,2024-08-20,,"['d alqattan', 'r sun', 'h liang', 'g nicosia', 'v snasel', 'r ranjan', 'v ojha']"
1719,2408.10754,ghost echoes revealed: benchmarking maintainability metrics and machine   learning predictions against human assessments,cs.se,"as generative ai is expected to increase global code volumes, the importance of maintainability from a human perspective will become even greater. various methods have been developed to identify the most important maintainability issues, including aggregated metrics and advanced machine learning (ml) models. this study benchmarks several maintainability prediction approaches, including state-of-the-art (sota) ml, sonarqube's maintainability rating, codescene's code health, and microsoft's maintainability index. our results indicate that codescene matches the accuracy of sota ml and outperforms the average human expert. importantly, unlike sota ml, codescene also provides end users with actionable code smell details to remedy identified issues. finally, caution is advised with sonarqube due to its tendency to generate many false positives. unfortunately, our findings call into question the validity of previous studies that solely relied on sonarqube output for establishing ground truth labels. to improve reliability in future maintainability and technical debt studies, we recommend employing more accurate metrics. moreover, reevaluating previous findings with code health would mitigate this revealed validity threat.",,2024-08-20,,"['markus borg', 'marwa ezzouhri', 'adam tornhill']"
1720,2408.10755,generating synthetic fair syntax-agnostic data by learning and   distilling fair representation,cs.lg cs.ai,"data fairness is a crucial topic due to the recent wide usage of ai powered applications. most of the real-world data is filled with human or machine biases and when those data are being used to train ai models, there is a chance that the model will reflect the bias in the training data. existing bias-mitigating generative methods based on gans, diffusion models need in-processing fairness objectives and fail to consider computational overhead while choosing computationally-heavy architectures, which may lead to high computational demands, instability and poor optimization performance. to mitigate this issue, in this work, we present a fair data generation technique based on knowledge distillation, where we use a small architecture to distill the fair representation in the latent space. the idea of fair latent space distillation enables more flexible and stable training of fair generative models (fgms). we first learn a syntax-agnostic (for any data type) fair representation of the data, followed by distillation in the latent space into a smaller model. after distillation, we use the distilled fair latent space to generate high-fidelity fair synthetic data. while distilling, we employ quality loss (for fair distillation) and utility loss (for data utility) to ensure that the fairness and data utility characteristics remain in the distilled latent space. our approaches show a 5%, 5% and 10% rise in performance in fairness, synthetic sample quality and data utility, respectively, than the state-of-the-art fair generative model.",,2024-08-20,,"['md fahim sikder', 'resmi ramachandranpillai', 'daniel de leng', 'fredrik heintz']"
1721,2408.10756,data ethics and practices of human-nonhuman sound technologies and   ecologies,cs.hc,"human-nonhuman sound interaction and technologies aim to bridge the gap of inter-species communication. while they emerge from attempts to understand and communicate with nonhumans, they also raise questions on the ethics of nonhuman data use, for example regarding the unintended consequences such data extraction can have to nonhumans. in this paper, we discuss power relations and aspects of representation in nonhuman data practices, and their potential critical implications to nonhumans. drawing from prior research on data ethics and posthumanities, we conceptualize two challenges of nonhuman data ethics for the design of human-nonhuman interaction (hni) and technologies in sound ecologies. we provide takeaways for how sensitivities toward nonhuman stakeholders can be considered in the design of hni in the context of sound ecologies.",,2024-08-20,,"['petra jääskeläinen', 'elin kanhov']"
1722,2408.10757,decreasing verification radius in local certification,cs.dc,"this paper deals with local certification, specifically locally checkable proofs: given a graph property, the task is to certify whether a graph satisfies the property. the verification of this certification needs to be done locally without the knowledge of the whole graph. more precisely, a distributed algorithm, called a verifier, is executed on each vertex. the verifier observes the local neighborhood up to a constant distance and either accepts or rejects. we examine the trade-off between the visibility radius and the size of certificates. we describe a procedure that decreases the radius by encoding the neighbourhood of each vertex into its certificate. we also provide a corresponding lower bound on the required certificate size increase, showing that such an approach is close to optimal.",,2024-08-20,,"['laurent feuilloley', 'jan janoušek', 'jan matyáš křišťan', 'josef erik sedláček']"
1723,2408.10758,does co-development with ai assistants lead to more maintainable code? a   registered report,cs.se,"[background/context] ai assistants like github copilot are transforming software engineering; several studies have highlighted productivity improvements. however, their impact on code quality, particularly in terms of maintainability, requires further investigation. [objective/aim] this study aims to examine the influence of ai assistants on software maintainability, specifically assessing how these tools affect the ability of developers to evolve code. [method] we will conduct a two-phased controlled experiment involving professional developers. in phase 1, developers will add a new feature to a java project, with or without the aid of an ai assistant. phase 2, a randomized controlled trial, will involve a different set of developers evolving random phase 1 projects - working without ai assistants. we will employ bayesian analysis to evaluate differences in completion time, perceived productivity, code quality, and test coverage.",,2024-08-20,,"['markus borg', 'dave hewett', 'donald graham', 'noric couderc', 'emma söderberg', 'luke church', 'dave farley']"
1724,2408.1076,sam-cod: sam-guided unified framework for weakly-supervised camouflaged   object detection,cs.cv cs.ai,"most camouflaged object detection (cod) methods heavily rely on mask annotations, which are time-consuming and labor-intensive to acquire. existing weakly-supervised cod approaches exhibit significantly inferior performance compared to fully-supervised methods and struggle to simultaneously support all the existing types of camouflaged object labels, including scribbles, bounding boxes, and points. even for segment anything model (sam), it is still problematic to handle the weakly-supervised cod and it typically encounters challenges of prompt compatibility of the scribble labels, extreme response, semantically erroneous response, and unstable feature representations, producing unsatisfactory results in camouflaged scenes. to mitigate these issues, we propose a unified cod framework in this paper, termed sam-cod, which is capable of supporting arbitrary weakly-supervised labels. our sam-cod employs a prompt adapter to handle scribbles as prompts based on sam. meanwhile, we introduce response filter and semantic matcher modules to improve the quality of the masks obtained by sam under cod prompts. to alleviate the negative impacts of inaccurate mask predictions, a new strategy of prompt-adaptive knowledge distillation is utilized to ensure a reliable feature representation. to validate the effectiveness of our approach, we have conducted extensive empirical experiments on three mainstream cod benchmarks. the results demonstrate the superiority of our method against state-of-the-art weakly-supervised and even fully-supervised methods.",,2024-08-20,,"['huafeng chen', 'pengxu wei', 'guangqian guo', 'shan gao']"
1725,2408.10761,on the power of graphical reconfigurable circuits,cs.dc,"we introduce the \emph{graphical reconfigurable circuits (grc)} model as an abstraction for distributed graph algorithms whose communication scheme is based on local mechanisms that collectively construct long-range reconfigurable channels (this is an extension to general graphs of a distributed computational model recently introduced by feldmann et al.\ (jcb 2022) for hexagonal grids). the crux of the grc model lies in its modest assumptions: (1) the individual nodes are computationally weak, with state space bounded independently of any global graph parameter; and (2) the reconfigurable communication channels are highly restrictive, only carrying information-less signals (a.k.a.\ \emph{beeps}). despite these modest assumptions, we prove that grc algorithms can solve many important distributed tasks efficiently, i.e., in polylogarithmic time. on the negative side, we establish various runtime lower bounds, proving that for other tasks, grc algorithms (if they exist) are doomed to be slow.",,2024-08-20,,"['yuval emek', 'yuval gil', 'noga harlev']"
1726,2408.10763,analyzing the impact of electric vehicles on local energy systems using   digital twins,cs.ma,"the electrification of the transportation and heating sector, the so-called sector coupling, is one of the core elements to achieve independence from fossil fuels. as it highly affects the electricity demand, especially on the local level, the integrated modeling and simulation of all sectors is a promising approach for analyzing design decisions or complex control strategies. this paper analyzes the increase in electricity demand resulting from sector coupling, mainly due to integrating electric vehicles into urban energy systems. therefore, we utilize a digital twin of an existing local energy system and extend it with a mobility simulation model to evaluate the impact of electric vehicles on the distribution grid level. our findings indicate a significant rise in annual electricity consumption attributed to electric vehicles, with home charging alone resulting in a 78% increase. however, we demonstrate that integrating photovoltaic and battery energy storage systems can effectively mitigate this rise.",,2024-08-20,,"['daniel rené bayer', 'marco pruckner']"
1727,2408.10764,predicting rewards alongside tokens: non-disruptive parameter insertion   for efficient inference intervention in large language model,cs.cl,"transformer-based large language models (llms) exhibit limitations such as generating unsafe responses, unreliable reasoning, etc. existing inference intervention approaches attempt to mitigate these issues by finetuning additional models to produce calibration signals (such as rewards) that guide the llm's decoding process. however, this solution introduces substantial time and space overhead due to the separate models required. this work proposes non-disruptive parameters insertion (otter), inserting extra parameters into the transformer architecture to predict calibration signals along with the original llm output. otter offers state-of-the-art performance on multiple demanding tasks while saving up to 86.5\% extra space and 98.5\% extra time. furthermore, otter seamlessly integrates with existing inference engines, requiring only a one-line code change, and the original model response remains accessible after the parameter insertion. our code is publicly available at \url{https://github.com/chenhan97/otter}",,2024-08-20,,"['chenhan yuan', 'fei huang', 'ru peng', 'keming lu', 'bowen yu', 'chang zhou', 'jingren zhou']"
1728,2408.10766,an open source python library for anonymizing sensitive data,cs.cr cs.db cs.se,"open science is a fundamental pillar to promote scientific progress and collaboration, based on the principles of open data, open source and open access. however, the requirements for publishing and sharing open data are in many cases difficult to meet in compliance with strict data protection regulations. consequently, researchers need to rely on proven methods that allow them to anonymize their data without sharing it with third parties. to this end, this paper presents the implementation of a python library for the anonymization of sensitive tabular data. this framework provides users with a wide range of anonymization methods that can be applied on the given dataset, including the set of identifiers, quasi-identifiers, generalization hierarchies and allowed level of suppression, along with the sensitive attribute and the level of anonymity required. the library has been implemented following best practices for integration and continuous development, as well as the use of workflows to test code coverage based on unit and functional tests.",,2024-08-20,,"['judith sáinz-pardo díaz', 'álvaro lópez garcía']"
1729,2408.10768,detection of intracranial hemorrhage for trauma patients,cs.cv,"whole-body ct is used for multi-trauma patients in the search of any and all injuries. since an initial assessment needs to be rapid and the search for lesions is done for the whole body, very little time can be allocated for the inspection of a specific anatomy. in particular, intracranial hemorrhages are still missed, especially by clinical students. in this work, we present a deep learning approach for highlighting such lesions to improve the diagnostic accuracy. while most works on intracranial hemorrhages perform segmentation, detection only requires bounding boxes for the localization of the bleeding. in this paper, we propose a novel voxel-complete iou (vc-iou) loss that encourages the network to learn the 3d aspect ratios of bounding boxes and leads to more precise detections. we extensively experiment on brain bleeding detection using a publicly available dataset, and validate it on a private cohort, where we achieve 0.877 ar30, 0.728 ap30, and 0.653 ar30, 0.514 ap30 respectively. these results constitute a relative +5% improvement in average recall for both datasets compared to other loss functions. finally, as there is little data currently publicly available for 3d object detection and as annotation resources are limited in the clinical setting, we evaluate the cost of different annotation methods, as well as the impact of imprecise bounding boxes in the training data on the detection performance.",,2024-08-20,,"['antoine p. sanner', 'nils f. grauhan', 'marc a. brockmann', 'ahmed e. othman', 'anirban mukhopadhyay']"
1730,2408.10769,a wild sheep chase through an orchard,q-bio.pe cs.cc math.co,"orchards are a biologically relevant class of phylogenetic networks as they can describe treelike evolutionary histories augmented with horizontal transfer events. moreover, the class has attractive mathematical characterizations that can be exploited algorithmically. on the other hand, undirected orchard networks have hardly been studied yet. here, we prove that deciding whether an undirected, binary phylogenetic network is an orchard -- or equivalently, whether it has an orientation that makes it a rooted orchard -- is np-hard. for this, we introduce a new characterization of undirected orchards which could be useful for proving positive results.",,2024-08-20,,"['jordan dempsey', 'leo van iersel', 'mark jones', 'yukihiro murakami', 'norbert zeh']"
1731,2408.10771,ssl-tts: leveraging self-supervised embeddings and knn retrieval for   zero-shot multi-speaker tts,eess.as cs.ai cs.lg cs.sd,"while recent zero-shot multispeaker text-to-speech (tts) models achieve impressive results, they typically rely on extensive transcribed speech datasets from numerous speakers and intricate training pipelines. meanwhile, self-supervised learning (ssl) speech features have emerged as effective intermediate representations for tts. it was also observed that ssl features from different speakers that are linearly close share phonetic information while maintaining individual speaker identity, which enables straight-forward and robust voice cloning. in this study, we introduce ssl-tts, a lightweight and efficient zero-shot tts framework trained on transcribed speech from a single speaker. ssl-tts leverages ssl features and retrieval methods for simple and robust zero-shot multi-speaker synthesis. objective and subjective evaluations show that our approach achieves performance comparable to state-of-the-art models that require significantly larger training datasets. the low training data requirements mean that ssl-tts is well suited for the development of multi-speaker tts systems for low-resource domains and languages. we also introduce an interpolation parameter which enables fine control over the output speech by blending voices. demo samples are available at https://idiap.github.io/ssl-tts",,2024-08-20,,"['karl el hajal', 'ajinkya kulkarni', 'enno hermann', 'mathew magimai. -doss']"
1732,2408.10773,multi-agent based simulation for investigating centralized charging   strategies and their impact on electric vehicle home charging ecosystem,cs.ma,"this paper addresses the critical integration of electric vehicles (evs) into the electricity grid, which is essential for achieving carbon neutrality by 2050. the rapid increase in ev adoption poses significant challenges to the existing grid infrastructure, particularly in managing the increasing electricity demand and mitigating the risk of grid overloads. centralized ev charging strategies are investigated due to their potential to optimize grid stability and efficiency, compared to decentralized approaches that may exacerbate grid stress. utilizing a multi-agent based simulation model, the study provides a realistic representation of the electric vehicle home charging ecosystem in a case study of strib, denmark. the findings show that the earliest-deadline-first and round robin perform best with 100% ev adoption in terms of ev user satisfaction. the simulation considers a realistic adoption curve, ev charging strategies, ev models, and driving patterns to capture the full ecosystem dynamics over a long-term period with high resolution (hourly). additionally, the study offers detailed load profiles for future distribution grids, demonstrating how centralized charging strategies can efficiently manage grid loads and prevent overloads.",,2024-08-20,,"['kristoffer christensen', 'bo nørregaard jørgensen', 'zheng grace ma']"
1733,2408.10777,just a hint: point-supervised camouflaged object detection,cs.cv cs.ai,"camouflaged object detection (cod) demands models to expeditiously and accurately distinguish objects which conceal themselves seamlessly in the environment. owing to the subtle differences and ambiguous boundaries, cod is not only a remarkably challenging task for models but also for human annotators, requiring huge efforts to provide pixel-wise annotations. to alleviate the heavy annotation burden, we propose to fulfill this task with the help of only one point supervision. specifically, by swiftly clicking on each object, we first adaptively expand the original point-based annotation to a reasonable hint area. then, to avoid partial localization around discriminative parts, we propose an attention regulator to scatter model attention to the whole object through partially masking labeled regions. moreover, to solve the unstable feature representation of camouflaged objects under only point-based annotation, we perform unsupervised contrastive learning based on differently augmented image pairs (e.g. changing color or doing translation). on three mainstream cod benchmarks, experimental results show that our model outperforms several weakly-supervised methods by a large margin across various metrics.",,2024-08-20,,"['huafeng chen', 'dian shao', 'guangqian guo', 'shan gao']"
1734,2408.10779,the power of abstract mac layer: a fault-tolerance perspective,cs.dc,"this paper studies the power of the ""abstract mac layer"" model in a single-hop asynchronous network. the model captures primitive properties of modern wireless mac protocols. in this model, newport [podc '14] proves that it is impossible to achieve deterministic consensus when nodes may crash. subsequently, newport and robinson [disc '18] present randomized consensus algorithms that terminate with o(n3 log n) expected broadcasts in a system of n nodes. we are not aware of any results on other fault-tolerant distributed tasks in this model.   we first study the computability aspect of the abstract mac layer. we present a wait-free algorithm that implements an atomic register. furthermore, we show that in general, k-set consensus is impossible. second, we aim to minimize storage complexity. existing algorithms require {\omega}(n log n) bits. we propose four wait-free consensus algorithms that only need constant storage complexity. (two approximate consensus and two randomized binary consensus algorithms.) one randomized algorithm terminates with o(n log n) expected broadcasts. all our consensus algorithms are anonymous, meaning that at the algorithm level, nodes do not need to have a unique identifier.",,2024-08-20,,"['qinzi zhang', 'lewis tseng']"
1735,2408.10783,multi-agent based modeling for investigating excess heat utilization   from electrolyzer production to district heating network,cs.ma,"power-to-hydrogen is crucial for the renewable energy transition, yet existing literature lacks business models for the significant excess heat it generates. this study addresses this by evaluating three models for selling electrolyzer-generated heat to district heating grids: constant, flexible, and renewable-source hydrogen production, with and without heat sales. using agent-based modeling and multi-criteria decision-making methods (vikor, topsis, promethee), it finds that selling excess heat can cut hydrogen production costs by 5.6%. the optimal model operates flexibly with electricity spot prices, includes heat sales, and maintains a hydrogen price of 3.3 eur/kg. environmentally, hydrogen production from grid electricity could emit up to 13,783.8 tons of co2 over four years from 2023. the best economic and environmental model uses renewable sources and sells heat at 3.5 eur/kg",,2024-08-20,,"['kristoffer christensen', 'bo nørregaard jørgensen', 'zheng grace ma']"
1736,2408.10787,lightmdetr: a lightweight approach for low-cost open-vocabulary object   detection training,cs.cv cs.lg,"object detection in computer vision traditionally involves identifying objects in images. by integrating textual descriptions, we enhance this process, providing better context and accuracy. the mdetr model significantly advances this by combining image and text data for more versatile object detection and classification. however, mdetr's complexity and high computational demands hinder its practical use. in this paper, we introduce lightweight mdetr (lightmdetr), an optimized mdetr variant designed for improved computational efficiency while maintaining robust multimodal capabilities. our approach involves freezing the mdetr backbone and training a sole component, the deep fusion encoder (dfe), to represent image and text modalities. a learnable context vector enables the dfe to switch between these modalities. evaluation on datasets like refcoco, refcoco+, and refcocog demonstrates that lightmdetr achieves superior precision and accuracy.",,2024-08-20,,"['binta sow', 'bilal faye', 'hanane azzag', 'mustapha lebbah']"
1737,2408.10788,understanding the skills gap between higher education and industry in   the uk in artificial intelligence sector,cs.ai,"as artificial intelligence (ai) changes how businesses work, there is a growing need for people who can work in this sector. this paper investigates how well universities in united kingdom offering courses in ai, prepare students for jobs in the real world. to gain insight into the differences between university curricula and industry demands we review the contents of taught courses and job advertisement portals. by using custom data scraping tools to gather information from job advertisements and university curricula, and frequency and naive bayes classifier analysis, this study will show exactly what skills industry is looking for. in this study we identified 12 skill categories that were used for mapping. the study showed that the university curriculum in the ai domain is well balanced in most technical skills, including programming and machine learning subjects, but have a gap in data science and maths and statistics skill categories.",,2024-08-20,,"['khushi jaiswal', 'ievgeniia kuzminykh', 'sanjay modgil']"
1738,2408.10789,learning part-aware 3d representations by fusing 2d gaussians and   superquadrics,cs.cv,"low-level 3d representations, such as point clouds, meshes, nerfs, and 3d gaussians, are commonly used to represent 3d objects or scenes. however, humans usually perceive 3d objects or scenes at a higher level as a composition of parts or structures rather than points or voxels. representing 3d as semantic parts can benefit further understanding and applications. we aim to solve part-aware 3d reconstruction, which parses objects or scenes into semantic parts. in this paper, we introduce a hybrid representation of superquadrics and 2d gaussians, trying to dig 3d structural clues from multi-view image inputs. accurate structured geometry reconstruction and high-quality rendering are achieved at the same time. we incorporate parametric superquadrics in mesh forms into 2d gaussians by attaching gaussian centers to faces in meshes. during the training, superquadrics parameters are iteratively optimized, and gaussians are deformed accordingly, resulting in an efficient hybrid representation. on the one hand, this hybrid representation inherits the advantage of superquadrics to represent different shape primitives, supporting flexible part decomposition of scenes. on the other hand, 2d gaussians are incorporated to model the complex texture and geometry details, ensuring high-quality rendering and geometry reconstruction. the reconstruction is fully unsupervised. we conduct extensive experiments on data from dtu and shapenet datasets, in which the method decomposes scenes into reasonable parts, outperforming existing state-of-the-art approaches.",,2024-08-20,,"['zhirui gao', 'renjiao yi', 'yuhang huang', 'wei chen', 'chenyang zhu', 'kai xu']"
1739,2408.1079,multi-agent based simulation for decentralized electric vehicle charging   strategies and their impacts,cs.ma,"the growing shift towards a smart grid involves integrating numerous new digital energy solutions into the energy ecosystems to address problems arising from the transition to carbon neutrality, particularly in linking the electricity and transportation sectors. yet, this shift brings challenges due to mass electric vehicle adoption and the lack of methods to adequately assess various ev charging algorithms and their ecosystem impacts. this paper introduces a multi-agent based simulation model, validated through a case study of a danish radial distribution network serving 126 households. the study reveals that traditional charging leads to grid overload by 2031 at 67% ev penetration, while decentralized strategies like real-time pricing could cause overloads as early as 2028. the developed multi-agent based simulation demonstrates its ability to offer detailed, hourly analysis of future load profiles in distribution grids, and therefore, can be applied to other prospective scenarios in similar energy systems.",,2024-08-20,,"['kristoffer christensen', 'bo nørregaard jørgensen', 'zheng grace ma']"
1740,2408.10791,exploring the impact of word prediction assistive features on smartphone   keyboards for blind users,cs.hc,"assistive technologies have been developed to enhance blind users' typing performance, focusing on speed, accuracy, and effort reduction. one such technology is word prediction software, designed to minimize keystrokes required for text input. this study investigates the impact of word prediction on typing performance among blind users using an on-screen qwerty keyboard. we conducted a comparative study involving eleven blind participants, evaluating both standard qwerty input and word prediction-assisted typing. our findings reveal that while word prediction slightly improves typing speed, it does not enhance typing accuracy and increases both physical and temporal workload compared to the default keyboard. we conclude with recommendations for improving word prediction systems, including more efficient editing methods and the integration of voice pitch variations to aid error recognition.",,2024-08-20,,"['mrim m. alnfiai', 'muhammad ashad kabir']"
1741,2408.10794,tapping in a remote vehicle's onboard llm to complement the ego   vehicle's field-of-view,cs.cv,"today's advanced automotive systems are turning into intelligent cyber-physical systems (cps), bringing computational intelligence to their cyber-physical context. such systems power advanced driver assistance systems (adas) that observe a vehicle's surroundings for their functionality. however, such adas have clear limitations in scenarios when the direct line-of-sight to surrounding objects is occluded, like in urban areas. imagine now automated driving (ad) systems that ideally could benefit from other vehicles' field-of-view in such occluded situations to increase traffic safety if, for example, locations about pedestrians can be shared across vehicles. current literature suggests vehicle-to-infrastructure (v2i) via roadside units (rsus) or vehicle-to-vehicle (v2v) communication to address such issues that stream sensor or object data between vehicles. when considering the ongoing revolution in vehicle system architectures towards powerful, centralized processing units with hardware accelerators, foreseeing the onboard presence of large language models (llms) to improve the passengers' comfort when using voice assistants becomes a reality. we are suggesting and evaluating a concept to complement the ego vehicle's field-of-view (fov) with another vehicle's fov by tapping into their onboard llm to let the machines have a dialogue about what the other vehicle ``sees''. our results show that very recent versions of llms, such as gpt-4v and gpt-4o, understand a traffic situation to an impressive level of detail, and hence, they can be used even to spot traffic participants. however, better prompts are needed to improve the detection quality and future work is needed towards a standardised message interchange format between vehicles.",,2024-08-20,,"['malsha ashani mahawatta dona', 'beatriz cabrero-daniel', 'yinan yu', 'christian berger']"
1742,2408.10795,adversarial attack for explanation robustness of rationalization models,cs.cl,"rationalization models, which select a subset of input text as rationale-crucial for humans to understand and trust predictions-have recently emerged as a prominent research area in explainable artificial intelligence. however, most of previous studies mainly focus on improving the quality of the rationale, ignoring its robustness to malicious attack. specifically, whether the rationalization models can still generate high-quality rationale under the adversarial attack remains unknown. to explore this, this paper proposes uat2e, which aims to undermine the explainability of rationalization models without altering their predictions, thereby eliciting distrust in these models from human users. uat2e employs the gradient-based search on triggers and then inserts them into the original input to conduct both the non-target and target attack. experimental results on five datasets reveal the vulnerability of rationalization models in terms of explanation, where they tend to select more meaningless tokens under attacks. based on this, we make a series of recommendations for improving rationalization models in terms of explanation.",,2024-08-20,,"['yuankai zhang', 'lingxiao kong', 'haozhao wang', 'ruixuan li', 'jun wang', 'yuhua li', 'wei liu']"
1743,2408.10796,honeyquest: rapidly measuring the enticingness of cyber deception   techniques with code-based questionnaires,cs.cr cs.cy,"fooling adversaries with traps such as honeytokens can slow down cyber attacks and create strong indicators of compromise. unfortunately, cyber deception techniques are often poorly specified. also, realistically measuring their effectiveness requires a well-exposed software system together with a production-ready implementation of these techniques. this makes rapid prototyping challenging. our work translates 13 previously researched and 12 self-defined techniques into a high-level, machine-readable specification. our open-source tool, honeyquest, allows researchers to quickly evaluate the enticingness of deception techniques without implementing them. we test the enticingness of 25 cyber deception techniques and 19 true security risks in an experiment with 47 humans. we successfully replicate the goals of previous work with many consistent findings, but without a time-consuming implementation of these techniques on real computer systems. we provide valuable insights for the design of enticing deception and also show that the presence of cyber deception can significantly reduce the risk that adversaries will find a true security risk by about 22% on average.",10.1145/3678890.3678897,2024-08-20,,"['mario kahlhofer', 'stefan achleitner', 'stefan rass', 'rené mayrhofer']"
1744,2408.10798,universal novelty detection through adaptive contrastive learning,cs.lg,"novelty detection is a critical task for deploying machine learning models in the open world. a crucial property of novelty detection methods is universality, which can be interpreted as generalization across various distributions of training or test data. more precisely, for novelty detection, distribution shifts may occur in the training set or the test set. shifts in the training set refer to cases where we train a novelty detector on a new dataset and expect strong transferability. conversely, distribution shifts in the test set indicate the methods' performance when the trained model encounters a shifted test sample. we experimentally show that existing methods falter in maintaining universality, which stems from their rigid inductive biases. motivated by this, we aim for more generalized techniques that have more adaptable inductive biases. in this context, we leverage the fact that contrastive learning provides an efficient framework to easily switch and adapt to new inductive biases through the proper choice of augmentations in forming the negative pairs. we propose a novel probabilistic auto-negative pair generation method autoaugood, along with contrastive learning, to yield a universal novelty detector method. our experiments demonstrate the superiority of our method under different distribution shifts in various image benchmark datasets. notably, our method emerges universality in the lens of adaptability to different setups of novelty detection, including one-class, unlabeled multi-class, and labeled multi-class settings. code: https://github.com/mojtaba-nafez/unode",,2024-08-20,,"['hossein mirzaei', 'mojtaba nafez', 'mohammad jafari', 'mohammad bagher soltani', 'mohammad azizmalayeri', 'jafar habibi', 'mohammad sabokrou', 'mohammad hossein rohban']"
1745,2408.10802,inverse deep learning ray tracing for heliostat surface prediction,cs.lg cs.ai,"concentrating solar power (csp) plants play a crucial role in the global transition towards sustainable energy. a key factor in ensuring the safe and efficient operation of csp plants is the distribution of concentrated flux density on the receiver. however, the non-ideal flux density generated by individual heliostats can undermine the safety and efficiency of the power plant. the flux density from each heliostat is influenced by its precise surface profile, which includes factors such as canting and mirror errors. accurately measuring these surface profiles for a large number of heliostats in operation is a formidable challenge. consequently, control systems often rely on the assumption of ideal surface conditions, which compromises both safety and operational efficiency. in this study, we introduce inverse deep learning ray tracing (idlr), an innovative method designed to predict heliostat surfaces based solely on target images obtained during heliostat calibration. our simulation-based investigation demonstrates that sufficient information regarding the heliostat surface is retained in the flux density distribution of a single heliostat, enabling deep learning models to accurately predict the underlying surface with deflectometry-like precision for the majority of heliostats. additionally, we assess the limitations of this method, particularly in relation to surface accuracy and resultant flux density predictions. furthermore, we are presenting a new comprehensive heliostat model using non-uniform rational b-spline (nurbs) that has the potential to become the new state of the art for heliostat surface parameterization. our findings reveal that idlr has significant potential to enhance csp plant operations, potentially increasing the overall efficiency and energy output of the power plants.",,2024-08-20,,"['jan lewen', 'max pargmann', 'mehdi cherti', 'jenia jitsev', 'robert pitz-paal', 'daniel maldonado quinto']"
1746,2408.10804,kotlin's type system is (also) unsound,cs.pl cs.se,"soundness of a type system is a fundemental property that guarantees that no operation that is not supported by a value will be performed on that value at run time. a type checker for a sound type system is expected to issue a warning on every type error. while soundness is a desirable property for many practical applications, in 2016, amin and tate presented the first unsoundness proof for two major industry languages: java and scala. this proof relied on use-site variance and implicit null values.   we present an unsoundness proof for kotlin, another emerging industry language, which relies on a previously unknown unsound combination of language features. kotlin does not have implicit null values, meaning that the proof by amin and tate would not work for kotlin. our new proof, which is an infringing code snippet, utilizes kotlin's \emph{declaration-site} variance specification and does not require implicit null values.   we present this counterexample to soundness in full along with detailed explanations of every step. finally, we present a thorough discussion on precisely which language features cause this issue, as well as how kotlin's compiler can be patched to fix it.",,2024-08-20,,"['elad kinsbruner', 'hila peleg', 'shachar itzhaky']"
1747,2408.10805,mpl: lifting 3d human pose from multi-view 2d poses,cs.cv,"estimating 3d human poses from 2d images is challenging due to occlusions and projective acquisition. learning-based approaches have been largely studied to address this challenge, both in single and multi-view setups. these solutions however fail to generalize to real-world cases due to the lack of (multi-view) 'in-the-wild' images paired with 3d poses for training. for this reason, we propose combining 2d pose estimation, for which large and rich training datasets exist, and 2d-to-3d pose lifting, using a transformer-based network that can be trained from synthetic 2d-3d pose pairs. our experiments demonstrate decreases up to 45% in mpjpe errors compared to the 3d pose obtained by triangulating the 2d poses. the framework's source code is available at https://github.com/aghasemzadeh/openmpl .",,2024-08-20,,"['seyed abolfazl ghasemzadeh', 'alexandre alahi', 'christophe de vleeschouwer']"
1748,2408.10807,dismix: disentangling mixtures of musical instruments for source-level   pitch and timbre manipulation,cs.sd cs.ai cs.lg eess.as,"existing work on pitch and timbre disentanglement has been mostly focused on single-instrument music audio, excluding the cases where multiple instruments are presented. to fill the gap, we propose dismix, a generative framework in which the pitch and timbre representations act as modular building blocks for constructing the melody and instrument of a source, and the collection of which forms a set of per-instrument latent representations underlying the observed mixture. by manipulating the representations, our model samples mixtures with novel combinations of pitch and timbre of the constituent instruments. we can jointly learn the disentangled pitch-timbre representations and a latent diffusion transformer that reconstructs the mixture conditioned on the set of source-level representations. we evaluate the model using both a simple dataset of isolated chords and a realistic four-part chorales in the style of j.s. bach, identify the key components for the success of disentanglement, and demonstrate the application of mixture transformation based on source-level attribute manipulation.",,2024-08-20,,"['yin-jyun luo', 'kin wai cheuk', 'woosung choi', 'toshimitsu uesaka', 'keisuke toyama', 'koichi saito', 'chieh-hsin lai', 'yuhta takida', 'wei-hsiang liao', 'simon dixon', 'yuki mitsufuji']"
1749,2408.10808,colbert retrieval and ensemble response scoring for language model   question answering,cs.cl cs.ir,"domain-specific question answering remains challenging for language models, given the deep technical knowledge required to answer questions correctly. this difficulty is amplified for smaller language models that cannot encode as much information in their parameters as larger models. the ""specializing large language models for telecom networks"" challenge aimed to enhance the performance of two small language models, phi-2 and falcon-7b in telecommunication question answering. in this paper, we present our question answering systems for this challenge. our solutions achieved leading marks of 81.9% accuracy for phi-2 and 57.3% for falcon-7b. we have publicly released our code and fine-tuned models.",,2024-08-20,,"['alex gichamba', 'tewodros kederalah idris', 'brian ebiyau', 'eric nyberg', 'teruko mitamura']"
1750,2408.10811,beyond english-centric llms: what language do multilingual language   models think in?,cs.cl cs.ai,"in this study, we investigate whether non-english-centric llms, despite their strong performance, `think' in their respective dominant language: more precisely, `think' refers to how the representations of intermediate layers, when un-embedded into the vocabulary space, exhibit higher probabilities for certain dominant languages during generation. we term such languages as internal $\textbf{latent languages}$.   we examine the latent language of three typical categories of models for japanese processing: llama2, an english-centric model; swallow, an english-centric model with continued pre-training in japanese; and llm-jp, a model pre-trained on balanced english and japanese corpora. our empirical findings reveal that, unlike llama2 which relies exclusively on english as the internal latent language, japanese-specific swallow and llm-jp employ both japanese and english, exhibiting dual internal latent languages. for any given target language, the model preferentially activates the latent language most closely related to it. in addition, we explore how intermediate layers respond to questions involving cultural conflicts between latent internal and target output languages. we further explore how the language identity shifts across layers while keeping consistent semantic meaning reflected in the intermediate layer representations.   this study deepens the understanding of non-english-centric large language models, highlighting the intricate dynamics of language representation within their intermediate layers.",,2024-08-20,,"['chengzhi zhong', 'fei cheng', 'qianying liu', 'junfeng jiang', 'zhen wan', 'chenhui chu', 'yugo murawaki', 'sadao kurohashi']"
1751,2408.10816,deep learning-based classification of dementia using image   representation of subcortical signals,eess.sp cs.lg,"dementia is a neurological syndrome marked by cognitive decline. alzheimer's disease (ad) and frontotemporal dementia (ftd) are the common forms of dementia, each with distinct progression patterns. eeg, a non-invasive tool for recording brain activity, has shown potential in distinguishing ad from ftd and mild cognitive impairment (mci). previous studies have utilized various eeg features, such as subband power and connectivity patterns to differentiate these conditions. however, artifacts in eeg signals can obscure crucial information, necessitating advanced signal processing techniques. this study aims to develop a deep learning-based classification system for dementia by analyzing scout time-series signals from deep brain regions, specifically the hippocampus, amygdala, and thalamus. the study utilizes scout time series extracted via the standardized low-resolution brain electromagnetic tomography (sloreta) technique. the time series is converted to image representations using continuous wavelet transform (cwt) and fed as input to deep learning models. two high-density eeg datasets are utilized to check for the efficacy of the proposed method: the online brainlat dataset (comprising ad, ftd, and healthy controls (hc)) and the in-house iitd-aiia dataset (including subjects with ad, mci, and hc). different classification strategies and classifier combinations have been utilized for the accurate mapping of classes on both datasets. the best results were achieved by using a product of probabilities from classifiers for left and right subcortical regions in conjunction with the densenet model architecture. it yields accuracies of 94.17$\%$ and 77.72$\%$ on the brainlat and iitd-aiia datasets, respectively. this highlights the potential of this approach for early and accurate differentiation of neurodegenerative disorders.",,2024-08-20,,"['shivani ranjan', 'ayush tripathi', 'harshal shende', 'robin badal', 'amit kumar', 'pramod yadav', 'deepak joshi', 'lalan kumar']"
1752,2408.10818,learning randomized algorithms with transformers,cs.lg,"randomization is a powerful tool that endows algorithms with remarkable properties. for instance, randomized algorithms excel in adversarial settings, often surpassing the worst-case performance of deterministic algorithms with large margins. furthermore, their success probability can be amplified by simple strategies such as repetition and majority voting. in this paper, we enhance deep neural networks, in particular transformer models, with randomization. we demonstrate for the first time that randomized algorithms can be instilled in transformers through learning, in a purely data- and objective-driven manner. first, we analyze known adversarial objectives for which randomized algorithms offer a distinct advantage over deterministic ones. we then show that common optimization techniques, such as gradient descent or evolutionary strategies, can effectively learn transformer parameters that make use of the randomness provided to the model. to illustrate the broad applicability of randomization in empowering neural networks, we study three conceptual tasks: associative recall, graph coloring, and agents that explore grid worlds. in addition to demonstrating increased robustness against oblivious adversaries through learned randomization, our experiments reveal remarkable performance improvements due to the inherently random nature of the neural networks' computation and predictions.",,2024-08-20,,"['johannes von oswald', 'seijin kobayashi', 'yassir akram', 'angelika steger']"
1753,2408.10819,exploiting large language models capabilities for question answer-driven   knowledge graph completion across static and temporal domains,cs.cl cs.ai,"knowledge graph completion (kgc) aims to identify missing triples in a knowledge graph (kg). this is typically achieved through tasks such as link prediction and instance completion. however, these methods often focus on either static knowledge graphs (skgs) or temporal knowledge graphs (tkgs), addressing only within-scope triples. this paper introduces a new generative completion framework called generative subgraph-based kgc (gs-kgc). gs-kgc employs a question-answering format to directly generate target entities, addressing the challenge of questions having multiple possible answers. we propose a strategy that extracts subgraphs centered on entities and relationships within the kg, from which negative samples and neighborhood information are separately obtained to address the one-to-many problem. our method generates negative samples using known facts to facilitate the discovery of new information. furthermore, we collect and refine neighborhood path data of known entities, providing contextual information to enhance reasoning in large language models (llms). our experiments evaluated the proposed method on four skgs and two tkgs, achieving state-of-the-art hits@1 metrics on five datasets. analysis of the results shows that gs-kgc can discover new triples within existing kgs and generate new facts beyond the closed kg, effectively bridging the gap between closed-world and open-world kgc.",,2024-08-20,,"['rui yang', 'jiahao zhu', 'jianping man', 'li fang', 'yi zhou']"
1754,2408.10821,constructing a high temporal resolution global lakes dataset via   swin-unet with applications to area prediction,cs.cv,"lakes provide a wide range of valuable ecosystem services, such as water supply, biodiversity habitats, and carbon sequestration. however, lakes are increasingly threatened by climate change and human activities. therefore, continuous global monitoring of lake dynamics is crucial, but remains challenging on a large scale. the recently developed global lakes area database (glakes) has mapped over 3.4 million lakes worldwide, but it only provides data at decadal intervals, which may be insufficient to capture rapid or short-term changes.this paper introduces an expanded lake database, glakes-additional, which offers biennial delineations and area measurements for 152,567 lakes globally from 1990 to 2021. we employed the swin-unet model, replacing traditional convolution operations, to effectively address the challenges posed by the receptive field requirements of high spatial resolution satellite imagery. the increased biennial time resolution helps to quantitatively attribute lake area changes to climatic and hydrological drivers, such as precipitation and temperature changes.for predicting lake area changes, we used a long short-term memory (lstm) neural network and an extended time series dataset for preliminary modeling. under climate and land use scenarios, our model achieved an rmse of 0.317 km^2 in predicting future lake area changes.",,2024-08-20,,"['yutian han', 'baoxiang huang', 'he gao']"
1755,2408.10822,navigating spatio-temporal heterogeneity: a graph transformer approach   for traffic forecasting,cs.lg,"traffic forecasting has emerged as a crucial research area in the development of smart cities. although various neural networks with intricate architectures have been developed to address this problem, they still face two key challenges: i) recent advancements in network designs for modeling spatio-temporal correlations are starting to see diminishing returns in performance enhancements. ii) additionally, most models do not account for the spatio-temporal heterogeneity inherent in traffic data, i.e., traffic distribution varies significantly across different regions and traffic flow patterns fluctuate across various time slots. to tackle these challenges, we introduce the spatio-temporal graph transformer (stgormer), which effectively integrates attribute and structure information inherent in traffic data for learning spatio-temporal correlations, and a mixture-of-experts module for capturing heterogeneity along spaital and temporal axes. specifically, we design two straightforward yet effective spatial encoding methods based on the graph structure and integrate time position encoding into the vanilla transformer to capture spatio-temporal traffic patterns. additionally, a mixture-of-experts enhanced feedforward neural network (fnn) module adaptively assigns suitable expert layers to distinct patterns via a spatio-temporal gating network, further improving overall prediction accuracy. experiments on five real-world datasets demonstrate that stgormer achieves state-of-the-art performance.",,2024-08-20,,"['jianxiang zhou', 'erdong liu', 'wei chen', 'siru zhong', 'yuxuan liang']"
1756,2408.10823,trustworthy compression? impact of ai-based codecs on biometrics for law   enforcement,cs.cv eess.iv,"image-based biometrics can aid law enforcement in various aspects, for example in iris, fingerprint and soft-biometric recognition. a critical precondition for recognition is the availability of sufficient biometric information in images. it is visually apparent that strong jpeg compression removes such details. however, latest ai-based image compression seemingly preserves many image details even for very strong compression factors. yet, these perceived details are not necessarily grounded in measurements, which raises the question whether these images can still be used for biometric recognition. in this work, we investigate how ai compression impacts iris, fingerprint and soft-biometric (fabrics and tattoo) images. we also investigate the recognition performance for iris and fingerprint images after ai compression. it turns out that iris recognition can be strongly affected, while fingerprint recognition is quite robust. the loss of detail is qualitatively best seen in fabrics and tattoos images. overall, our results show that ai-compression still permits many biometric tasks, but attention to strong compression factors in sensitive tasks is advisable.",,2024-08-20,,"['sandra bergmann', 'denise moussa', 'christian riess']"
1757,2408.10826,neulite: memory-efficient federated learning via elastic progressive   training,cs.dc,"federated learning (fl) emerges as a new learning paradigm that enables multiple devices to collaboratively train a shared model while preserving data privacy. however, intensive memory footprint during the training process severely bottlenecks the deployment of fl on resource-constrained devices in real-world cases. in this paper, we propose neulite, a framework that breaks the memory wall through elastic progressive training. unlike traditional fl, which updates the full model during the whole training procedure, neulite divides the model into blocks and conducts the training process in a progressive manner. except for the progressive training paradigm, neulite further features the following two key components to guide the training process: 1) curriculum mentor and 2) training harmonizer. specifically, the curriculum mentor devises curriculum-aware training losses for each block, assisting them in learning the expected feature representation and mitigating the loss of valuable information. additionally, the training harmonizer develops a parameter co-adaptation training paradigm to break the information isolation across blocks from both forward and backward propagation. furthermore, it constructs output modules for each block to strengthen model parameter co-adaptation. extensive experiments are conducted to evaluate the effectiveness of neulite across both simulation and hardware testbeds. the results demonstrate that neulite effectively reduces peak memory usage by up to 50.4%. it also enhances model performance by up to 84.2% and accelerates the training process by up to 1.9x.",,2024-08-20,,"['yebo wu', 'li li', 'chunlin tian', 'dubing chen', 'chengzhong xu']"
1758,2408.10827,co2wounds-v2: extended chronic wounds dataset from leprosy patients,eess.iv cs.cv,"chronic wounds pose an ongoing health concern globally, largely due to the prevalence of conditions such as diabetes and leprosy's disease. the standard method of monitoring these wounds involves visual inspection by healthcare professionals, a practice that could present challenges for patients in remote areas with inadequate transportation and healthcare infrastructure. this has led to the development of algorithms designed for the analysis and follow-up of wound images, which perform image-processing tasks such as classification, detection, and segmentation. however, the effectiveness of these algorithms heavily depends on the availability of comprehensive and varied wound image data, which is usually scarce. this paper introduces the co2wounds-v2 dataset, an extended collection of rgb wound images from leprosy patients with their corresponding semantic segmentation annotations, aiming to enhance the development and testing of image-processing algorithms in the medical field.",,2024-08-20,,"['karen sanchez', 'carlos hinojosa', 'olinto mieles', 'chen zhao', 'bernard ghanem', 'henry arguello']"
1760,2408.1083,single bridge formation in self-organizing particle systems,cs.dc cs.et,"local interactions of uncoordinated individuals produce the collective behaviors of many biological systems, inspiring much of the current research in programmable matter. a striking example is the spontaneous assembly of fire ants into ""bridges"" comprising their own bodies to traverse obstacles and reach sources of food. experiments and simulations suggest that, remarkably, these ants always form one bridge -- instead of multiple, competing bridges -- despite a lack of central coordination. we argue that the reliable formation of a single bridge does not require sophistication on behalf of the individuals by provably reproducing this behavior in a self-organizing particle system. we show that the formation of a single bridge by the particles is a statistical inevitability of their preferences to move in a particular direction, such as toward a food source, and their preference for more neighbors. two parameters, $\eta$ and $\beta$, reflect the strengths of these preferences and determine the gibbs stationary measure of the corresponding particle system's markov chain dynamics. we show that a single bridge almost certainly forms when $\eta$ and $\beta$ are sufficiently large. our proof introduces an auxiliary markov chain, called an ""occupancy chain"", that captures only the significant, global changes to the system. through the occupancy chain, we abstract away information about the motion of individual particles, but we gain a more direct means of analyzing their collective behavior. such abstractions provide a promising new direction for understanding many other systems of programmable matter.",,2024-08-20,,"['joseph briones', 'jacob calvert', 'noah egan', 'shunhao oh', 'dana randall', 'andréa w. richa']"
1761,2408.10831,zebrapose: zebra detection and pose estimation using only synthetic data,cs.cv cs.ai cs.ro,"synthetic data is increasingly being used to address the lack of labeled images in uncommon domains for deep learning tasks. a prominent example is 2d pose estimation of animals, particularly wild species like zebras, for which collecting real-world data is complex and impractical. however, many approaches still require real images, consistency and style constraints, sophisticated animal models, and/or powerful pre-trained networks to bridge the syn-to-real gap. moreover, they often assume that the animal can be reliably detected in images or videos, a hypothesis that often does not hold, e.g. in wildlife scenarios or aerial images. to solve this, we use synthetic data generated with a 3d photorealistic simulator to obtain the first synthetic dataset that can be used for both detection and 2d pose estimation of zebras without applying any of the aforementioned bridging strategies. unlike previous works, we extensively train and benchmark our detection and 2d pose estimation models on multiple real-world and synthetic datasets using both pre-trained and non-pre-trained backbones. these experiments show how the models trained from scratch and only with synthetic data can consistently generalize to real-world images of zebras in both tasks. moreover, we show it is possible to easily generalize those same models to 2d pose estimation of horses with a minimal amount of real-world images to account for the domain transfer. code, results, trained models; and the synthetic, training, and validation data, including 104k manually labeled frames, are provided as open-source at https://zebrapose.is.tue.mpg.de/",,2024-08-20,,"['elia bonetto', 'aamir ahmad']"
1762,2408.10838,multilevel cnns for parametric pdes based on adaptive finite elements,cs.lg cs.na math.na,"a neural network architecture is presented that exploits the multilevel properties of high-dimensional parameter-dependent partial differential equations, enabling an efficient approximation of parameter-to-solution maps, rivaling best-in-class methods such as low-rank tensor regression in terms of accuracy and complexity. the neural network is trained with data on adaptively refined finite element meshes, thus reducing data complexity significantly. error control is achieved by using a reliable finite element a posteriori error estimator, which is also provided as input to the neural network.   the proposed u-net architecture with cnn layers mimics a classical finite element multigrid algorithm. it can be shown that the cnn efficiently approximates all operations required by the solver, including the evaluation of the residual-based error estimator. in the cnn, a culling mask set-up according to the local corrections due to refinement on each mesh level reduces the overall complexity, allowing the network optimization with localized fine-scale finite element data.   a complete convergence and complexity analysis is carried out for the adaptive multilevel scheme, which differs in several aspects from previous non-adaptive multilevel cnn. moreover, numerical experiments with common benchmark problems from uncertainty quantification illustrate the practical performance of the architecture.",,2024-08-20,,"['janina enrica schütte', 'martin eigel']"
1763,2408.10839,benchmarking large language models for math reasoning tasks,cs.cl cs.lg,"the use of large language models (llms) in mathematical reasoning has become a cornerstone of related research, demonstrating the intelligence of these models and enabling potential practical applications through their advanced performance, such as in educational settings. despite the variety of datasets and in-context learning algorithms designed to improve the ability of llms to automate mathematical problem solving, the lack of comprehensive benchmarking across different datasets makes it complicated to select an appropriate model for specific tasks. in this project, we present a benchmark that fairly compares seven state-of-the-art in-context learning algorithms for mathematical problem solving across five widely used mathematical datasets on four powerful foundation models. furthermore, we explore the trade-off between efficiency and performance, highlighting the practical applications of llms for mathematical reasoning. our results indicate that larger foundation models like gpt-4o and llama 3-70b can solve mathematical reasoning independently from the concrete prompting strategy, while for smaller models the in-context learning approach significantly influences the performance. moreover, the optimal prompt depends on the chosen foundation model. we open-source our benchmark code to support the integration of additional models in future research.",,2024-08-20,,"['kathrin seßler', 'yao rong', 'emek gözlüklü', 'enkelejda kasneci']"
1766,2408.10844,aligning object detector bounding boxes with human preference,cs.cv,"previous work shows that humans tend to prefer large bounding boxes over small bounding boxes with the same iou. however, we show here that commonly used object detectors predict large and small boxes equally often. in this work, we investigate how to align automatically detected object boxes with human preference and study whether this improves human quality perception. we evaluate the performance of three commonly used object detectors through a user study (n = 123). we find that humans prefer object detections that are upscaled with factors of 1.5 or 2, even if the corresponding ap is close to 0. motivated by this result, we propose an asymmetric bounding box regression loss that encourages large over small predicted bounding boxes. our evaluation study shows that object detectors fine-tuned with the asymmetric loss are better aligned with human preference and are preferred over fixed scaling factors. a qualitative evaluation shows that human preference might be influenced by some object characteristics, like object shape.",,2024-08-20,,"['ombretta strafforello', 'osman s. kayhan', 'oana inel', 'klamer schutte', 'jan van gemert']"
1769,2408.10848,perception-guided jailbreak against text-to-image models,cs.cv,"in recent years, text-to-image (t2i) models have garnered significant attention due to their remarkable advancements. however, security concerns have emerged due to their potential to generate inappropriate or not-safe-for-work (nsfw) images. in this paper, inspired by the observation that texts with different semantics can lead to similar human perceptions, we propose an llm-driven perception-guided jailbreak method, termed pgj. it is a black-box jailbreak method that requires no specific t2i model (model-free) and generates highly natural attack prompts. specifically, we propose identifying a safe phrase that is similar in human perception yet inconsistent in text semantics with the target unsafe word and using it as a substitution. the experiments conducted on six open-source models and commercial online services with thousands of prompts have verified the effectiveness of pgj.",,2024-08-20,,"['yihao huang', 'le liang', 'tianlin li', 'xiaojun jia', 'run wang', 'weikai miao', 'geguang pu', 'yang liu']"
1770,2408.10849,a noval feature via color quantisation for fake audio detection,cs.sd eess.as,"in the field of deepfake detection, previous studies focus on using reconstruction or mask and prediction methods to train pre-trained models, which are then transferred to fake audio detection training where the encoder is used to extract features, such as wav2vec2.0 and masked auto encoder. these methods have proven that using real audio for reconstruction pre-training can better help the model distinguish fake audio. however, the disadvantage lies in poor interpretability, meaning it is hard to intuitively present the differences between deepfake and real audio. this paper proposes a noval feature extraction method via color quantisation which constrains the reconstruction to use a limited number of colors for the spectral image-like input. the proposed method ensures reconstructed input differs from the original, which allows for intuitive observation of the focus areas in the spectral reconstruction. experiments conducted on the asvspoof2019 dataset demonstrate that the proposed method achieves better classification performance compared to using the original spectral as input and pretraining the recolor network can also benefit the fake audio detection.",,2024-08-20,,"['zhiyong wang', 'xiaopeng wang', 'yuankun xie', 'ruibo fu', 'zhengqi wen', 'jianhua tao', 'yukun liu', 'guanjun li', 'xin qi', 'yi lu', 'xuefei liu', 'yongwei li']"
1771,2408.1085,hardware implementation of projection-aggregation decoders for   reed-muller codes,cs.ar cs.it eess.sp math.it,"this paper presents the hardware implementation of two variants of projection-aggregation-based decoding of reed-muller (rm) codes, namely unique projection aggregation (upa) and collapsed projection aggregation (cpa). our study focuses on introducing hardware architectures for both upa and cpa. through thorough analysis and experimentation, we observe that the hardware implementation of upa exhibits superior resource usage and reduced energy consumption compared to cpa for the vanilla ipa decoder. this finding underscores a critical insight: software optimizations, in isolation, may not necessarily translate into hardware cost-effectiveness.",,2024-08-20,,"['marzieh hashemipour-nazari', 'andrea nardi-dei', 'kees goossens', 'alexios balatsoukas-stimming']"
1772,2408.10852,eele: exploring efficient and extensible lora integration in emotional   text-to-speech,cs.sd eess.as,"in the current era of artificial intelligence generated content (aigc), a low-rank adaptation (lora) method has emerged. it uses a plugin-based approach to learn new knowledge with lower parameter quantities and computational costs, and it can be plugged in and out based on the specific sub-tasks, offering high flexibility. however, the current application schemes primarily incorporate lora into the pre-introduced conditional parts of the speech models. this fixes the position of lora, limiting the flexibility and scalability of its application. therefore, we propose the exploring efficient and extensible lora integration in emotional text-to-speech (eele) method. starting from a general neutral speech model, we do not pre-introduce emotional information but instead use the lora plugin to design a flexible adaptive scheme that endows the model with emotional generation capabilities. specifically, we initially train the model using only neutral speech data. after training is complete, we insert lora into different modules and fine-tune the model with emotional speech data to find the optimal insertion scheme. through experiments, we compare and test the effects of inserting lora at different positions within the model and assess lora's ability to learn various emotions, effectively proving the validity of our method. additionally, we explore the impact of the rank size of lora and the difference compared to directly fine-tuning the entire model.",,2024-08-20,,"['xin qi', 'ruibo fu', 'zhengqi wen', 'jianhua tao', 'shuchen shi', 'yi lu', 'zhiyong wang', 'xiaopeng wang', 'yuankun xie', 'yukun liu', 'guanjun li', 'xuefei liu', 'yongwei li']"
1773,2408.10853,does current deepfake audio detection model effectively detect alm-based   deepfake audio?,cs.sd cs.ai eess.as,"currently, audio language models (alms) are rapidly advancing due to the developments in large language models and audio neural codecs. these alms have significantly lowered the barrier to creating deepfake audio, generating highly realistic and diverse types of deepfake audio, which pose severe threats to society. consequently, effective audio deepfake detection technologies to detect alm-based audio have become increasingly critical. this paper investigate the effectiveness of current countermeasure (cm) against alm-based audio. specifically, we collect 12 types of the latest alm-based deepfake audio and utilizing the latest cms to evaluate. our findings reveal that the latest codec-trained cm can effectively detect alm-based audio, achieving 0% equal error rate under most alm test conditions, which exceeded our expectations. this indicates promising directions for future research in alm-based deepfake audio detection.",,2024-08-20,,"['yuankun xie', 'chenxu xiong', 'xiaopeng wang', 'zhiyong wang', 'yi lu', 'xin qi', 'ruibo fu', 'yukun liu', 'zhengqi wen', 'jianhua tao', 'guanjun li', 'long ye']"
1774,2408.10854,mambads: near-surface meteorological field downscaling with topography   constrained selective state space modeling,physics.ao-ph cs.ai cs.cv,"in an era of frequent extreme weather and global warming, obtaining precise, fine-grained near-surface weather forecasts is increasingly essential for human activities. downscaling (ds), a crucial task in meteorological forecasting, enables the reconstruction of high-resolution meteorological states for target regions from global-scale forecast results. previous downscaling methods, inspired by cnn and transformer-based super-resolution models, lacked tailored designs for meteorology and encountered structural limitations. notably, they failed to efficiently integrate topography, a crucial prior in the downscaling process. in this paper, we address these limitations by pioneering the selective state space model into the meteorological field downscaling and propose a novel model called mambads. this model enhances the utilization of multivariable correlations and topography information, unique challenges in the downscaling process while retaining the advantages of mamba in long-range dependency modeling and linear computational complexity. through extensive experiments in both china mainland and the continental united states (conus), we validated that our proposed mambads achieves state-of-the-art results in three different types of meteorological field downscaling settings. we will release the code subsequently.",,2024-08-20,,"['zili liu', 'hao chen', 'lei bai', 'wenyuan li', 'wanli ouyang', 'zhengxia zou', 'zhenwei shi']"
1775,2408.10858,knowledge sharing and transfer via centralized reward agent for   multi-task reinforcement learning,cs.lg cs.ai,"reward shaping is effective in addressing the sparse-reward challenge in reinforcement learning by providing immediate feedback through auxiliary informative rewards. based on the reward shaping strategy, we propose a novel multi-task reinforcement learning framework, that integrates a centralized reward agent (cra) and multiple distributed policy agents. the cra functions as a knowledge pool, which aims to distill knowledge from various tasks and distribute it to individual policy agents to improve learning efficiency. specifically, the shaped rewards serve as a straightforward metric to encode knowledge. this framework not only enhances knowledge sharing across established tasks but also adapts to new tasks by transferring valuable reward signals. we validate the proposed method on both discrete and continuous domains, demonstrating its robustness in multi-task sparse-reward settings and its effective transferability to unseen tasks.",,2024-08-20,,"['haozhe ma', 'zhengding luo', 'thanh vinh vo', 'kuankuan sima', 'tze-yun leong']"
1776,2408.10861,dvrp-mhsi: dynamic visualization research platform for multimodal   human-swarm interaction,cs.ro cs.hc,"in recent years, there has been a significant amount of research on algorithms and control methods for distributed collaborative robots. however, the emergence of collective behavior in a swarm is still difficult to predict and control. nevertheless, human interaction with the swarm helps render the swarm more predictable and controllable, as human operators can utilize intuition or knowledge that is not always available to the swarm. therefore, this paper designs the dynamic visualization research platform for multimodal human-swarm interaction (dvrp-mhsi), which is an innovative open system that can perform real-time dynamic visualization and is specifically designed to accommodate a multitude of interaction modalities (such as brain-computer, eye-tracking, electromyographic, and touch-based interfaces), thereby expediting progress in human-swarm interaction research. specifically, the platform consists of custom-made low-cost omnidirectional wheeled mobile robots, multitouch screens and two workstations. in particular, the mutitouch screens can recognize human gestures and the shapes of objects placed on them, and they can also dynamically render diverse scenes. one of the workstations processes communication information within robots and the other one implements human-robot interaction methods. the development of dvrp-mhsi frees researchers from hardware or software details and allows them to focus on versatile swarm algorithms and human-swarm interaction methods without being limited to fixed scenarios, tasks, and interfaces. the effectiveness and potential of the platform for human-swarm interaction studies are validated by several demonstrative experiments.",,2024-08-20,,"['pengming zhu', 'zhiwen zeng', 'weijia yao', 'wei dai', 'huimin lu', 'zongtan zhou']"
1777,2408.10862,feature selection from differentially private correlations,cs.lg stat.ml,"data scientists often seek to identify the most important features in high-dimensional datasets. this can be done through $l_1$-regularized regression, but this can become inefficient for very high-dimensional datasets. additionally, high-dimensional regression can leak information about individual datapoints in a dataset. in this paper, we empirically evaluate the established baseline method for feature selection with differential privacy, the two-stage selection technique, and show that it is not stable under sparsity. this makes it perform poorly on real-world datasets, so we consider a different approach to private feature selection. we employ a correlations-based order statistic to choose important features from a dataset and privatize them to ensure that the results do not leak information about individual datapoints. we find that our method significantly outperforms the established baseline for private feature selection on many datasets.",,2024-08-20,,"['ryan swope', 'amol khanna', 'philip doldo', 'saptarshi roy', 'edward raff']"
1778,2408.10864,"rage music classification and analysis using k-nearest neighbour, random   forest, support vector machine, convolutional neural networks, and gradient   boosting",cs.sd eess.as,"we classify rage music (a subgenre of rap well-known for disagreements on whether a particular song is part of the genre) with an extensive feature set through algorithms including random forest, support vector machine, k-nearest neighbour, gradient boosting, and convolutional neural networks. we compare methods of classification in the application of audio analysis with machine learning and identify optimal models. we then analyze the significant audio features present in and most effective in categorizing rage music, while also identifying key audio features as well as broader separating sonic variations and trends.",,2024-08-20,,['akul kumar']
1779,2408.10865,multi-agent multi-armed bandits with stochastic sharable arm capacities,cs.ai,"motivated by distributed selection problems, we formulate a new variant of multi-player multi-armed bandit (mab) model, which captures stochastic arrival of requests to each arm, as well as the policy of allocating requests to players. the challenge is how to design a distributed learning algorithm such that players select arms according to the optimal arm pulling profile (an arm pulling profile prescribes the number of players at each arm) without communicating to each other. we first design a greedy algorithm, which locates one of the optimal arm pulling profiles with a polynomial computational complexity. we also design an iterative distributed algorithm for players to commit to an optimal arm pulling profile with a constant number of rounds in expectation. we apply the explore then commit (etc) framework to address the online setting when model parameters are unknown. we design an exploration strategy for players to estimate the optimal arm pulling profile. since such estimates can be different across different players, it is challenging for players to commit. we then design an iterative distributed algorithm, which guarantees that players can arrive at a consensus on the optimal arm pulling profile in only m rounds. we conduct experiments to validate our algorithm.",,2024-08-20,,"['hong xie', 'jinyu mo', 'defu lian', 'jie wang', 'enhong chen']"
1780,2408.10871,radio u-net: a convolutional neural network to detect diffuse radio   sources in galaxy clusters and beyond,astro-ph.im astro-ph.co cs.ai cs.cv cs.lg,"the forthcoming generation of radio telescope arrays promises significant advancements in sensitivity and resolution, enabling the identification and characterization of many new faint and diffuse radio sources. conventional manual cataloging methodologies are anticipated to be insufficient to exploit the capabilities of new radio surveys. radio interferometric images of diffuse sources present a challenge for image segmentation tasks due to noise, artifacts, and embedded radio sources. in response to these challenges, we introduce radio u-net, a fully convolutional neural network based on the u-net architecture. radio u-net is designed to detect faint and extended sources in radio surveys, such as radio halos, relics, and cosmic web filaments. radio u-net was trained on synthetic radio observations built upon cosmological simulations and then tested on a sample of galaxy clusters, where the detection of cluster diffuse radio sources relied on customized data reduction and visual inspection of lofar two metre sky survey (lotss) data. the 83% of clusters exhibiting diffuse radio emission were accurately identified, and the segmentation successfully recovered the morphology of the sources even in low-quality images. in a test sample comprising 246 galaxy clusters, we achieved a 73% accuracy rate in distinguishing between clusters with and without diffuse radio emission. our results establish the applicability of radio u-net to extensive radio survey datasets, probing its efficiency on cutting-edge high-performance computing systems. this approach represents an advancement in optimizing the exploitation of forthcoming large radio surveys for scientific exploration.",,2024-08-20,,"['chiara stuardi', 'claudio gheller', 'franco vazza', 'andrea botteon']"
1781,2408.10876,"more options for prelabor rupture of membranes, a bayesian analysis",stat.ap cs.lg,"an obstetric goal for a laboring mother is to achieve a vaginal delivery as it reduces the risks inherent in major abdominal surgery (i.e., a cesarean section). various medical interventions may be used by a physician to increase the likelihood of this occurring while minimizing maternal and fetal morbidity. however, patients with prelabor rupture of membranes (prom) have only two commonly used options for cervical ripening, pitocin and misoprostol. little research exists on the benefits/risks for these two key drugs for prom patients. a major limitation with most induction-of-labor related research is the inability to account for differences in \textit{bishop scores} that are commonly used in obstetrical practice to determine the next induction agent offered to the patient. this creates a confounding factor, which biases the results, but has not been realized in the literature. in this work, we use a bayesian model of the relationships between the relevant factors, informed by expert physicians, to separate the confounding variable from its actual impact. in doing so, we provide strong evidence that pitocin and buccal misoprostol are equally effective and safe; thus, physicians have more choice in clinical care than previously realized. this is particularly important for developing countries where neither medication may be readily available, and prior guidelines may create an artificial barrier to needed medication.",,2024-08-20,,"['ashley klein', 'edward raff', 'elisabeth seamon', 'lily foley', 'timothy bussert']"
1782,2408.10878,dbhp: trajectory imputation in multi-agent sports using derivative-based   hybrid prediction,cs.ai cs.lg cs.ma,"many spatiotemporal domains handle multi-agent trajectory data, but in real-world scenarios, collected trajectory data are often partially missing due to various reasons. while existing approaches demonstrate good performance in trajectory imputation, they face challenges in capturing the complex dynamics and interactions between agents due to a lack of physical constraints that govern realistic trajectories, leading to suboptimal results. to address this issue, the paper proposes a derivative-based hybrid prediction (dbhp) framework that can effectively impute multiple agents' missing trajectories. first, a neural network equipped with set transformers produces a naive prediction of missing trajectories while satisfying the permutation-equivariance in terms of the order of input agents. then, the framework makes alternative predictions leveraging velocity and acceleration information and combines all the predictions with properly determined weights to provide final imputed trajectories. in this way, our proposed framework not only accurately predicts position, velocity, and acceleration values but also enforces the physical relationship between them, eventually improving both the accuracy and naturalness of the predicted trajectories. accordingly, the experiment results about imputing player trajectories in team sports show that our framework significantly outperforms existing imputation baselines.",,2024-08-20,,"['hanjun choi', 'hyunsung kim', 'minho lee', 'chang-jo kim', 'jinsung yoon', 'sang-ki ko']"
1783,2408.1088,open 3d world in autonomous driving,cs.cv,"the capability for open vocabulary perception represents a significant advancement in autonomous driving systems, facilitating the comprehension and interpretation of a wide array of textual inputs in real-time. despite extensive research in open vocabulary tasks within 2d computer vision, the application of such methodologies to 3d environments, particularly within large-scale outdoor contexts, remains relatively underdeveloped. this paper presents a novel approach that integrates 3d point cloud data, acquired from lidar sensors, with textual information. the primary focus is on the utilization of textual data to directly localize and identify objects within the autonomous driving context. we introduce an efficient framework for the fusion of bird's-eye view (bev) region features with textual features, thereby enabling the system to seamlessly adapt to novel textual inputs and enhancing the robustness of open vocabulary detection tasks. the effectiveness of the proposed methodology is rigorously evaluated through extensive experimentation on the newly introduced nuscenes-t dataset, with additional validation of its zero-shot performance on the lyft level 5 dataset. this research makes a substantive contribution to the advancement of autonomous driving technologies by leveraging multimodal data to enhance open vocabulary perception in 3d environments, thereby pushing the boundaries of what is achievable in autonomous navigation and perception.",,2024-08-20,,"['xinlong cheng', 'lei li']"
1784,2408.10883,daad: dynamic analysis and adaptive discriminator for fake news   detection,cs.ai cs.cv,"in current web environment, fake news spreads rapidly across online social networks, posing serious threats to society. existing multimodal fake news detection (mfnd) methods can be classified into knowledge-based and semantic-based approaches. however, these methods are overly dependent on human expertise and feedback, lacking flexibility. to address this challenge, we propose a dynamic analysis and adaptive discriminator (daad) approach for fake news detection. for knowledge-based methods, we introduce the monte carlo tree search (mcts) algorithm to leverage the self-reflective capabilities of large language models (llms) for prompt optimization, providing richer, domain-specific details and guidance to the llms, while enabling more flexible integration of llm comment on news content. for semantic-based methods, we define four typical deceit patterns: emotional exaggeration, logical inconsistency, image manipulation, and semantic inconsistency, to reveal the mechanisms behind fake news creation. to detect these patterns, we carefully design four discriminators and expand them in depth and breadth, using the soft-routing mechanism to explore optimal detection models. experimental results on three real-world datasets demonstrate the superiority of our approach. the code will be available at: https://github.com/suxinqi/daad.",,2024-08-20,,"['xinqi su', 'yawen cui', 'ajian liu', 'xun lin', 'yuhao wang', 'haochen liang', 'wenhui li', 'zitong yu']"
1785,2408.10885,low-quality image detection by hierarchical vae,cs.cv,"to make an employee roster, photo album, or training dataset of generative models, one needs to collect high-quality images while dismissing low-quality ones. this study addresses a new task of unsupervised detection of low-quality images. we propose a method that not only detects low-quality images with various types of degradation but also provides visual clues of them based on an observation that partial reconstruction by hierarchical variational autoencoders fails for low-quality images. the experiments show that our method outperforms several unsupervised out-of-distribution detection methods and also gives visual clues for low-quality images that help humans recognize them even in thumbnail view.",,2024-08-20,,"['tomoyasu nanaumi', 'kazuhiko kawamoto', 'hiroshi kera']"
1786,2408.10886,leveraging llms for the quality assurance of software requirements,cs.se,"successful software projects depend on the quality of software requirements. creating high-quality requirements is a crucial step toward successful software development. effective support in this area can significantly reduce development costs and enhance the software quality. in this paper, we introduce and assess the capabilities of a large language model (llm) to evaluate the quality characteristics of software requirements according to the iso 29148 standard. we aim to further improve the support of stakeholders engaged in requirements engineering (re). we show how an llm can assess requirements, explain its decision-making process, and examine its capacity to propose improved versions of requirements. we conduct a study with software engineers to validate our approach. our findings emphasize the potential of llms for improving the quality of software requirements.",,2024-08-20,,"['sebastian lubos', 'alexander felfernig', 'thi ngoc trang tran', 'damian garber', 'merfat el mansi', 'seda polat erdeniz', 'viet-man le']"
1787,2408.10887,a mini-review on mobile manipulators with variable autonomy,cs.ro,"this paper presents a mini-review of the current state of research in mobile manipulators with variable levels of autonomy, emphasizing their associated challenges and application environments. the need for mobile manipulators in different environments is evident due to the unique challenges and risks each presents. many systems deployed in these environments are not fully autonomous, requiring human-robot teaming to ensure safe and reliable operations under uncertainties. through this analysis, we identify gaps and challenges in the literature on variable autonomy, including cognitive workload and communication delays, and propose future directions, including whole-body variable autonomy for mobile manipulators, virtual reality frameworks, and large language models to reduce operators' complexity and cognitive load in some challenging and uncertain scenarios.",,2024-08-20,,"['cesar alan contreras', 'alireza rastegarpanah', 'rustam stolkin', 'manolis chiou']"
1788,2408.10889,on learning action costs from input plans,cs.ai,"most of the work on learning action models focus on learning the actions' dynamics from input plans. this allows us to specify the valid plans of a planning task. however, very little work focuses on learning action costs, which in turn allows us to rank the different plans. in this paper we introduce a new problem: that of learning the costs of a set of actions such that a set of input plans are optimal under the resulting planning model. to solve this problem we present $lacfip^k$, an algorithm to learn action's costs from unlabeled input plans. we provide theoretical and empirical results showing how $lacfip^k$ can successfully solve this task.",,2024-08-20,,"['marianela morales', 'alberto pozanco', 'giuseppe canonaco', 'sriram gopalakrishnan', 'daniel borrajo', 'manuela veloso']"
1789,2408.10892,characterization of circular-arc graphs: ii. mcconnell flipping,math.co cs.ds,"mcconnell [focs 2001] presented a flipping transformation from circular-arc graphs to interval graphs with certain patterns of representations. beyond its algorithmic implications, this transformation is instrumental in identifying all minimal graphs that are not circular-arc graphs. we conduct a structural study of this transformation, and for $c_{4}$-free graphs, we achieve a complete characterization of these patterns. this characterization allows us, among other things, to identify all minimal chordal graphs that are not circular-arc graphs in a companion paper.",,2024-08-20,,"['yixin cao', 'tomasz krawczyk']"
1790,2408.10894,vilref: a chinese vision-language retinal foundation model,cs.cv,"subtle semantic differences in retinal image and text data present great challenges for pre-training visual-language models. moreover, false negative samples, i.e., image-text pairs having the same semantics but incorrectly regarded as negatives, disrupt the visual-language pre-training process and affect the model's learning ability. this work aims to develop a retinal foundation model, called vilref, by pre-training on a paired dataset comprising 451,956 retinal images and corresponding diagnostic text reports. in our vision-language pre-training strategy, we leverage expert knowledge to facilitate the extraction of labels and propose a novel constraint, the weighted similarity coupling loss, to adjust the speed of pushing sample pairs further apart dynamically within the feature space. furthermore, we employ a batch expansion module with dynamic memory queues, maintained by momentum encoders, to supply extra samples and compensate for the vacancies caused by eliminating false negatives. extensive experiments are conducted on multiple datasets for downstream classification and segmentation tasks. the experimental results demonstrate the powerful zero-shot and transfer learning capabilities of vilref, verifying the effectiveness of our pre-training strategy. our vilref model is available at: https://github.com/t6yang/vilref.",,2024-08-20,,"['shengzhu yang', 'jiawei du', 'jia guo', 'weihang zhang', 'hanruo liu', 'huiqi li', 'ningli wang']"
1791,2408.10895,analytical and empirical study of herding effects in recommendation   systems,cs.ai,"online rating systems are often used in numerous web or mobile applications, e.g., amazon and tripadvisor, to assess the ground-truth quality of products. due to herding effects, the aggregation of historical ratings (or historical collective opinion) can significantly influence subsequent ratings, leading to misleading and erroneous assessments. we study how to manage product ratings via rating aggregation rules and shortlisted representative reviews, for the purpose of correcting the assessment error. we first develop a mathematical model to characterize important factors of herding effects in product ratings. we then identify sufficient conditions (via the stochastic approximation theory), under which the historical collective opinion converges to the ground-truth collective opinion of the whole user population. these conditions identify a class of rating aggregation rules and review selection mechanisms that can reveal the ground-truth product quality. we also quantify the speed of convergence (via the martingale theory), which reflects the efficiency of rating aggregation rules and review selection mechanisms. we prove that the herding effects slow down the speed of convergence while an accurate review selection mechanism can speed it up. we also study the speed of convergence numerically and reveal trade-offs in selecting rating aggregation rules and review selection mechanisms. to show the utility of our framework, we design a maximum likelihood algorithm to infer model parameters from ratings, and conduct experiments on rating datasets from amazon and tripadvisor. we show that proper recency aware rating aggregation rules can improve the speed of convergence in amazon and tripadvisor by 41% and 62% respectively.",,2024-08-20,,"['hong xie', 'mingze zhong', 'defu lian', 'zhen wang', 'enhong chen']"
1792,2408.10899,"all robots in one: a new standard and unified dataset for versatile,   general-purpose embodied agents",cs.ro,"embodied ai is transforming how ai systems interact with the physical world, yet existing datasets are inadequate for developing versatile, general-purpose agents. these limitations include a lack of standardized formats, insufficient data diversity, and inadequate data volume. to address these issues, we introduce ario (all robots in one), a new data standard that enhances existing datasets by offering a unified data format, comprehensive sensory modalities, and a combination of real-world and simulated data. ario aims to improve the training of embodied ai agents, increasing their robustness and adaptability across various tasks and environments. building upon the proposed new standard, we present a large-scale unified ario dataset, comprising approximately 3 million episodes collected from 258 series and 321,064 tasks. the ario standard and dataset represent a significant step towards bridging the gaps of existing data resources. by providing a cohesive framework for data collection and representation, ario paves the way for the development of more powerful and versatile embodied ai agents, capable of navigating and interacting with the physical world in increasingly complex and diverse ways. the project is available on https://imaei.github.io/project_pages/ario/",,2024-08-20,,"['zhiqiang wang', 'hao zheng', 'yunshuang nie', 'wenjun xu', 'qingwei wang', 'hua ye', 'zhe li', 'kaidong zhang', 'xuewen cheng', 'wanxi dong', 'chang cai', 'liang lin', 'feng zheng', 'xiaodan liang']"
1793,2408.109,towards efficient formal verification of spiking neural network,cs.ai cs.et cs.ne,"recently, ai research has primarily focused on large language models (llms), and increasing accuracy often involves scaling up and consuming more power. the power consumption of ai has become a significant societal issue; in this context, spiking neural networks (snns) offer a promising solution. snns operate event-driven, like the human brain, and compress information temporally. these characteristics allow snns to significantly reduce power consumption compared to perceptron-based artificial neural networks (anns), highlighting them as a next-generation neural network technology. however, societal concerns regarding ai go beyond power consumption, with the reliability of ai models being a global issue. for instance, adversarial attacks on ai models are a well-studied problem in the context of traditional neural networks. despite their importance, the stability and property verification of snns remains in the early stages of research. most snn verification methods are time-consuming and barely scalable, making practical applications challenging. in this paper, we introduce temporal encoding to achieve practical performance in verifying the adversarial robustness of snns. we conduct a theoretical analysis of this approach and demonstrate its success in verifying snns at previously unmanageable scales. our contribution advances snn verification to a practical level, facilitating the safer application of snns.",,2024-08-20,,"['baekryun seong', 'jieung kim', 'sang-ki ko']"
1794,2408.10901,a grey-box attack against latent diffusion model-based image editing by   posterior collapse,cs.cv cs.ai cs.lg,"recent advancements in generative ai, particularly latent diffusion models (ldms), have revolutionized image synthesis and manipulation. however, these generative techniques raises concerns about data misappropriation and intellectual property infringement. adversarial attacks on machine learning models have been extensively studied, and a well-established body of research has extended these techniques as a benign metric to prevent the underlying misuse of generative ai. current approaches to safeguarding images from manipulation by ldms are limited by their reliance on model-specific knowledge and their inability to significantly degrade semantic quality of generated images. in response to these shortcomings, we propose the posterior collapse attack (pca) based on the observation that vaes suffer from posterior collapse during training. our method minimizes dependence on the white-box information of target models to get rid of the implicit reliance on model-specific knowledge. by accessing merely a small amount of ldm parameters, in specific merely the vae encoder of ldms, our method causes a substantial semantic collapse in generation quality, particularly in perceptual consistency, and demonstrates strong transferability across various model architectures. experimental results show that pca achieves superior perturbation effects on image generation of ldms with lower runtime and vram. our method outperforms existing techniques, offering a more robust and generalizable solution that is helpful in alleviating the socio-technical challenges posed by the rapidly evolving landscape of generative ai.",,2024-08-20,,"['zhongliang guo', 'lei fang', 'jingyu lin', 'yifei qian', 'shuai zhao', 'zeyu wang', 'junhao dong', 'cunjian chen', 'ognjen arandjelović', 'chun pong lau']"
1795,2408.10902,soda-eval: open-domain dialogue evaluation in the age of llms,cs.cl,"although human evaluation remains the gold standard for open-domain dialogue evaluation, the growing popularity of automated evaluation using large language models (llms) has also extended to dialogue. however, most frameworks leverage benchmarks that assess older chatbots on aspects such as fluency and relevance, which are not reflective of the challenges associated with contemporary models. in fact, a qualitative analysis on soda, a gpt-3.5 generated dialogue dataset, suggests that current chatbots may exhibit several recurring issues related to coherence and commonsense knowledge, but generally produce highly fluent and relevant responses.   noting the aforementioned limitations, this paper introduces soda-eval, an annotated dataset based on soda that covers over 120k turn-level assessments across 10k dialogues, where the annotations were generated by gpt-4. using soda-eval as a benchmark, we then study the performance of several open-access instruction-tuned llms, finding that dialogue evaluation remains challenging. fine-tuning these models improves performance over few-shot inferences, both in terms of correlation and explanation.",,2024-08-20,,"['john mendonça', 'isabel trancoso', 'alon lavie']"
1796,2408.10905,"the impact of labeling automotive ai as ""trustworthy"" or ""reliable"" on   user evaluation and technology acceptance",cs.hc cs.ai cs.et,"this study explores whether labeling ai as ""trustworthy"" or ""reliable"" influences user perceptions and acceptance of automotive ai technologies. using a one-way between-subjects design, the research involved 478 online participants who were presented with guidelines for either trustworthy or reliable ai. participants then evaluated three vignette scenarios and completed a modified version of the technology acceptance model, which included variables such as perceived ease of use, human-like trust, and overall attitude. although labeling ai as ""trustworthy"" did not significantly influence judgments on specific scenarios, it increased perceived ease of use and human-like trust, particularly benevolence. this suggests a positive impact on usability and an anthropomorphic effect on user perceptions. the study provides insights into how specific labels can influence attitudes toward ai technology.",,2024-08-20,,"['john dorsch', 'ophelia deroy']"
1797,2408.10906,shapesplat: a large-scale dataset of gaussian splats and their   self-supervised pretraining,cs.cv,"3d gaussian splatting (3dgs) has become the de facto method of 3d representation in many vision tasks. this calls for the 3d understanding directly in this representation space. to facilitate the research in this direction, we first build a large-scale dataset of 3dgs using the commonly used shapenet and modelnet datasets. our dataset shapesplat consists of 65k objects from 87 unique categories, whose labels are in accordance with the respective datasets. the creation of this dataset utilized the compute equivalent of 2 gpu years on a titan xp gpu.   we utilize our dataset for unsupervised pretraining and supervised finetuning for classification and segmentation tasks. to this end, we introduce \textbf{\textit{gaussian-mae}}, which highlights the unique benefits of representation learning from gaussian parameters. through exhaustive experiments, we provide several valuable insights. in particular, we show that (1) the distribution of the optimized gs centroids significantly differs from the uniformly sampled point cloud (used for initialization) counterpart; (2) this change in distribution results in degradation in classification but improvement in segmentation tasks when using only the centroids; (3) to leverage additional gaussian parameters, we propose gaussian feature grouping in a normalized feature space, along with splats pooling layer, offering a tailored solution to effectively group and embed similar gaussians, which leads to notable improvement in finetuning tasks.",,2024-08-20,,"['qi ma', 'yue li', 'bin ren', 'nicu sebe', 'ender konukoglu', 'theo gevers', 'luc van gool', 'danda pani paudel']"
1798,2408.10908,enhancing end-to-end autonomous driving systems through synchronized   human behavior data,cs.ro cs.hc,"this paper presents a pioneering exploration into the integration of fine-grained human supervision within the autonomous driving domain to enhance system performance. the current advances in end-to-end autonomous driving normally are data-driven and rely on given expert trials. however, this reliance limits the systems' generalizability and their ability to earn human trust. addressing this gap, our research introduces a novel approach by synchronously collecting data from human and machine drivers under identical driving scenarios, focusing on eye-tracking and brainwave data to guide machine perception and decision-making processes. this paper utilizes the carla simulation to evaluate the impact brought by human behavior guidance. experimental results show that using human attention to guide machine attention could bring a significant improvement in driving performance. however, guidance by human intention still remains a challenge. this paper pioneers a promising direction and potential for utilizing human behavior guidance to enhance autonomous systems.",,2024-08-20,,"['yiqun duan', 'zhuoli zhuang', 'jinzhao zhou', 'yu-cheng chang', 'yu-kai wang', 'chin-teng lin']"
1799,2408.10912,an achievable rate-distortion region of joint identification and sensing   for multiple access channels,cs.it math.it,"in contrast to shannon transmission codes, the size of identification (id) codes for discrete memoryless channels (dmcs) experiences doubly exponential growth with the block length when randomized encoding is used. additional enhancements within the id paradigm can be realized through supplementary resources such as quantum entanglement, common randomness (cr), and feedback. joint transmission and sensing demonstrate significant benefits over separation-based methods. inspired by the significant impact of feedback on the id capacity, our work delves into the realm of joint id and sensing (jidas) for state-dependent multiple access channels (sd-macs) with noiseless strictly casual feedback. here, the senders aim to convey id messages to the receiver while simultaneously sensing the channel states. we establish a lower bound on the capacity-distortion region of the sd-macs. an example shows that jidas outperforms the separation-based approach.",,2024-08-20,,"['yaning zhao', 'wafa labidi', 'holger boche', 'eduard jorswieck', 'christian deppe']"
1800,2408.10913,how much reserve fuel: quantifying the maximal energy cost of system   disturbances,eess.sy cs.sy math.oc,"motivated by the design question of additional fuel needed to complete a task in an uncertain environment, this paper introduces metrics to quantify the maximal additional energy used by a control system in the presence of bounded disturbances when compared to a nominal, disturbance-free system. in particular, we consider the task of finite-time stabilization for a linear time-invariant system. we first derive the nominal energy required to achieve this task in a disturbance-free system, and then the worst-case energy over all feasible disturbances. the latter leads to an optimal control problem with a least-squares solution, and then an infinite-dimensional optimization problem where we derive an upper bound on the solution. the comparison of these energies is accomplished using additive and multiplicative metrics, and we derive analytical bounds on these metrics. simulation examples on an admire fighter jet model demonstrate the practicability of these metrics, and their variation with the task hardness, a combination of the distance of the initial condition from the origin and the task completion time.",,2024-08-20,,"['ram padmanabhan', 'craig bakker', 'siddharth abhijit dinkar', 'melkior ornik']"
1801,2408.10914,"to code, or not to code? exploring impact of code in pre-training",cs.cl,"including code in the pre-training data mixture, even for models not specifically designed for code, has become a common practice in llms pre-training. while there has been anecdotal consensus among practitioners that code data plays a vital role in general llms' performance, there is only limited work analyzing the precise impact of code on non-code tasks. in this work, we systematically investigate the impact of code data on general performance. we ask ""what is the impact of code data used in pre-training on a large variety of downstream tasks beyond code generation"". we conduct extensive ablations and evaluate across a broad range of natural language reasoning tasks, world knowledge tasks, code benchmarks, and llm-as-a-judge win-rates for models with sizes ranging from 470m to 2.8b parameters. across settings, we find a consistent results that code is a critical building block for generalization far beyond coding tasks and improvements to code quality have an outsized impact across all tasks. in particular, compared to text-only pre-training, the addition of code results in up to relative increase of 8.2% in natural language (nl) reasoning, 4.2% in world knowledge, 6.6% improvement in generative win-rates, and a 12x boost in code performance respectively. our work suggests investments in code quality and preserving code during pre-training have positive impacts.",,2024-08-20,,"['viraat aryabumi', 'yixuan su', 'raymond ma', 'adrien morisot', 'ivan zhang', 'acyr locatelli', 'marzieh fadaee', 'ahmet üstün', 'sara hooker']"
1802,2408.10918,checkwhy: causal fact verification via argument structure,cs.cl,"with the growing complexity of fact verification tasks, the concern with ""thoughtful"" reasoning capabilities is increasing. however, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. in this paper, we introduce checkwhy, a challenging dataset tailored to a novel causal fact verification task: checking the truthfulness of the causal relation within claims through rigorous reasoning steps. checkwhy consists of over 19k ""why"" claim-evidence-argument structure triplets with supports, refutes, and not enough info labels. each argument structure is composed of connected evidence, representing the reasoning process that begins with foundational evidence and progresses toward claim establishment. through extensive experiments on state-of-the-art models, we validate the importance of incorporating the argument structure for causal fact verification. moreover, the automated and human evaluation of argument structure generation reveals the difficulty in producing satisfying argument structure by fine-tuned models or chain-of-thought prompted llms, leaving considerable room for future improvements.",,2024-08-20,,"['jiasheng si', 'yibo zhao', 'yingjie zhu', 'haiyang zhu', 'wenpeng lu', 'deyu zhou']"
1803,2408.1092,recurrent neural networks learn to store and generate sequences using   non-linear representations,cs.lg cs.ai cs.ne,"the linear representation hypothesis (lrh) states that neural networks learn to encode concepts as directions in activation space, and a strong version of the lrh states that models learn only such encodings. in this paper, we present a counterexample to this strong lrh: when trained to repeat an input token sequence, gated recurrent neural networks (rnns) learn to represent the token at each position with a particular order of magnitude, rather than a direction. these representations have layered features that are impossible to locate in distinct linear subspaces. to show this, we train interventions to predict and manipulate tokens by learning the scaling factor corresponding to each sequence position. these interventions indicate that the smallest rnns find only this magnitude-based solution, while larger rnns have linear representations. these findings strongly indicate that interpretability research should not be confined by the lrh.",,2024-08-20,,"['róbert csordás', 'christopher potts', 'christopher d. manning', 'atticus geiger']"
1804,2408.10921,mtfineval:a multi-domain chinese financial benchmark with eurypalynous   questions,cs.ai,"with the emergence of more and more economy-specific llms, how to measure whether they can be safely invested in production becomes a problem. previous research has primarily focused on evaluating the performance of llms within specific application scenarios. however, these benchmarks cannot reflect the theoretical level and generalization ability, and the backward datasets are increasingly unsuitable for problems in real scenarios. in this paper, we have compiled a new benchmark, mtfineval, focusing on the llms' basic knowledge of economics, which can always be used as a basis for judgment. to examine only theoretical knowledge as much as possible, mtfineval is build with foundational questions from university textbooks,and exam papers in economics and management major. aware of the overall performance of llms do not depend solely on one subdiscipline of economics, mtfineval comprise 360 questions refined from six major disciplines of economics, and reflect capabilities more comprehensively. experiment result shows all llms perform poorly on mtfineval, which proves that our benchmark built on basic knowledge is very successful. our research not only offers guidance for selecting the appropriate llm for specific use cases, but also put forward increase the rigor reliability of llms from the basics.",,2024-08-20,,"['xinyu liu', 'ke jin']"
1805,2408.10932,the evolution of reinforcement learning in quantitative finance,cs.ai cs.ce cs.lg,"reinforcement learning (rl) has experienced significant advancement over the past decade, prompting a growing interest in applications within finance. this survey critically evaluates 167 publications, exploring diverse rl applications and frameworks in finance. financial markets, marked by their complexity, multi-agent nature, information asymmetry, and inherent randomness, serve as an intriguing test-bed for rl. traditional finance offers certain solutions, and rl advances these with a more dynamic approach, incorporating machine learning methods, including transfer learning, meta-learning, and multi-agent solutions. this survey dissects key rl components through the lens of quantitative finance. we uncover emerging themes, propose areas for future research, and critique the strengths and weaknesses of existing methods.",,2024-08-20,,"['nikolaos pippas', 'cagatay turkay', 'elliot a. ludvig']"
1806,2408.10933,evaluating assistive technologies on a trade fair: methodological   overview and lessons learned,cs.hc cs.ro,"user-centered evaluations are a core requirement in the development of new user related technologies. however, it is often difficult to recruit sufficient participants, especially if the target population is small, particularly busy, or in some way restricted in their mobility. we bypassed these problems by conducting studies on trade fairs that were specifically designed for our target population (potentially care-receiving individuals in wheelchairs) and therefore provided our users with external incentive to attend our study. this paper presents our gathered experiences, including methodological specifications and lessons learned, and is aimed to guide other researchers with conducting similar studies. in addition, we also discuss chances generated by this unconventional study environment as well as its limitations.",,2024-08-20,,"['annalies baumeister', 'felix goldau', 'max pascher', 'jens gerken', 'udo frese', 'patrizia tolle']"
1807,2408.10934,sdi-net: toward sufficient dual-view interaction for low-light stereo   image enhancement,cs.cv cs.ai eess.iv,"currently, most low-light image enhancement methods only consider information from a single view, neglecting the correlation between cross-view information. therefore, the enhancement results produced by these methods are often unsatisfactory. in this context, there have been efforts to develop methods specifically for low-light stereo image enhancement. these methods take into account the cross-view disparities and enable interaction between the left and right views, leading to improved performance. however, these methods still do not fully exploit the interaction between left and right view information. to address this issue, we propose a model called toward sufficient dual-view interaction for low-light stereo image enhancement (sdi-net). the backbone structure of sdi-net is two encoder-decoder pairs, which are used to learn the mapping function from low-light images to normal-light images. among the encoders and the decoders, we design a module named cross-view sufficient interaction module (csim), aiming to fully exploit the correlations between the binocular views via the attention mechanism. the quantitative and visual results on public datasets validate the superiority of our method over other related methods. ablation studies also demonstrate the effectiveness of the key elements in our model.",,2024-08-20,,"['linlin hu', 'ao sun', 'shijie hao', 'richang hong', 'meng wang']"
1808,2408.10935,large point-to-gaussian model for image-to-3d generation,cs.cv,"recently, image-to-3d approaches have significantly advanced the generation quality and speed of 3d assets based on large reconstruction models, particularly 3d gaussian reconstruction models. existing large 3d gaussian models directly map 2d image to 3d gaussian parameters, while regressing 2d image to 3d gaussian representations is challenging without 3d priors. in this paper, we propose a large point-to-gaussian model, that inputs the initial point cloud produced from large 3d diffusion model conditional on 2d image to generate the gaussian parameters, for image-to-3d generation. the point cloud provides initial 3d geometry prior for gaussian generation, thus significantly facilitating image-to-3d generation. moreover, we present the \textbf{a}ttention mechanism, \textbf{p}rojection mechanism, and \textbf{p}oint feature extractor, dubbed as \textbf{app} block, for fusing the image features with point cloud features. the qualitative and quantitative experiments extensively demonstrate the effectiveness of the proposed approach on gso and objaverse datasets, and show the proposed method achieves state-of-the-art performance.",,2024-08-20,,"['longfei lu', 'huachen gao', 'tao dai', 'yaohua zha', 'zhi hou', 'junta wu', 'shu-tao xia']"
1809,2408.10937,proxona: leveraging llm-driven personas to enhance creators'   understanding of their audience,cs.hc,"creators are nothing without their audience, and thereby understanding their audience is the cornerstone of their professional achievement. yet many creators feel lost while comprehending audiences with existing tools, which offer insufficient insights for tailoring content to audience needs. to address the challenges creators face in understanding their audience, we present proxona, a system for defining and extracting representative audience personas from the comments. creators converse with personas to gain insights into their preferences and engagement, solicit feedback, and implement evidence-based improvements to their content. powered by large language models, proxona analyzes audience comments, distilling the latent characteristics of audiences into tangible dimensions (classification categories) and values (category attributes). proxona then clusters these into synthetic personas. our technical evaluations demonstrated that our pipelines effectively generated relevant and distinct dimensions and values, enabling the deduction of audience-reflecting personas, while minimizing the likelihood of hallucinations in persona responses. our user evaluation with 11 creators showed that proxona supported creators to gain new insights about their audience, make informed decisions, and successfully complete content creation with high confidence. proxona's data-driven audience personas empower creators to seamlessly integrate audience perspectives into their creative processes, fostering a collaborative approach to content creation.",,2024-08-20,,"['yoonseo choi', 'eun jeong kang', 'seulgi choi', 'min kyung lee', 'juho kim']"
1810,2408.10939,conformalized interval arithmetic with symmetric calibration,cs.lg stat.ml,"uncertainty quantification is essential in decision-making, especially when joint distributions of random variables are involved. while conformal prediction provides distribution-free prediction sets with valid coverage guarantees, it traditionally focuses on single predictions. this paper introduces novel conformal prediction methods for estimating the sum or average of unknown labels over specific index sets. we develop conformal prediction intervals for single target to the prediction interval for sum of multiple targets. under permutation invariant assumptions, we prove the validity of our proposed method. we also apply our algorithms on class average estimation and path cost prediction tasks, and we show that our method outperforms existing conformalized approaches as well as non-conformal approaches.",,2024-08-20,,"['rui luo', 'zhixin zhou']"
1811,2408.1094,a closer look at data augmentation strategies for finetuning-based   low/few-shot object detection,cs.cv cs.ai cs.lg cs.pf,"current methods for low- and few-shot object detection have primarily focused on enhancing model performance for detecting objects. one common approach to achieve this is by combining model finetuning with data augmentation strategies. however, little attention has been given to the energy efficiency of these approaches in data-scarce regimes. this paper seeks to conduct a comprehensive empirical study that examines both model performance and energy efficiency of custom data augmentations and automated data augmentation selection strategies when combined with a lightweight object detector. the methods are evaluated in three different benchmark datasets in terms of their performance and energy consumption, and the efficiency factor is employed to gain insights into their effectiveness considering both performance and efficiency. consequently, it is shown that in many cases, the performance gains of data augmentation strategies are overshadowed by their increased energy usage, necessitating the development of more energy efficient data augmentation strategies to address data scarcity.",,2024-08-20,,"['vladislav li', 'georgios tsoumplekas', 'ilias siniosoglou', 'vasileios argyriou', 'anastasios lytos', 'eleftherios fountoukidis', 'panagiotis sarigiannidis']"
1812,2408.10941,safety-critical stabilization of force-controlled nonholonomic robots,eess.sy cs.sy,"we present a safety-critical controller for the problem of stabilization for force-controlled nonholonomic autonomous vehicles. the proposed control law is based on the constructions of control lyapunov functions (clfs) and control barrier functions (cbfs) for cascaded systems. to address nonholonomicity, we design the nominal controller that guarantees global asymptotic stability and local exponential stability for the closed-loop system in polar coordinates and construct a strict lyapunov function valid on any compact sets. furthermore, we present a procedure for constructing cbfs for cascaded systems, utilizing the cbf of the kinematic model through integrator backstepping. quadratic programming is employed to combine clfs and cbfs to integrate both stability and safety in the closed loop. the proposed control law is time-invariant, continuous along trajectories, and easy to implement. our main results guarantee both safety and local asymptotic stability for the closed-loop system.",,2024-08-20,,"['tianyu han', 'bo wang']"
1813,2408.10942,robust regression with ensembles communicating over noisy channels,cs.lg cs.dc cs.it math.it,"as machine-learning models grow in size, their implementation requirements cannot be met by a single computer system. this observation motivates distributed settings, in which intermediate computations are performed across a network of processing units, while the central node only aggregates their outputs. however, distributing inference tasks across low-precision or faulty edge devices, operating over a network of noisy communication channels, gives rise to serious reliability challenges. we study the problem of an ensemble of devices, implementing regression algorithms, that communicate through additive noisy channels in order to collaboratively perform a joint regression task. we define the problem formally, and develop methods for optimizing the aggregation coefficients for the parameters of the noise in the channels, which can potentially be correlated. our results apply to the leading state-of-the-art ensemble regression methods: bagging and gradient boosting. we demonstrate the effectiveness of our algorithms on both synthetic and real-world datasets.",,2024-08-20,,"['yuval ben-hur', 'yuval cassuto']"
1814,2408.10943,sysbench: can large language models follow system messages?,cs.cl,"large language models (llms) have become instrumental across various applications, with the customization of these models to specific scenarios becoming increasingly critical. system message, a fundamental component of llms, is consist of carefully crafted instructions that guide the behavior of model to meet intended goals. despite the recognized potential of system messages to optimize ai-driven solutions, there is a notable absence of a comprehensive benchmark for evaluating how well different llms follow these system messages. to fill this gap, we introduce sysbench, a benchmark that systematically analyzes system message following ability in terms of three challenging aspects: constraint complexity, instruction misalignment and multi-turn stability. in order to enable effective evaluation, sysbench constructs multi-turn user conversations covering various interaction relationships, based on six common types of constraints from system messages in real-world scenarios. our dataset contains 500 system messages from various domains, each paired with 5 turns of user conversations, which have been manually formulated and checked to guarantee high quality. sysbench provides extensive evaluation across various llms, measuring their ability to follow specified constraints given in system messages. the results highlight both the strengths and weaknesses of existing models, offering key insights and directions for future research. the open source library sysbench is available at https://github.com/pku-baichuan-mlsystemlab/sysbench.",,2024-08-20,,"['yanzhao qin', 'tao zhang', 'tao zhang', 'yanjun shen', 'wenjing luo', 'haoze sun', 'yan zhang', 'yujing qiao', 'weipeng chen', 'zenan zhou', 'wentao zhang', 'bin cui']"
1815,2408.10945,hired: attention-guided token dropping for efficient inference of   high-resolution vision-language models in resource-constrained environments,cs.cv cs.ai,"high-resolution vision-language models (vlms) have been widely used in multimodal tasks to enhance accuracy by preserving detailed image information. however, these models often generate excessive visual tokens due to encoding multiple partitions of the input image. processing these excessive visual tokens is computationally challenging, especially in resource-constrained environments with commodity gpus. to support high-resolution images while meeting resource constraints, we propose high-resolution early dropping (hired), a token-dropping scheme that operates within a fixed token budget before the large language model (llm) stage. hired can be integrated with existing high-resolution vlms in a plug-and-play manner, as it requires no additional training while still maintaining superior accuracy. we strategically use the vision encoder's attention in the initial layers to assess the visual content of each image partition and allocate the token budget accordingly. then, using the attention in the final layer, we select the most important visual tokens from each partition within the allocated budget, dropping the rest. empirically, when applied to llava-next-7b on nvidia tesla p40 gpu, hired with a 20% token budget increases token generation throughput by 4.7, reduces first-token generation latency by 15 seconds, and saves 2.3 gb of gpu memory for a single inference.",,2024-08-20,,"['kazi hasan ibn arif', 'jinyi yoon', 'dimitrios s. nikolopoulos', 'hans vandierendonck', 'deepu john', 'bo ji']"
1816,2408.10946,large language model driven recommendation,cs.ai,"while previous chapters focused on recommendation systems (rss) based on standardized, non-verbal user feedback such as purchases, views, and clicks -- the advent of llms has unlocked the use of natural language (nl) interactions for recommendation. this chapter discusses how llms' abilities for general nl reasoning present novel opportunities to build highly personalized rss -- which can effectively connect nuanced and diverse user preferences to items, potentially via interactive dialogues. to begin this discussion, we first present a taxonomy of the key data sources for language-driven recommendation, covering item descriptions, user-system interactions, and user profiles. we then proceed to fundamental techniques for llm recommendation, reviewing the use of encoder-only and autoregressive llm recommendation in both tuned and untuned settings. afterwards, we move to multi-module recommendation architectures in which llms interact with components such as retrievers and rss in multi-stage pipelines. this brings us to architectures for conversational recommender systems (crss), in which llms facilitate multi-turn dialogues where each turn presents an opportunity not only to make recommendations, but also to engage with the user in interactive preference elicitation, critiquing, and question-answering.",,2024-08-20,,"['anton korikov', 'scott sanner', 'yashar deldjoo', 'zhankui he', 'julian mcauley', 'arnau ramisa', 'rene vidal', 'mahesh sathiamoorthy', 'atoosa kasrizadeh', 'silvia milano', 'francesco ricci']"
1817,2408.10947,dr.academy: a benchmark for evaluating questioning capability in   education for large language models,cs.ai cs.cl cs.cy,"teachers are important to imparting knowledge and guiding learners, and the role of large language models (llms) as potential educators is emerging as an important area of study. recognizing llms' capability to generate educational content can lead to advances in automated and personalized learning. while llms have been tested for their comprehension and problem-solving skills, their capability in teaching remains largely unexplored. in teaching, questioning is a key skill that guides students to analyze, evaluate, and synthesize core concepts and principles. therefore, our research introduces a benchmark to evaluate the questioning capability in education as a teacher of llms through evaluating their generated educational questions, utilizing anderson and krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary domains. we shift the focus from llms as learners to llms as educators, assessing their teaching capability through guiding them to generate questions. we apply four metrics, including relevance, coverage, representativeness, and consistency, to evaluate the educational quality of llms' outputs. our results indicate that gpt-4 demonstrates significant potential in teaching general, humanities, and science courses; claude2 appears more apt as an interdisciplinary teacher. furthermore, the automatic scores align with human perspectives.",,2024-08-20,,"['yuyan chen', 'chenwei wu', 'songzhou yan', 'panjun liu', 'haoyu zhou', 'yanghua xiao']"
1818,2408.10948,gaim: attacking graph neural networks via adversarial influence   maximization,cs.lg cs.ai,"recent studies show that well-devised perturbations on graph structures or node features can mislead trained graph neural network (gnn) models. however, these methods often overlook practical assumptions, over-rely on heuristics, or separate vital attack components. in response, we present gaim, an integrated adversarial attack method conducted on a node feature basis while considering the strict black-box setting. specifically, we define an adversarial influence function to theoretically assess the adversarial impact of node perturbations, thereby reframing the gnn attack problem into the adversarial influence maximization problem. in our approach, we unify the selection of the target node and the construction of feature perturbations into a single optimization problem, ensuring a unique and consistent feature perturbation for each target node. we leverage a surrogate model to transform this problem into a solvable linear programming task, streamlining the optimization process. moreover, we extend our method to accommodate label-oriented attacks, broadening its applicability. thorough evaluations on five benchmark datasets across three popular models underscore the effectiveness of our method in both untargeted and label-oriented targeted attacks. through comprehensive analysis and ablation studies, we demonstrate the practical value and efficacy inherent to our design choices.",,2024-08-20,,"['xiaodong yang', 'xiaoting li', 'huiyuan chen', 'yiwei cai']"
1819,2408.10951,wave-mask/mix: exploring wavelet-based augmentations for time series   forecasting,cs.lg cs.ai,"data augmentation is important for improving machine learning model performance when faced with limited real-world data. in time series forecasting (tsf), where accurate predictions are crucial in fields like finance, healthcare, and manufacturing, traditional augmentation methods for classification tasks are insufficient to maintain temporal coherence. this research introduces two augmentation approaches using the discrete wavelet transform (dwt) to adjust frequency elements while preserving temporal dependencies in time series data. our methods, wavelet masking (wavemask) and wavelet mixing (wavemix), are evaluated against established baselines across various forecasting horizons. to the best of our knowledge, this is the first study to conduct extensive experiments on multivariate time series using discrete wavelet transform as an augmentation technique. experimental results demonstrate that our techniques achieve competitive results with previous methods. we also explore cold-start forecasting using downsampled training datasets, comparing outcomes to baseline methods.",,2024-08-20,,"['dona arabi', 'jafar bakhshaliyev', 'ayse coskuner', 'kiran madhusudhanan', 'kami serdar uckardes']"
1820,2408.10955,multichannel attention networks with ensembled transfer learning to   recognize bangla handwritten charecter,cs.cv,"the bengali language is the 5th most spoken native and 7th most spoken language in the world, and bengali handwritten character recognition has attracted researchers for decades. however, other languages such as english, arabic, turkey, and chinese character recognition have contributed significantly to developing handwriting recognition systems. still, little research has been done on bengali character recognition because of the similarity of the character, curvature and other complexities. however, many researchers have used traditional machine learning and deep learning models to conduct bengali hand-written recognition. the study employed a convolutional neural network (cnn) with ensemble transfer learning and a multichannel attention network. we generated the feature from the two branches of the cnn, including inception net and resnet and then produced an ensemble feature fusion by concatenating them. after that, we applied the attention module to produce the contextual information from the ensemble features. finally, we applied a classification module to refine the features and classification. we evaluated the proposed model using the camterdb 3.1.2 data set and achieved 92\% accuracy for the raw dataset and 98.00\% for the preprocessed dataset. we believe that our contribution to the bengali handwritten character recognition domain will be considered a great development.",,2024-08-20,,"['farhanul haque', 'md. al-hasan', 'sumaiya tabssum mou', 'abu saleh musa miah', 'jungpil shin', 'md abdur rahim']"
1821,2408.10958,kilometer-scale convection allowing model emulation using generative   diffusion modeling,physics.ao-ph cs.lg,"storm-scale convection-allowing models (cams) are an important tool for predicting the evolution of thunderstorms and mesoscale convective systems that result in damaging extreme weather. by explicitly resolving convective dynamics within the atmosphere they afford meteorologists the nuance needed to provide outlook on hazard. deep learning models have thus far not proven skilful at km-scale atmospheric simulation, despite being competitive at coarser resolution with state-of-the-art global, medium-range weather forecasting. we present a generative diffusion model called stormcast, which emulates the high-resolution rapid refresh (hrrr) model-noaa's state-of-the-art 3km operational cam. stormcast autoregressively predicts 99 state variables at km scale using a 1-hour time step, with dense vertical resolution in the atmospheric boundary layer, conditioned on 26 synoptic variables. we present evidence of successfully learnt km-scale dynamics including competitive 1-6 hour forecast skill for composite radar reflectivity alongside physically realistic convective cluster evolution, moist updrafts, and cold pool morphology. stormcast predictions maintain realistic power spectra for multiple predicted variables across multi-hour forecasts. together, these results establish the potential for autoregressive ml to emulate cams -- opening up new km-scale frontiers for regional ml weather prediction and future climate hazard dynamical downscaling.",,2024-08-20,,"['jaideep pathak', 'yair cohen', 'piyush garg', 'peter harrington', 'noah brenowitz', 'dale durran', 'morteza mardani', 'arash vahdat', 'shaoming xu', 'karthik kashinath', 'michael pritchard']"
1822,2408.10961,combinatorial alphabet-dependent bounds for insdel codes,math.co cs.it math.it,"error-correcting codes resilient to synchronization errors such as insertions and deletions are known as insdel codes. due to their important applications in dna storage and computational biology, insdel codes have recently become a focal point of research in coding theory.   in this paper, we present several new combinatorial upper and lower bounds on the maximum size of $q$-ary insdel codes. our main upper bound is a sphere-packing bound obtained by solving a linear programming (lp) problem. it improves upon previous results for cases when the distance $d$ or the alphabet size $q$ is large. our first lower bound is derived from a connection between insdel codes and matchings in special hypergraphs. this lower bound, together with our upper bound, shows that for fixed block length $n$ and edit distance $d$, when $q$ is sufficiently large, the maximum size of insdel codes is $ \frac{q^{n-\frac{d}{2}+1}}{{n\choose \frac{d}{2}-1}}(1 \pm o(1))$. the second lower bound refines alon et al.'s recent logarithmic improvement on levenshtein's gv-type bound and extends its applicability to large $q$ and $d$.",,2024-08-20,,"['xiangliang kong', 'itzhak tamo', 'hengjia wei']"
1823,2408.10962,nlp for the greek language: a longer survey,cs.cl,"english language is in the spotlight of the natural language processing (nlp) community with other languages, like greek, lagging behind in terms of offered methods, tools and resources. due to the increasing interest in nlp, in this paper we try to condense research efforts for the automatic processing of greek language covering the last three decades. in particular, we list and briefly discuss related works, resources and tools, categorized according to various processing layers and contexts. we are not restricted to the modern form of greek language but also cover ancient greek and various greek dialects. this survey can be useful for researchers and students interested in nlp tasks, information retrieval and knowledge management for the greek language.",,2024-08-20,,"['katerina papantoniou', 'yannis tzitzikas']"
1824,2408.10963,keyspace: public key infrastructure considerations in interplanetary   networks,cs.cr cs.ni,"as satellite networks grow larger and begin to incorporate interplanetary communication, there is an increasing interest in the unsolved problem of how to approach pki in these conditions. in this paper we explore the goals and requirements for implementing key management systems in satellite networks, focusing on megaconstellations and interplanetary networks. we design a set of standardized experiments which can be used to compare systems against one another for particular network topologies. using these, we demonstrate that terrestrial pki techniques are feasible in highly distributed interplanetary networks, showing that it is possible to configure pki systems to achieve efficient low-latency connection establishment, and minimize the impact of attacks through effective revocations.   we evaluate this by building the deep space network simulator (dsns), a novel network simulator aimed at efficient simulation of large space networks. we run simulations evaluating connection establishment and key revocation under a wide range of pki configurations. finally, we propose and evaluate two additional configuration options: ocsp hybrid, and the use of relay nodes as a firewall. together these minimize the extent of the network an attacker can reach with a compromised key, and reduce the attacker's load on interplanetary relay links.",,2024-08-20,,"['joshua smailes', 'sebastian köhler', 'simon birnbach', 'martin strohmeier', 'ivan martinovic']"
1825,2408.10966,isles'24: improving final infarct prediction in ischemic stroke using   multimodal imaging and clinical data,eess.iv cs.cv,"accurate estimation of core (irreversibly damaged tissue) and penumbra (salvageable tissue) volumes is essential for ischemic stroke treatment decisions. perfusion ct, the clinical standard, estimates these volumes but is affected by variations in deconvolution algorithms, implementations, and thresholds. core tissue expands over time, with growth rates influenced by thrombus location, collateral circulation, and inherent patient-specific factors. understanding this tissue growth is crucial for determining the need to transfer patients to comprehensive stroke centers, predicting the benefits of additional reperfusion attempts during mechanical thrombectomy, and forecasting final clinical outcomes. this work presents the isles'24 challenge, which addresses final post-treatment stroke infarct prediction from pre-interventional acute stroke imaging and clinical data. isles'24 establishes a unique 360-degree setting where all feasibly accessible clinical data are available for participants, including full ct acute stroke imaging, sub-acute follow-up mri, and clinical tabular data. the contributions of this work are two-fold: first, we introduce a standardized benchmarking of final stroke infarct segmentation algorithms through the isles'24 challenge; second, we provide insights into infarct segmentation using multimodal imaging and clinical data strategies by identifying outperforming methods on a finely curated dataset. the outputs of this challenge are anticipated to enhance clinical decision-making and improve patient outcome predictions. all isles'24 materials, including data, performance evaluation scripts, and leading algorithmic strategies, are available to the research community following \url{https://isles-24.grand-challenge.org/}.",,2024-08-20,,"['ezequiel de la rosa', 'ruisheng su', 'mauricio reyes', 'roland wiest', 'evamaria o. riedel', 'florian kofler', 'kaiyuan yang', 'hakim baazaoui', 'david robben', 'susanne wegener', 'jan s. kirschke', 'benedikt wiestler', 'bjoern menze']"
1826,2408.1097,hybrid recurrent models support emergent descriptions for hierarchical   planning and control,cs.ai cs.sy eess.sy,"an open problem in artificial intelligence is how systems can flexibly learn discrete abstractions that are useful for solving inherently continuous problems. previous work has demonstrated that a class of hybrid state-space model known as recurrent switching linear dynamical systems (rslds) discover meaningful behavioural units via the piecewise linear decomposition of complex continuous dynamics (linderman et al., 2016). furthermore, they model how the underlying continuous states drive these discrete mode switches. we propose that the rich representations formed by an rslds can provide useful abstractions for planning and control. we present a novel hierarchical model-based algorithm inspired by active inference in which a discrete mdp sits above a low-level linear-quadratic controller. the recurrent transition dynamics learned by the rslds allow us to (1) specify temporally-abstracted sub-goals in a method reminiscent of the options framework, (2) lift the exploration into discrete space allowing us to exploit information-theoretic exploration bonuses and (3) `cache' the approximate solutions to low-level problems in the discrete planner. we successfully apply our model to the sparse continuous mountain car task, demonstrating fast system identification via enhanced exploration and non-trivial planning through the delineation of abstract sub-goals.",,2024-08-20,,"['poppy collis', 'ryan singh', 'paul f kinghorn', 'christopher l buckley']"
1827,2408.10971,asynchronous fault-tolerant distributed proper coloring of graphs,cs.dc,"we revisit asynchronous computing in networks of crash-prone processes, under the asynchronous variant of the standard local model, recently introduced by fraigniaud et al. [disc 2022]. we focus on the vertex coloring problem, and our contributions concern both lower and upper bounds for this problem.   on the upper bound side, we design an algorithm tolerating an arbitrarily large number of crash failures that computes an $o(\delta^2)$-coloring of any $n$-node graph of maximum degree $\delta$, in $o(\log^\star n)$ rounds. this extends linial's seminal result from the (synchronous failure-free) local model to its asynchronous crash-prone variant. then, by allowing a dependency on $\delta$ on the runtime, we show that we can reduce the colors to $\big(\frac12(\delta+1)(\delta+2)-1 \big)$. for cycles (i.e., for $\delta=2$), our algorithm achieves a 5-coloring of any $n$-node cycle, in $o(\log^\star n)$ rounds. this improves the known 6-coloring algorithm by fraigniaud et al., and fixes a bug in their algorithm, which was erroneously claimed to produce a 5-coloring.   on the lower bound side, we show that, for $k<5$, and for every prime integer~$n$, no algorithm can $k$-color the $n$-node cycle in the asynchronous crash-prone variant of local, independently from the round-complexities of the algorithms. this lower bound is obtained by reduction from an original extension of the impossibility of solving weak symmetry-breaking in the wait-free shared-memory model. we show that this impossibility still holds even if the processes are provided with inputs susceptible to help breaking symmetry.",,2024-08-20,,"['alkida balliu', 'pierre fraigniaud', 'patrick lambein-monette', 'dennis olivetti', 'mikael rabie']"
1828,2408.10974,deep reinforcement learning for network energy saving in 6g and beyond   networks,cs.ni,"network energy saving has received great attention from operators and vendors to reduce energy consumption and co2 emissions to the environment as well as significantly reduce costs for mobile network operators. however, the design of energy-saving networks also needs to ensure the mobile users' (mus) qos requirements such as throughput requirements (tr). this work considers a mobile cellular network including many ground base stations (gbss), and some gbss are intentionally turned off due to network energy saving (nes) or crash, so the mus located in these outage gbss are not served in time. based on this observation, we propose the problem of maximizing the total achievable throughput in the network by optimizing the gbss' antenna tilt and adaptive transmission power with a given number of served mus satisfied. notice that, the mu is considered successfully served if its reference signal received power (rsrp) and throughput requirement are satisfied. the formulated optimization problem becomes difficult to solve with multiple binary variables and non-convex constraints along with random throughput requirements and random placement of mus. we propose a deep q-learning-based algorithm to help the network learn the uncertainty and dynamics of the transmission environment. extensive simulation results show that our proposed algorithm achieves much better performance than the benchmark schemes.",,2024-08-20,,"['dinh-hieu tran', 'nguyen van huynh', 'soumeya kaada', 'van nhan vo', 'eva lagunas', 'symeon chatzinotas']"
1829,2408.10976,kernel-based differentiable learning of non-parametric directed acyclic   graphical models,stat.ml cs.lg,"causal discovery amounts to learning a directed acyclic graph (dag) that encodes a causal model. this model selection problem can be challenging due to its large combinatorial search space, particularly when dealing with non-parametric causal models. recent research has sought to bypass the combinatorial search by reformulating causal discovery as a continuous optimization problem, employing constraints that ensure the acyclicity of the graph. in non-parametric settings, existing approaches typically rely on finite-dimensional approximations of the relationships between nodes, resulting in a score-based continuous optimization problem with a smooth acyclicity constraint. in this work, we develop an alternative approximation method by utilizing reproducing kernel hilbert spaces (rkhs) and applying general sparsity-inducing regularization terms based on partial derivatives. within this framework, we introduce an extended rkhs representer theorem. to enforce acyclicity, we advocate the log-determinant formulation of the acyclicity constraint and show its stability. finally, we assess the performance of our proposed rkhs-dagma procedure through simulations and illustrative data analyses.",,2024-08-20,,"['yurou liang', 'oleksandr zadorozhnyi', 'mathias drton']"
1830,2408.10979,the fusion of phonography and ideographic characters into virtual   chinese characters -- based on chinese and english,cs.cl,"the characters used in modern countries are mainly divided into ideographic characters and phonetic characters, both of which have their advantages and disadvantages. chinese is difficult to learn and easy to master, while english is easy to learn but has a large vocabulary. there is still no language that combines the advantages of both languages and has less memory capacity, can form words, and is easy to learn. therefore, inventing new characters that can be combined and the popularization of deep knowledge, and reduce disputes through communication. firstly, observe the advantages and disadvantages of chinese and english, such as their vocabulary, information content, and ease of learning in deep scientific knowledge, and create a new writing system. then, use comparative analysis to observe the total score of the new language. through this article, it can be concluded that the new text combines the advantages of both pictographic and alphabetical writing: new characters that can be combined into words reduces the vocabulary that needs to be learned; special prefixes allow beginners to quickly guess the approximate category and meaning of unseen words; new characters can enable humans to quickly learn more advanced knowledge.",,2024-08-20,,"['hongfa zi', 'zhen liu']"
1831,2408.10982,greediris: scalable influence maximization using distributed streaming   maximum cover,cs.dc,"influence maximization--the problem of identifying a subset of k influential seeds (vertices) in a network--is a classical problem in network science with numerous applications. the problem is np-hard, but there exist efficient polynomial time approximations. however, scaling these algorithms still remain a daunting task due to the complexities associated with steps involving stochastic sampling and large-scale aggregations. in this paper, we present a new parallel distributed approximation algorithm for influence maximization with provable approximation guarantees. our approach, which we call greediris, leverages the randgreedi framework--a state-of-the-art approach for distributed submodular optimization--for solving a step that computes a maximum k cover. greediris combines distributed and streaming models of computations, along with pruning techniques, to effectively address the communication bottlenecks of the algorithm. experimental results on up to 512 nodes (32k cores) of the nersc perlmutter supercomputer show that greediris can achieve good strong scaling performance, preserve quality, and significantly outperform the other state-of-the-art distributed implementations. for instance, on 512 nodes, the most performant variant of greediris achieves geometric mean speedups of 28.99x and 36.35x for two different diffusion models, over a state-of-the-art parallel implementation. we also present a communication-optimized version of greediris that further improves the speedups by two orders of magnitude.",,2024-08-20,,"['reet barik', 'wade cappa', 's m ferdous', 'marco minutoli', 'mahantesh halappanavar', 'ananth kalyanaraman']"
1832,2408.10987,denoising plane wave ultrasound images using diffusion probabilistic   models,eess.iv cs.ai cs.cv,"ultrasound plane wave imaging is a cutting-edge technique that enables high frame-rate imaging. however, one challenge associated with high frame-rate ultrasound imaging is the high noise associated with them, hindering their wider adoption. therefore, the development of a denoising method becomes imperative to augment the quality of plane wave images. drawing inspiration from denoising diffusion probabilistic models (ddpms), our proposed solution aims to enhance plane wave image quality. specifically, the method considers the distinction between low-angle and high-angle compounding plane waves as noise and effectively eliminates it by adapting a ddpm to beamformed radiofrequency (rf) data. the method underwent training using only 400 simulated images. in addition, our approach employs natural image segmentation masks as intensity maps for the generated images, resulting in accurate denoising for various anatomy shapes. the proposed method was assessed across simulation, phantom, and in vivo images. the results of the evaluations indicate that our approach not only enhances image quality on simulated data but also demonstrates effectiveness on phantom and in vivo data in terms of image quality. comparative analysis with other methods underscores the superiority of our proposed method across various evaluation metrics. the source code and trained model will be released along with the dataset at: http://code.sonography.ai",,2024-08-20,,"['hojat asgariandehkordi', 'sobhan goudarzi', 'mostafa sharifzadeh', 'adrian basarab', 'hassan rivaz']"
1833,2408.10993,facial demorphing via identity preserving image decomposition,cs.cv,"a face morph is created by combining the face images usually pertaining to two distinct identities. the goal is to generate an image that can be matched with two identities thereby undermining the security of a face recognition system. to deal with this problem, several morph attack detection techniques have been developed. but these methods do not extract any information about the underlying bonafides used to create them. demorphing addresses this limitation. however, current demorphing techniques are mostly reference-based, i.e, they need an image of one of the identities to recover the other. in this work, we treat demorphing as an ill-posed decomposition problem. we propose a novel method that is reference-free and recovers the bonafides with high accuracy. our method decomposes the morph into several identity-preserving feature components. a merger network then weighs and combines these components to recover the bonafides. our method is observed to reconstruct high-quality bonafides in terms of definition and fidelity. experiments on the casia-webface, smdd and amsl datasets demonstrate the effectiveness of our method.",,2024-08-20,,"['nitish shukla', 'arun ross']"
1834,2408.10995,ctp-llm: clinical trial phase transition prediction using large language   models,cs.cl,"new medical treatment development requires multiple phases of clinical trials. despite the significant human and financial costs of bringing a drug to market, less than 20% of drugs in testing will make it from the first phase to final approval. recent literature indicates that the design of the trial protocols significantly contributes to trial performance. we investigated clinical trial outcome prediction (ctop) using trial design documents to predict phase transitions automatically. we propose ctp-llm, the first large language model (llm) based model for ctop. we also introduce the phasetransition (pt) dataset; which labels trials based on their progression through the regulatory process and serves as a benchmark for ctop evaluation. our fine-tuned gpt-3.5-based model (ctp-llm) predicts clinical trial phase transition by analyzing the trial's original protocol texts without requiring human-selected features. ctp-llm achieves a 67% accuracy rate in predicting trial phase transitions across all phases and a 75% accuracy rate specifically in predicting the transition from phase~iii to final approval. our experimental performance highlights the potential of llm-powered applications in forecasting clinical trial outcomes and assessing trial design.",,2024-08-20,,"['michael reinisch', 'jianfeng he', 'chenxi liao', 'sauleh ahmad siddiqui', 'bei xiao']"
1835,2408.10996,approximation rates for shallow relu$^k$ neural networks on sobolev   spaces via the radon transform,stat.ml cs.lg cs.na math.na,"let $\omega\subset \mathbb{r}^d$ be a bounded domain. we consider the problem of how efficiently shallow neural networks with the relu$^k$ activation function can approximate functions from sobolev spaces $w^s(l_p(\omega))$ with error measured in the $l_q(\omega)$-norm. utilizing the radon transform and recent results from discrepancy theory, we provide a simple proof of nearly optimal approximation rates in a variety of cases, including when $q\leq p$, $p\geq 2$, and $s \leq k + (d+1)/2$. the rates we derive are optimal up to logarithmic factors, and significantly generalize existing results. an interesting consequence is that the adaptivity of shallow relu$^k$ neural networks enables them to obtain optimal approximation rates for smoothness up to order $s = k + (d+1)/2$, even though they represent piecewise polynomials of fixed degree $k$.",,2024-08-20,,"['tong mao', 'jonathan w. siegel', 'jinchao xu']"
1836,2408.10997,disentangling segmental and prosodic factors to non-native speech   comprehensibility,cs.cl eess.as,"current accent conversion (ac) systems do not disentangle the two main sources of non-native accent: segmental and prosodic characteristics. being able to manipulate a non-native speaker's segmental and/or prosodic channels independently is critical to quantify how these two channels contribute to speech comprehensibility and social attitudes. we present an ac system that not only decouples voice quality from accent, but also disentangles the latter into its segmental and prosodic characteristics. the system is able to generate accent conversions that combine (1) the segmental characteristics from a source utterance, (2) the voice characteristics from a target utterance, and (3) the prosody of a reference utterance. we show that vector quantization of acoustic embeddings and removal of consecutive duplicated codewords allows the system to transfer prosody and improve voice similarity. we conduct perceptual listening tests to quantify the individual contributions of segmental features and prosody on the perceived comprehensibility of non-native speech. our results indicate that, contrary to prior research in non-native speech, segmental features have a larger impact on comprehensibility than prosody. the proposed ac system may also be used to study how segmental and prosody cues affect social attitudes towards non-native speech.",,2024-08-20,,"['waris quamer', 'ricardo gutierrez-osuna']"
1837,2408.10998,audio match cutting: finding and creating matching audio transitions in   movies and videos,cs.sd cs.lg eess.as,"a ""match cut"" is a common video editing technique where a pair of shots that have a similar composition transition fluidly from one to another. although match cuts are often visual, certain match cuts involve the fluid transition of audio, where sounds from different sources merge into one indistinguishable transition between two shots. in this paper, we explore the ability to automatically find and create ""audio match cuts"" within videos and movies. we create a self-supervised audio representation for audio match cutting and develop a coarse-to-fine audio match pipeline that recommends matching shots and creates the blended audio. we further annotate a dataset for the proposed audio match cut task and compare the ability of multiple audio representations to find audio match cut candidates. finally, we evaluate multiple methods to blend two matching audio candidates with the goal of creating a smooth transition. project page and examples are available at: https://denfed.github.io/audiomatchcut/",10.1109/icassp48485.2024.10447306,2024-08-20,,"['dennis fedorishin', 'lie lu', 'srirangaraj setlur', 'venu govindaraju']"
1838,2408.11,senpa-mae: sensor parameter aware masked autoencoder for multi-satellite   self-supervised pretraining,cs.cv,"this paper introduces senpa-mae, a transformer architecture that encodes the sensor parameters of an observed multispectral signal into the image embeddings. senpa-mae can be pre-trained on imagery of different satellites with non-matching spectral or geometrical sensor characteristics. to incorporate sensor parameters, we propose a versatile sensor parameter encoding module as well as a data augmentation strategy for the diversification of the pre-training dataset. this enables the model to effectively differentiate between various sensors and gain an understanding of sensor parameters and the correlation to the observed signal. given the rising number of earth observation satellite missions and the diversity in their sensor specifications, our approach paves the way towards a sensor-independent earth observation foundation model. this opens up possibilities such as cross-sensor training and sensor-independent inference.",,2024-08-20,,"['jonathan prexl', 'michael schmitt']"
1839,2408.11001,megafusion: extend diffusion models towards higher-resolution image   generation without further tuning,cs.cv,"diffusion models have emerged as frontrunners in text-to-image generation for their impressive capabilities. nonetheless, their fixed image resolution during training often leads to challenges in high-resolution image generation, such as semantic inaccuracies and object replication. this paper introduces megafusion, a novel approach that extends existing diffusion-based text-to-image generation models towards efficient higher-resolution generation without additional fine-tuning or extra adaptation. specifically, we employ an innovative truncate and relay strategy to bridge the denoising processes across different resolutions, allowing for high-resolution image generation in a coarse-to-fine manner. moreover, by integrating dilated convolutions and noise re-scheduling, we further adapt the model's priors for higher resolution. the versatility and efficacy of megafusion make it universally applicable to both latent-space and pixel-space diffusion models, along with other derivative models. extensive experiments confirm that megafusion significantly boosts the capability of existing models to produce images of megapixels and various aspect ratios, while only requiring about 40% of the original computational cost.",,2024-08-20,,"['haoning wu', 'shaocheng shen', 'qiang hu', 'xiaoyun zhang', 'ya zhang', 'yanfeng wang']"
1840,2408.11002,on the cop number of string graphs,cs.dm math.co,"cops and robber is a well-studied two-player pursuit-evasion game played on a graph, where a group of cops tries to capture the robber. the \emph{cop number} of a graph is the minimum number of cops required to capture the robber. gaven\v{c}iak et al.~[eur. j. of comb. 72, 45--69 (2018)] studied the game on intersection graphs and established that the cop number for the class of string graphs is at most 15, and asked as an open question to improve this bound for string graphs and subclasses of string graphs. we address this question and establish that the cop number of a string graph is at most 13. to this end, we develop a novel \textit{guarding} technique. we further establish that this technique can be useful for other cops and robber games on graphs admitting a representation. in particular, we show that four cops have a winning strategy for a variant of cops and robber, named fully active cops and robber, on planar graphs, addressing an open question of gromovikov et al.~[austr. j. comb. 76(2), 248--265 (2020)]. in passing, we also improve the known bounds on the cop number of boxicity 2 graphs.",,2024-08-20,,"['sandip das', 'harmender gahlawat']"
1841,2408.11006,"while github copilot excels at coding, does it ensure responsible   output?",cs.cl cs.cr,"the rapid development of large language models (llms) has significantly advanced code completion capabilities, giving rise to a new generation of llm-based code completion tools (lccts). unlike general-purpose llms, these tools possess unique workflows, integrating multiple information sources as input and prioritizing code suggestions over natural language interaction, which introduces distinct security challenges. additionally, lccts often rely on proprietary code datasets for training, raising concerns about the potential exposure of sensitive data. this paper exploits these distinct characteristics of lccts to develop targeted attack methodologies on two critical security risks: jailbreaking and training data extraction attacks. our experimental results expose significant vulnerabilities within lccts, including a 99.4% success rate in jailbreaking attacks on github copilot and a 46.3% success rate on amazon q. furthermore, we successfully extracted sensitive user data from github copilot, including 54 real email addresses and 314 physical addresses associated with github usernames. our study also demonstrates that these code-based attack methods are effective against general-purpose llms, such as the gpt series, highlighting a broader security misalignment in the handling of code by modern llms. these findings underscore critical security challenges associated with lccts and suggest essential directions for strengthening their security frameworks. the example code and attack samples from our research are provided at https://github.com/sensente/security-attacks-on-lccts.",,2024-08-20,,"['wen cheng', 'ke sun', 'xinyu zhang', 'wei wang']"
1842,2408.11007,extending the quantitative pattern-matching paradigm,cs.pl cs.lo,"we show how (well-established) type systems based on non-idempotent intersection types can be extended to characterize termination properties of functional programming languages with pattern matching features. to model such programming languages, we use a (weak and closed) $\lambda$-calculus integrating a pattern matching mechanism on algebraic data types (adts). remarkably, we also show that this language not only encodes plotkin's cbv and cbn $\lambda$-calculus as well as other subsuming frameworks, such as the bang-calculus, but can also be used to interpret the semantics of effectful languages with exceptions. after a thorough study of the untyped language, we introduce a type system based on intersection types, and we show through purely logical methods that the set of terminating terms of the language corresponds exactly to that of well-typed terms. moreover, by considering non-idempotent intersection types, this characterization turns out to be quantitative, i.e. the size of the type derivation of a term t gives an upper bound for the number of evaluation steps from t to its normal form.",,2024-08-20,,"['sandra alves', 'delia kesner', 'miguel ramos']"
1843,2408.11008,towards a standardized representation for deep learning collective   algorithms,cs.dc,"the explosion of machine learning model size has led to its execution on distributed clusters at a very large scale. many works have tried to optimize the process of producing collective algorithms and running collective communications, which act as a bottleneck to distributed machine learning. however, different works use their own collective algorithm representation, pushing away from co-optimizing collective communication and the rest of the workload. the lack of a standardized collective algorithm representation has also hindered interoperability between collective algorithm producers and consumers. additionally, tool-specific conversions and modifications have to be made for each pair of tools producing and consuming collective algorithms which adds to engineering efforts.   in this position paper, we propose a standardized workflow leveraging a common collective algorithm representation. upstream producers and downstream consumers converge to a common representation format based on chakra execution trace, a commonly used graph based representation of distributed machine learning workloads. such a common representation enables us to view collective communications at the same level as workload operations and decouple producer and consumer tools, enhance interoperability, and relieve the user from the burden of having to focus on downstream implementations. we provide a proof-of-concept of this standardized workflow by simulating collective algorithms generated by the mscclang domain-specific language through the astra-sim distributed machine learning simulator using various network configurations.",,2024-08-20,,"['jinsun yoo', 'william won', 'meghan cowan', 'nan jiang', 'benjamin klenk', 'srinivas sridharan', 'tushar krishna']"
1844,2408.11015,hyperproperty-preserving register specifications (extended version),cs.dc,"reasoning about hyperproperties of concurrent implementations, such as the guarantees these implementations provide to randomized client programs, has been a long-standing challenge. standard linearizability enables the use of atomic specifications for reasoning about standard properties, but not about hyperproperties. a stronger correctness criterion, called strong linearizability, enables such reasoning, but is rarely achievable, leaving various useful implementations with no means for reasoning about their hyperproperties. in this paper, we focus on registers and devise non-atomic specifications that capture a wide-range of well-studied register implementations and enable reasoning about their hyperproperties. first, we consider the class of write strong-linearizable implementations, a recently proposed useful weakening of strong linearizability, which allows more intricate implementations, such as the well-studied single-writer abd distributed implementation. we introduce a simple shared-memory register specification that can be used for reasoning about hyperproperties of programs that use write strongly-linearizable implementations. second, we introduce a new linearizability class, which we call decisive linearizability, that is weaker than write strong-linearizability and includes multi-writer abd, and develop a second shared-memory register specification for reasoning about hyperproperties of programs that use register implementations of this class. these results shed light on the hyperproperties guaranteed when simulating shared memory in a crash-resilient message-passing system.",,2024-08-20,,"['yoav ben shimon', 'ori lahav', 'sharon shoham']"
1845,2408.11017,multiwinner temporal voting with aversion to change,cs.gt cs.ai cs.cc,"we study two-stage committee elections where voters have dynamic preferences over candidates; at each stage, a committee is chosen under a given voting rule. we are interested in identifying a winning committee for the second stage that overlaps as much as possible with the first-stage committee. we show a full complexity dichotomy for the class of thiele rules: this problem is tractable for approval voting (av) and hard for all other thiele rules (including, in particular, proportional approval voting and the chamberlin-courant rule). we extend this dichotomy to the greedy variants of thiele rules. we also explore this problem from a parameterized complexity perspective for several natural parameters. we complement the theory with experimental analysis: e.g., we investigate the average number of changes in the committee as a function of changes in voters' preferences and the role of ties.",,2024-08-20,,"['valentin zech', 'niclas boehmer', 'edith elkind', 'nicholas teh']"
1846,2408.11019,an overlooked role of context-sensitive dendrites,q-bio.nc cs.ai cs.lg,"to date, most dendritic studies have predominantly focused on the apical zone of pyramidal two-point neurons (tpns) receiving only feedback (fb) connections from higher perceptual layers and using them for learning. recent cellular neurophysiology and computational neuroscience studies suggests that the apical input (context), coming from feedback and lateral connections, is multifaceted and far more diverse, with greater implications for ongoing learning and processing in the brain than previously realized. in addition to the fb, the apical tuft receives signals from neighboring cells of the same network as proximal (p) context, other parts of the brain as distal (d) context, and overall coherent information across the network as universal (u) context. the integrated context (c) amplifies and suppresses the transmission of coherent and conflicting feedforward (ff) signals, respectively. specifically, we show that complex context-sensitive (cs)-tpns flexibly integrate c moment-by-moment with the ff somatic current at the soma such that the somatic current is amplified when both feedforward (ff) and c are coherent; otherwise, it is attenuated. this generates the event only when the ff and c currents are coherent, which is then translated into a singlet or a burst based on the fb information. spiking simulation results show that this flexible integration of somatic and contextual currents enables the propagation of more coherent signals (bursts), making learning faster with fewer neurons. similar behavior is observed when this functioning is used in conventional artificial networks, where orders of magnitude fewer neurons are required to process vast amounts of heterogeneous real-world audio-visual (av) data trained using backpropagation (bp). the computational findings presented here demonstrate the universality of cs-tpns, suggesting a dendritic narrative that was previously overlooked.",,2024-08-20,,"['mohsin raza', 'ahsan adeel']"
1847,2408.11021,athena: safe autonomous agents with verbal contrastive learning,cs.cl cs.ai cs.ma,"due to emergent capabilities, large language models (llms) have been utilized as language-based agents to perform a variety of tasks and make decisions with an increasing degree of autonomy. these autonomous agents can understand high-level instructions, interact with their environments, and execute complex tasks using a selection of tools available to them. as the capabilities of the agents expand, ensuring their safety and trustworthiness becomes more imperative. in this study, we introduce the athena framework which leverages the concept of verbal contrastive learning where past safe and unsafe trajectories are used as in-context (contrastive) examples to guide the agent towards safety while fulfilling a given task. the framework also incorporates a critiquing mechanism to guide the agent to prevent risky actions at every step. furthermore, due to the lack of existing benchmarks on the safety reasoning ability of llm-based agents, we curate a set of 80 toolkits across 8 categories with 180 scenarios to provide a safety evaluation benchmark. our experimental evaluation, with both closed- and open-source llms, indicates verbal contrastive learning and interaction-level critiquing improve the safety rate significantly.",,2024-08-20,,"['tanmana sadhu', 'ali pesaranghader', 'yanan chen', 'dong hoon yi']"
1848,2408.11029,scaling law with learning rate annealing,cs.cl,"we find that the cross-entropy loss curves of neural language models empirically adhere to a scaling law with learning rate (lr) annealing over training steps ($s$): $$l(s) = l_0 + a\cdot s_1^{-\alpha} - c\cdot s_2$$ where $s_1$ is forward area and $s_2$ is learning rate annealing area. this formulation takes into account two factors: (1) the forward scaling defined as typical scaling law, and (2) the additional loss drop brought by lr annealing. therefore, this formulation can describe the full loss curve at each step, rather than the single loss point at the end of training. applying the scaling law with lr annealing and fitting only one or two training curves, we can accurately predict the loss of language model training at any given step and across any learning rate scheduler (lrs). furthermore, this equation accurately describes the dynamics during training process, and provides a theoretical verification and explanation for numerous experimental findings of previous studies, particularly those focusing on lr schedule and lr annealing. the resulting insights, also serve as a guide for researchers to select critical lrs in advance by prediction using our equation. most significantly, since all the points in a full training curve follow the equation, we can achieve accurate loss prediction at any given step across any learning rate scheduler, while expending less than 1\% of the computational cost required by the chinchilla scaling law to fit language modeling loss. this approach extremely democratizes scaling law fitting and predicting in developing large language models.",,2024-08-20,,"['howe tissue', 'venus wang', 'lu wang']"
1849,2408.1103,openscan: a benchmark for generalized open-vocabulary 3d scene   understanding,cs.cv,"open-vocabulary 3d scene understanding (ov-3d) aims to localize and classify novel objects beyond the closed object classes. however, existing approaches and benchmarks primarily focus on the open vocabulary problem within the context of object classes, which is insufficient to provide a holistic evaluation to what extent a model understands the 3d scene. in this paper, we introduce a more challenging task called generalized open-vocabulary 3d scene understanding (gov-3d) to explore the open vocabulary problem beyond object classes. it encompasses an open and diverse set of generalized knowledge, expressed as linguistic queries of fine-grained and object-specific attributes. to this end, we contribute a new benchmark named openscan, which consists of 3d object attributes across eight representative linguistic aspects, including affordance, property, material, and more. we further evaluate state-of-the-art ov-3d methods on our openscan benchmark, and discover that these methods struggle to comprehend the abstract vocabularies of the gov-3d task, a challenge that cannot be addressed by simply scaling up object classes during training. we highlight the limitations of existing methodologies and explore a promising direction to overcome the identified shortcomings. data and code are available at https://github.com/youjunzhao/openscan",,2024-08-20,,"['youjun zhao', 'jiaying lin', 'shuquan ye', 'qianshi pang', 'rynson w. h. lau']"
1850,2408.11032,atmospheric transport modeling of co$_2$ with neural networks,cs.lg cs.cv physics.ao-ph,"accurately describing the distribution of co$_2$ in the atmosphere with atmospheric tracer transport models is essential for greenhouse gas monitoring and verification support systems to aid implementation of international climate agreements. large deep neural networks are poised to revolutionize weather prediction, which requires 3d modeling of the atmosphere. while similar in this regard, atmospheric transport modeling is subject to new challenges. both, stable predictions for longer time horizons and mass conservation throughout need to be achieved, while io plays a larger role compared to computational costs. in this study we explore four different deep neural networks (unet, graphcast, spherical fourier neural operator and swintransformer) which have proven as state-of-the-art in weather prediction to assess their usefulness for atmospheric tracer transport modeling. for this, we assemble the carbonbench dataset, a systematic benchmark tailored for machine learning emulators of eulerian atmospheric transport. through architectural adjustments, we decouple the performance of our emulators from the distribution shift caused by a steady rise in atmospheric co$_2$. more specifically, we center co$_2$ input fields to zero mean and then use an explicit flux scheme and a mass fixer to assure mass balance. this design enables stable and mass conserving transport for over 6 months with all four neural network architectures. in our study, the swintransformer displays particularly strong emulation skill (90-day $r^2 > 0.99$), with physically plausible emulation even for forward runs of multiple years. this work paves the way forward towards high resolution forward and inverse modeling of inert trace gases with neural networks.",,2024-08-20,,"['vitus benson', 'ana bastos', 'christian reimers', 'alexander j. winkler', 'fanny yang', 'markus reichstein']"
1851,2408.11039,transfusion: predict the next token and diffuse images with one   multi-modal model,cs.ai cs.cv,"we introduce transfusion, a recipe for training a multi-modal model over discrete and continuous data. transfusion combines the language modeling loss function (next token prediction) with diffusion to train a single transformer over mixed-modality sequences. we pretrain multiple transfusion models up to 7b parameters from scratch on a mixture of text and image data, establishing scaling laws with respect to a variety of uni- and cross-modal benchmarks. our experiments show that transfusion scales significantly better than quantizing images and training a language model over discrete image tokens. by introducing modality-specific encoding and decoding layers, we can further improve the performance of transfusion models, and even compress each image to just 16 patches. we further demonstrate that scaling our transfusion recipe to 7b parameters and 2t multi-modal tokens produces a model that can generate images and text on a par with similar scale diffusion models and language models, reaping the benefits of both worlds.",,2024-08-20,,"['chunting zhou', 'lili yu', 'arun babu', 'kushal tirumala', 'michihiro yasunaga', 'leonid shamis', 'jacob kahn', 'xuezhe ma', 'luke zettlemoyer', 'omer levy']"
1852,2408.1104,solving the convex flow problem,math.oc cs.ms,"in this paper, we introduce the solver convexflows for the convex flow problem first defined in the authors' previous work. in this problem, we aim to optimize a concave utility function depending on the flows over a graph. however, unlike the classic network flows literature, we also allow for a concave relationship between the input and output flows of edges. this nonlinear gain describes many physical phenomena, including losses in power network transmission lines. we outline an efficient algorithm for solving this problem which parallelizes over the graph edges. we provide an open source implementation of this algorithm in the julia programming language package convexflows.jl. this package includes an interface to easily specify these flow problems. we conclude by walking through an example of solving for an optimal power flow using convexflows.",,2024-08-20,,"['theo diamandis', 'guillermo angeris']"
1853,2408.11041,decentralized distributed graph coloring ii: degree+1-coloring virtual   graphs,cs.dc cs.ds,"graph coloring is fundamental to distributed computing. we give the first general treatment of the coloring of virtual graphs, where the graph $h$ to be colored is locally embedded within the communication graph $g$. besides generalizing classical distributed graph coloring (where $h=g$), this captures other previously studied settings, including cluster graphs and power graphs.   we find that the complexity of coloring a virtual graph depends on the edge congestion of its embedding. the main question of interest is how fast we can color virtual graphs of constant congestion. we find that, surprisingly, these graphs can be colored nearly as fast as ordinary graphs. namely, we give a $o(\log^4\log n)$-round algorithm for the deg+1-coloring problem, where each node is assigned more colors than its degree.   this can be viewed as a case where a distributed graph problem can be solved even when the operation of each node is decentralized.",,2024-08-20,,"['maxime flin', 'magnús m. halldórsson', 'alexandre nolin']"
1854,2408.11042,graphfsa: a finite state automaton framework for algorithmic learning on   graphs,cs.ai,"many graph algorithms can be viewed as sets of rules that are iteratively applied, with the number of iterations dependent on the size and complexity of the input graph. existing machine learning architectures often struggle to represent these algorithmic decisions as discrete state transitions. therefore, we propose a novel framework: graphfsa (graph finite state automaton). graphfsa is designed to learn a finite state automaton that runs on each node of a given graph. we test graphfsa on cellular automata problems, showcasing its abilities in a straightforward algorithmic setting. for a comprehensive empirical evaluation of our framework, we create a diverse range of synthetic problems. as our main application, we then focus on learning more elaborate graph algorithms. our findings suggest that graphfsa exhibits strong generalization and extrapolation abilities, presenting an alternative approach to represent these algorithms.",,2024-08-20,,"['florian grötschla', 'joël mathys', 'christoffer raun', 'roger wattenhofer']"
1855,2408.11043,reconciling methodological paradigms: employing large language models as   novice qualitative research assistants in talent management research,cs.cy cs.ai,"qualitative data collection and analysis approaches, such as those employing interviews and focus groups, provide rich insights into customer attitudes, sentiment, and behavior. however, manually analyzing qualitative data requires extensive time and effort to identify relevant topics and thematic insights. this study proposes a novel approach to address this challenge by leveraging retrieval augmented generation (rag) based large language models (llms) for analyzing interview transcripts. the novelty of this work lies in strategizing the research inquiry as one that is augmented by an llm that serves as a novice research assistant. this research explores the mental model of llms to serve as novice qualitative research assistants for researchers in the talent management space. a rag-based llm approach is extended to enable topic modeling of semi-structured interview data, showcasing the versatility of these models beyond their traditional use in information retrieval and search. our findings demonstrate that the llm-augmented rag approach can successfully extract topics of interest, with significant coverage compared to manually generated topics from the same dataset. this establishes the viability of employing llms as novice qualitative research assistants. additionally, the study recommends that researchers leveraging such models lean heavily on quality criteria used in traditional qualitative research to ensure rigor and trustworthiness of their approach. finally, the paper presents key recommendations for industry practitioners seeking to reconcile the use of llms with established qualitative research paradigms, providing a roadmap for the effective integration of these powerful, albeit novice, ai tools in the analysis of qualitative datasets within talent",,2024-08-20,,"['sreyoshi bhaduri', 'satya kapoor', 'alex gil', 'anshul mittal', 'rutu mulkar']"
1856,2408.11046,inside the black box: detecting data leakage in pre-trained language   encoders,cs.cl,"despite being prevalent in the general field of natural language processing (nlp), pre-trained language models inherently carry privacy and copyright concerns due to their nature of training on large-scale web-scraped data. in this paper, we pioneer a systematic exploration of such risks associated with pre-trained language encoders, specifically focusing on the membership leakage of pre-training data exposed through downstream models adapted from pre-trained language encoders-an aspect largely overlooked in existing literature. our study encompasses comprehensive experiments across four types of pre-trained encoder architectures, three representative downstream tasks, and five benchmark datasets. intriguingly, our evaluations reveal, for the first time, the existence of membership leakage even when only the black-box output of the downstream model is exposed, highlighting a privacy risk far greater than previously assumed. alongside, we present in-depth analysis and insights toward guiding future researchers and practitioners in addressing the privacy considerations in developing pre-trained language models.",,2024-08-20,,"['yuan xin', 'zheng li', 'ning yu', 'dingfan chen', 'mario fritz', 'michael backes', 'yang zhang']"
1857,2408.11048,rp1m: a large-scale motion dataset for piano playing with bi-manual   dexterous robot hands,cs.ro cs.ai cs.lg,"it has been a long-standing research goal to endow robot hands with human-level dexterity. bi-manual robot piano playing constitutes a task that combines challenges from dynamic tasks, such as generating fast while precise motions, with slower but contact-rich manipulation problems. although reinforcement learning based approaches have shown promising results in single-task performance, these methods struggle in a multi-song setting. our work aims to close this gap and, thereby, enable imitation learning approaches for robot piano playing at scale. to this end, we introduce the robot piano 1 million (rp1m) dataset, containing bi-manual robot piano playing motion data of more than one million trajectories. we formulate finger placements as an optimal transport problem, thus, enabling automatic annotation of vast amounts of unlabeled songs. benchmarking existing imitation learning approaches shows that such approaches reach state-of-the-art robot piano playing performance by leveraging rp1m.",,2024-08-20,,"['yi zhao', 'le chen', 'jan schneider', 'quankai gao', 'juho kannala', 'bernhard schölkopf', 'joni pajarinen', 'dieter büchler']"
1858,2408.11051,flame: learning to navigate with multimodal llm in urban environments,cs.cv cs.ai cs.cl cs.ro,"large language models (llms) have demonstrated potential in vision-and-language navigation (vln) tasks, yet current applications face challenges. while llms excel in general conversation scenarios, they struggle with specialized navigation tasks, yielding suboptimal performance compared to specialized vln models. we introduce flame (flamingo-architected embodied agent), a novel multimodal llm-based agent and architecture designed for urban vln tasks that efficiently handles multiple observations. our approach implements a three-phase tuning technique for effective adaptation to navigation tasks, including single perception tuning for street view description, multiple perception tuning for trajectory summarization, and end-to-end training on vln datasets. the augmented datasets are synthesized automatically. experimental results demonstrate flame's superiority over existing methods, surpassing state-of-the-art methods by a 7.3% increase in task completion rate on touchdown dataset. this work showcases the potential of multimodal llms (mllms) in complex navigation tasks, representing an advancement towards practical applications of mllms in embodied ai. project page: https://flame-sjtu.github.io",,2024-08-20,,"['yunzhe xu', 'yiyuan pan', 'zhe liu', 'hesheng wang']"
1859,2408.11052,accelerating goal-conditioned rl algorithms and research,cs.lg cs.ai,"self-supervision has the potential to transform reinforcement learning (rl), paralleling the breakthroughs it has enabled in other areas of machine learning. while self-supervised learning in other domains aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (gcrl) agents discover new behaviors by learning from the goals achieved during unstructured interaction with the environment. however, these methods have failed to see similar success, both due to a lack of data from slow environments as well as a lack of stable algorithms. we take a step toward addressing both of these issues by releasing a high-performance codebase and benchmark jaxgcrl for self-supervised gcrl, enabling researchers to train agents for millions of environment steps in minutes on a single gpu. the key to this performance is a combination of gpu-accelerated environments and a stable, batched version of the contrastive reinforcement learning algorithm, based on an infonce objective, that effectively makes use of this increased data throughput. with this approach, we provide a foundation for future research in self-supervised gcrl, enabling researchers to quickly iterate on new ideas and evaluate them in a diverse set of challenging environments. website + code: https://github.com/michalbortkiewicz/jaxgcrl",,2024-08-20,,"['michał bortkiewicz', 'władek pałucki', 'vivek myers', 'tadeusz dziarmaga', 'tomasz arczewski', 'łukasz kuciński', 'benjamin eysenbach']"
1860,2408.11053,"revisiting verilogeval: newer llms, in-context learning, and   specification-to-rtl tasks",cs.se cs.ai,"the application of large-language models (llms) to digital hardware code generation is an emerging field. most llms are primarily trained on natural language and software code. hardware code, such as verilog, represents only a small portion of the training data and few hardware benchmarks exist. to address this gap, the open-source verilogeval benchmark was released in 2023, providing a consistent evaluation framework for llms on code completion tasks. it was tested on state-of-the-art models at the time including gpt-4. however, verilogeval and other verilog generation benchmarks lack failure analysis and, in present form, are not conducive to exploring prompting techniques. also, since verilogeval's release, both commercial and open-source models have seen continued development.   in this work, we evaluate new commercial and open-source models of varying sizes against an improved verilogeval benchmark suite. we enhance verilogeval's infrastructure and dataset by automatically classifying failures, introduce new prompts for supporting in-context learning (icl) examples, and extend the supported tasks to specification-to-rtl translation. we find a measurable improvement in commercial state-of-the-art models, with gpt-4 turbo achieving a 59% pass rate on spec-to-rtl tasks. we also study the performance of open-source and domain-specific models that have emerged, and demonstrate that models can benefit substantially from icl. we find that recently-released llama 3.1 405b achieves a pass rate of 58%, effectively matching that of gpt-4 turbo, and that the much smaller domain-specific rtl-coder 6.7b models achieve an impressive 37% pass rate. however, prompt engineering is key to achieving good pass rates, and varies widely with model and task. a benchmark infrastructure that allows for prompt engineering and failure analysis is key to continued model development and deployment.",,2024-08-20,,"['nathaniel pinckney', 'christopher batten', 'mingjie liu', 'haoxing ren', 'brucek khailany']"
1861,2408.11054,neco: improving dinov2's spatial representations in 19 gpu hours with   patch neighbor consistency,cs.cv cs.ai,"we propose sorting patch representations across views as a novel self-supervised learning signal to improve pretrained representations. to this end, we introduce neco: patch neighbor consistency, a novel training loss that enforces patch-level nearest neighbor consistency across a student and teacher model, relative to reference batches. our method leverages a differentiable sorting method applied on top of pretrained representations, such as dinov2-registers to bootstrap the learning signal and further improve upon them. this dense post-pretraining leads to superior performance across various models and datasets, despite requiring only 19 hours on a single gpu. we demonstrate that this method generates high-quality dense feature encoders and establish several new state-of-the-art results: +5.5% and + 6% for non-parametric in-context semantic segmentation on ade20k and pascal voc, and +7.2% and +5.7% for linear segmentation evaluations on coco-things and -stuff.",,2024-08-20,,"['valentinos pariza', 'mohammadreza salehi', 'gertjan burghouts', 'francesco locatello', 'yuki m. asano']"
1862,2408.11055,prompt-guided image-adaptive neural implicit lookup tables for   interpretable image enhancement,cs.cv,"in this paper, we delve into the concept of interpretable image enhancement, a technique that enhances image quality by adjusting filter parameters with easily understandable names such as ""exposure"" and ""contrast"". unlike using predefined image editing filters, our framework utilizes learnable filters that acquire interpretable names through training. our contribution is two-fold. firstly, we introduce a novel filter architecture called an image-adaptive neural implicit lookup table, which uses a multilayer perceptron to implicitly define the transformation from input feature space to output color space. by incorporating image-adaptive parameters directly into the input features, we achieve highly expressive filters. secondly, we introduce a prompt guidance loss to assign interpretable names to each filter. we evaluate visual impressions of enhancement results, such as exposure and contrast, using a vision and language model along with guiding prompts. we define a constraint to ensure that each filter affects only the targeted visual impression without influencing other attributes, which allows us to obtain the desired filter effects. experimental results show that our method outperforms existing predefined filter-based methods, thanks to the filters optimized to predict target results. our source code is available at https://github.com/satoshi-kosugi/pg-ia-nilut.",10.1145/3664647.3680743,2024-08-20,,['satoshi kosugi']
